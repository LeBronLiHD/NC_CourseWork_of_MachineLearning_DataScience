{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTWdLWeWeAkQ"
   },
   "source": [
    "# README\n",
    "\n",
    "Dear TA, because of my carelessness, I realized that we are expected to implement Problem 2.1 in Tensorflow and Keras at the time when I have finished implementation in PyTorch.\n",
    "\n",
    "The place where the Tensorflow and Kera is used is in the second half of this .ipynb file, please see the end.\n",
    "\n",
    "Thanks a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "epPOuItfSkXA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "from torchvision.datasets import MNIST,FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439,
     "referenced_widgets": [
      "1fc76c33a13e44728bf6d974d5036cc7",
      "57fdcfcdc4e240ffa2189a29e2517633",
      "55f40a11927b42e6af8c4eaa37df344b",
      "d5801e57bec3448dae87a53fc1b907a2",
      "85a978c798ba44c4ba4fa2ace2bd4983",
      "7c73bf30e8ca400e9b1df74221b3c26c",
      "06c878ac72ce4b98b8743bdcc679643e",
      "353d957da38b4917ba8067fc71daaa19",
      "ff64e56c0d1c461da44351c69addac7f",
      "dd069f3fa7634cfa878523058aedafd1",
      "e31cdb7f86cb4c5d8af8dca59b5726d6",
      "42066f9eebbc471cad42292234606c54",
      "4c4a404f55b34b229a984f93ddea1f29",
      "cea0ea0ed6544874b6f4d1f8505071fc",
      "dfc3b4f1fd7142d497b4797425b65292",
      "2d86297399034b389663116e71567f52",
      "d36de7b8a3164379a1e814bbd3ad097d",
      "ffd1f3a4f7bc49ff8d0ab31c9c8bf000",
      "148d268885544c53999e71cceccf6c96",
      "48d6c74d5c304882bb8be8a3674de859",
      "bff4a9aec0d1460aa1a5b01a4ca9dccb",
      "5e0f3233166148ec89445f05c0256668",
      "67247d9d5c454310816815207df8feea",
      "c980d794034a4315ae931fd0f5dc2dcd",
      "094de1b4857b4668b72a3160e0af4ae3",
      "2d11f46392804f2aa0206790ce5e8ce1",
      "925214df03974081b0507f44b461e463",
      "a55a0760c4ce449ca604f931e3c76ea8",
      "f40fcf31f4c845f4928b6d7c9f738322",
      "d330ee2e8bc640e694abaf2371f0994c",
      "c9580c5922b848dbbeed254a69a302e0",
      "341c0e8cd3e542778cdc006479db4701",
      "4344f89c1ec14095a45de9ba880d9343",
      "3a26773d69f34cabb07deb3d63733938",
      "676c07ac3b804786bb65b88e07673633",
      "d90ab9d6017a411fa3efa24de9895501",
      "02f72b93b4bb4431914c34df47cb1ed8",
      "6ae38e8964c84b0b8a539a3ea62e7583",
      "ecbe5e6cad78453183cb57a66a382f96",
      "64e7e002e0274fbd906ac56c49271019",
      "28442885523141fb8688f1a1f9365c82",
      "ddf26eedd06c45679b1a17b8ce37fa6f",
      "3d4a15640ef5422299989e834da73626",
      "9e896960a2894d7a9c18116881a54ef6"
     ]
    },
    "id": "Gwt-qBzWTA3u",
    "outputId": "192f5c40-8a3f-4f61-e334-52b80671105c"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "data_train = MNIST(root = \"data/\", \n",
    "          transform = transform, ## 图像变换操作\n",
    "          train =True, ## 决定使用训练集还是测试集\n",
    "          download = True) ## 选择是否需要下载数据\n",
    "data_test = MNIST(root = \"data/\",\n",
    "          transform = transform,\n",
    "          train =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AS44xNKaTcW5",
    "outputId": "67c4a542-5be4-440b-bf26-ab96a897dde4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train))\n",
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "MoSh5C8VTnX6",
    "outputId": "319e9226-3668-4f3a-8c55-e3c89495b317"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "for i in range(36):\n",
    "    plt.subplot(6, 6, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(data_train[i][0].numpy().reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Digit: {}\".format(data_train[i][1]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "y98rXL-5TzEw",
    "outputId": "8e8e178d-67d1-4c53-916e-da4c5c0935cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pixel Value Distribution')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(data_train[0][0].numpy().reshape(28,28), cmap='gray', interpolation='none')\n",
    "plt.title(\"Digit: {}\".format(data_train[0][1]))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2,1,2)\n",
    "plt.hist(data_train[0][0].numpy().reshape(784))\n",
    "plt.title(\"Pixel Value Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KtLoec1GUCrP"
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hwOqm3byUGbP"
   },
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=data_train,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=data_test,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j4ghi99jUbOT"
   },
   "outputs": [],
   "source": [
    "mlp = nn.Sequential(nn.Flatten(),\n",
    "           nn.Linear(784,512),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(p=0.2),\n",
    "           nn.Linear(512,512),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(p=0.2),\n",
    "           nn.Linear(512,512), \n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(p=0.2),\n",
    "           nn.Linear(512,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrHW_n27Zkpq",
    "outputId": "88cc8ec3-0692-4495-fbf2-570f6a5c5095",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "Loss is:2.3005, Train_accuracy is 12.8950%, Test_accuracy is 14.1800%\n",
      "================================================================================\n",
      "Epoch 2/2000\n",
      "Loss is:2.2988, Train_accuracy is 14.9500%, Test_accuracy is 16.3100%\n",
      "================================================================================\n",
      "Epoch 3/2000\n",
      "Loss is:2.2970, Train_accuracy is 16.8483%, Test_accuracy is 18.4700%\n",
      "================================================================================\n",
      "Epoch 4/2000\n",
      "Loss is:2.2950, Train_accuracy is 18.7383%, Test_accuracy is 19.9600%\n",
      "================================================================================\n",
      "Epoch 5/2000\n",
      "Loss is:2.2932, Train_accuracy is 20.3867%, Test_accuracy is 21.2600%\n",
      "================================================================================\n",
      "Epoch 6/2000\n",
      "Loss is:2.2911, Train_accuracy is 22.2300%, Test_accuracy is 22.8700%\n",
      "================================================================================\n",
      "Epoch 7/2000\n",
      "Loss is:2.2891, Train_accuracy is 24.0033%, Test_accuracy is 26.0900%\n",
      "================================================================================\n",
      "Epoch 8/2000\n",
      "Loss is:2.2871, Train_accuracy is 26.3650%, Test_accuracy is 28.4200%\n",
      "================================================================================\n",
      "Epoch 9/2000\n",
      "Loss is:2.2847, Train_accuracy is 29.2717%, Test_accuracy is 32.2500%\n",
      "================================================================================\n",
      "Epoch 10/2000\n",
      "Loss is:2.2822, Train_accuracy is 32.4017%, Test_accuracy is 34.1600%\n",
      "================================================================================\n",
      "Epoch 11/2000\n",
      "Loss is:2.2797, Train_accuracy is 35.1117%, Test_accuracy is 37.3000%\n",
      "================================================================================\n",
      "Epoch 12/2000\n",
      "Loss is:2.2768, Train_accuracy is 37.6383%, Test_accuracy is 39.0500%\n",
      "================================================================================\n",
      "Epoch 13/2000\n",
      "Loss is:2.2737, Train_accuracy is 40.4133%, Test_accuracy is 41.9700%\n",
      "================================================================================\n",
      "Epoch 14/2000\n",
      "Loss is:2.2703, Train_accuracy is 42.4133%, Test_accuracy is 44.4000%\n",
      "================================================================================\n",
      "Epoch 15/2000\n",
      "Loss is:2.2667, Train_accuracy is 44.2983%, Test_accuracy is 45.7100%\n",
      "================================================================================\n",
      "Epoch 16/2000\n",
      "Loss is:2.2626, Train_accuracy is 46.1117%, Test_accuracy is 46.9900%\n",
      "================================================================================\n",
      "Epoch 17/2000\n",
      "Loss is:2.2583, Train_accuracy is 47.4267%, Test_accuracy is 48.9900%\n",
      "================================================================================\n",
      "Epoch 18/2000\n",
      "Loss is:2.2534, Train_accuracy is 48.6000%, Test_accuracy is 50.3000%\n",
      "================================================================================\n",
      "Epoch 19/2000\n",
      "Loss is:2.2478, Train_accuracy is 49.7617%, Test_accuracy is 50.8700%\n",
      "================================================================================\n",
      "Epoch 20/2000\n",
      "Loss is:2.2416, Train_accuracy is 50.7950%, Test_accuracy is 51.3400%\n",
      "================================================================================\n",
      "Epoch 21/2000\n",
      "Loss is:2.2345, Train_accuracy is 51.2367%, Test_accuracy is 51.2300%\n",
      "================================================================================\n",
      "Epoch 22/2000\n",
      "Loss is:2.2266, Train_accuracy is 51.8917%, Test_accuracy is 51.8200%\n",
      "================================================================================\n",
      "Epoch 23/2000\n",
      "Loss is:2.2174, Train_accuracy is 52.1167%, Test_accuracy is 52.5900%\n",
      "================================================================================\n",
      "Epoch 24/2000\n",
      "Loss is:2.2073, Train_accuracy is 52.6733%, Test_accuracy is 52.8300%\n",
      "================================================================================\n",
      "Epoch 25/2000\n",
      "Loss is:2.1956, Train_accuracy is 52.5650%, Test_accuracy is 52.3000%\n",
      "================================================================================\n",
      "Epoch 26/2000\n",
      "Loss is:2.1820, Train_accuracy is 52.8650%, Test_accuracy is 52.9800%\n",
      "================================================================================\n",
      "Epoch 27/2000\n",
      "Loss is:2.1667, Train_accuracy is 52.7333%, Test_accuracy is 52.8900%\n",
      "================================================================================\n",
      "Epoch 28/2000\n",
      "Loss is:2.1484, Train_accuracy is 53.2900%, Test_accuracy is 53.2800%\n",
      "================================================================================\n",
      "Epoch 29/2000\n",
      "Loss is:2.1272, Train_accuracy is 53.4083%, Test_accuracy is 53.5300%\n",
      "================================================================================\n",
      "Epoch 30/2000\n",
      "Loss is:2.1029, Train_accuracy is 53.8817%, Test_accuracy is 54.0100%\n",
      "================================================================================\n",
      "Epoch 31/2000\n",
      "Loss is:2.0747, Train_accuracy is 54.0033%, Test_accuracy is 54.3400%\n",
      "================================================================================\n",
      "Epoch 32/2000\n",
      "Loss is:2.0417, Train_accuracy is 54.9567%, Test_accuracy is 54.9800%\n",
      "================================================================================\n",
      "Epoch 33/2000\n",
      "Loss is:2.0046, Train_accuracy is 55.6817%, Test_accuracy is 55.9500%\n",
      "================================================================================\n",
      "Epoch 34/2000\n",
      "Loss is:1.9611, Train_accuracy is 56.6183%, Test_accuracy is 56.7700%\n",
      "================================================================================\n",
      "Epoch 35/2000\n",
      "Loss is:1.9119, Train_accuracy is 57.6717%, Test_accuracy is 57.6200%\n",
      "================================================================================\n",
      "Epoch 36/2000\n",
      "Loss is:1.8573, Train_accuracy is 59.0317%, Test_accuracy is 59.6200%\n",
      "================================================================================\n",
      "Epoch 37/2000\n",
      "Loss is:1.7958, Train_accuracy is 60.0750%, Test_accuracy is 60.4900%\n",
      "================================================================================\n",
      "Epoch 38/2000\n",
      "Loss is:1.7295, Train_accuracy is 61.5283%, Test_accuracy is 61.9700%\n",
      "================================================================================\n",
      "Epoch 39/2000\n",
      "Loss is:1.6574, Train_accuracy is 62.6450%, Test_accuracy is 63.7900%\n",
      "================================================================================\n",
      "Epoch 40/2000\n",
      "Loss is:1.5825, Train_accuracy is 63.5100%, Test_accuracy is 64.0000%\n",
      "================================================================================\n",
      "Epoch 41/2000\n",
      "Loss is:1.5041, Train_accuracy is 64.4050%, Test_accuracy is 65.6700%\n",
      "================================================================================\n",
      "Epoch 42/2000\n",
      "Loss is:1.4253, Train_accuracy is 65.9650%, Test_accuracy is 66.3600%\n",
      "================================================================================\n",
      "Epoch 43/2000\n",
      "Loss is:1.3522, Train_accuracy is 66.7550%, Test_accuracy is 67.6000%\n",
      "================================================================================\n",
      "Epoch 44/2000\n",
      "Loss is:1.2797, Train_accuracy is 67.8767%, Test_accuracy is 68.6300%\n",
      "================================================================================\n",
      "Epoch 45/2000\n",
      "Loss is:1.2144, Train_accuracy is 68.6850%, Test_accuracy is 69.6400%\n",
      "================================================================================\n",
      "Epoch 46/2000\n",
      "Loss is:1.1545, Train_accuracy is 69.7000%, Test_accuracy is 70.7000%\n",
      "================================================================================\n",
      "Epoch 47/2000\n",
      "Loss is:1.1025, Train_accuracy is 70.4967%, Test_accuracy is 71.3400%\n",
      "================================================================================\n",
      "Epoch 48/2000\n",
      "Loss is:1.0528, Train_accuracy is 71.1617%, Test_accuracy is 72.4000%\n",
      "================================================================================\n",
      "Epoch 49/2000\n",
      "Loss is:1.0092, Train_accuracy is 72.0700%, Test_accuracy is 72.8300%\n",
      "================================================================================\n",
      "Epoch 50/2000\n",
      "Loss is:0.9704, Train_accuracy is 72.7450%, Test_accuracy is 73.6700%\n",
      "================================================================================\n",
      "Epoch 51/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.9361, Train_accuracy is 73.3700%, Test_accuracy is 74.1200%\n",
      "================================================================================\n",
      "Epoch 52/2000\n",
      "Loss is:0.9073, Train_accuracy is 73.9333%, Test_accuracy is 74.9700%\n",
      "================================================================================\n",
      "Epoch 53/2000\n",
      "Loss is:0.8786, Train_accuracy is 74.5217%, Test_accuracy is 75.1300%\n",
      "================================================================================\n",
      "Epoch 54/2000\n",
      "Loss is:0.8539, Train_accuracy is 74.9200%, Test_accuracy is 75.6500%\n",
      "================================================================================\n",
      "Epoch 55/2000\n",
      "Loss is:0.8304, Train_accuracy is 75.5583%, Test_accuracy is 76.3800%\n",
      "================================================================================\n",
      "Epoch 56/2000\n",
      "Loss is:0.8098, Train_accuracy is 76.0300%, Test_accuracy is 76.9200%\n",
      "================================================================================\n",
      "Epoch 57/2000\n",
      "Loss is:0.7895, Train_accuracy is 76.4217%, Test_accuracy is 77.6300%\n",
      "================================================================================\n",
      "Epoch 58/2000\n",
      "Loss is:0.7734, Train_accuracy is 76.8550%, Test_accuracy is 77.3300%\n",
      "================================================================================\n",
      "Epoch 59/2000\n",
      "Loss is:0.7581, Train_accuracy is 77.2650%, Test_accuracy is 78.5100%\n",
      "================================================================================\n",
      "Epoch 60/2000\n",
      "Loss is:0.7432, Train_accuracy is 77.6183%, Test_accuracy is 78.5400%\n",
      "================================================================================\n",
      "Epoch 61/2000\n",
      "Loss is:0.7283, Train_accuracy is 78.0167%, Test_accuracy is 79.3000%\n",
      "================================================================================\n",
      "Epoch 62/2000\n",
      "Loss is:0.7169, Train_accuracy is 78.4150%, Test_accuracy is 79.1600%\n",
      "================================================================================\n",
      "Epoch 63/2000\n",
      "Loss is:0.7021, Train_accuracy is 78.6483%, Test_accuracy is 79.3000%\n",
      "================================================================================\n",
      "Epoch 64/2000\n",
      "Loss is:0.6919, Train_accuracy is 78.8283%, Test_accuracy is 79.8400%\n",
      "================================================================================\n",
      "Epoch 65/2000\n",
      "Loss is:0.6806, Train_accuracy is 79.4117%, Test_accuracy is 80.0200%\n",
      "================================================================================\n",
      "Epoch 66/2000\n",
      "Loss is:0.6666, Train_accuracy is 79.7883%, Test_accuracy is 80.1900%\n",
      "================================================================================\n",
      "Epoch 67/2000\n",
      "Loss is:0.6591, Train_accuracy is 80.0183%, Test_accuracy is 80.7400%\n",
      "================================================================================\n",
      "Epoch 68/2000\n",
      "Loss is:0.6483, Train_accuracy is 80.2250%, Test_accuracy is 80.6600%\n",
      "================================================================================\n",
      "Epoch 69/2000\n",
      "Loss is:0.6399, Train_accuracy is 80.5883%, Test_accuracy is 81.1700%\n",
      "================================================================================\n",
      "Epoch 70/2000\n",
      "Loss is:0.6314, Train_accuracy is 80.8183%, Test_accuracy is 81.1900%\n",
      "================================================================================\n",
      "Epoch 71/2000\n",
      "Loss is:0.6245, Train_accuracy is 80.9350%, Test_accuracy is 81.9000%\n",
      "================================================================================\n",
      "Epoch 72/2000\n",
      "Loss is:0.6181, Train_accuracy is 81.3250%, Test_accuracy is 81.7600%\n",
      "================================================================================\n",
      "Epoch 73/2000\n",
      "Loss is:0.6101, Train_accuracy is 81.3917%, Test_accuracy is 82.1600%\n",
      "================================================================================\n",
      "Epoch 74/2000\n",
      "Loss is:0.6031, Train_accuracy is 81.9617%, Test_accuracy is 82.4000%\n",
      "================================================================================\n",
      "Epoch 75/2000\n",
      "Loss is:0.5947, Train_accuracy is 81.8433%, Test_accuracy is 82.2000%\n",
      "================================================================================\n",
      "Epoch 76/2000\n",
      "Loss is:0.5882, Train_accuracy is 82.1150%, Test_accuracy is 82.8500%\n",
      "================================================================================\n",
      "Epoch 77/2000\n",
      "Loss is:0.5849, Train_accuracy is 82.3083%, Test_accuracy is 82.9700%\n",
      "================================================================================\n",
      "Epoch 78/2000\n",
      "Loss is:0.5783, Train_accuracy is 82.4283%, Test_accuracy is 82.8000%\n",
      "================================================================================\n",
      "Epoch 79/2000\n",
      "Loss is:0.5693, Train_accuracy is 82.6417%, Test_accuracy is 83.3800%\n",
      "================================================================================\n",
      "Epoch 80/2000\n",
      "Loss is:0.5669, Train_accuracy is 82.8850%, Test_accuracy is 83.6700%\n",
      "================================================================================\n",
      "Epoch 81/2000\n",
      "Loss is:0.5614, Train_accuracy is 83.0400%, Test_accuracy is 83.8000%\n",
      "================================================================================\n",
      "Epoch 82/2000\n",
      "Loss is:0.5559, Train_accuracy is 83.3617%, Test_accuracy is 83.2700%\n",
      "================================================================================\n",
      "Epoch 83/2000\n",
      "Loss is:0.5491, Train_accuracy is 83.4517%, Test_accuracy is 83.7800%\n",
      "================================================================================\n",
      "Epoch 84/2000\n",
      "Loss is:0.5466, Train_accuracy is 83.4600%, Test_accuracy is 83.6600%\n",
      "================================================================================\n",
      "Epoch 85/2000\n",
      "Loss is:0.5415, Train_accuracy is 83.7633%, Test_accuracy is 84.7100%\n",
      "================================================================================\n",
      "Epoch 86/2000\n",
      "Loss is:0.5387, Train_accuracy is 83.8100%, Test_accuracy is 84.5900%\n",
      "================================================================================\n",
      "Epoch 87/2000\n",
      "Loss is:0.5325, Train_accuracy is 84.0567%, Test_accuracy is 84.1300%\n",
      "================================================================================\n",
      "Epoch 88/2000\n",
      "Loss is:0.5302, Train_accuracy is 84.0767%, Test_accuracy is 84.5400%\n",
      "================================================================================\n",
      "Epoch 89/2000\n",
      "Loss is:0.5293, Train_accuracy is 84.1083%, Test_accuracy is 84.6600%\n",
      "================================================================================\n",
      "Epoch 90/2000\n",
      "Loss is:0.5228, Train_accuracy is 84.3083%, Test_accuracy is 84.8900%\n",
      "================================================================================\n",
      "Epoch 91/2000\n",
      "Loss is:0.5173, Train_accuracy is 84.5650%, Test_accuracy is 85.0300%\n",
      "================================================================================\n",
      "Epoch 92/2000\n",
      "Loss is:0.5120, Train_accuracy is 84.7933%, Test_accuracy is 85.2300%\n",
      "================================================================================\n",
      "Epoch 93/2000\n",
      "Loss is:0.5122, Train_accuracy is 84.7083%, Test_accuracy is 85.1600%\n",
      "================================================================================\n",
      "Epoch 94/2000\n",
      "Loss is:0.5057, Train_accuracy is 84.8167%, Test_accuracy is 85.1100%\n",
      "================================================================================\n",
      "Epoch 95/2000\n",
      "Loss is:0.5031, Train_accuracy is 84.8767%, Test_accuracy is 85.3100%\n",
      "================================================================================\n",
      "Epoch 96/2000\n",
      "Loss is:0.4977, Train_accuracy is 85.2250%, Test_accuracy is 85.6200%\n",
      "================================================================================\n",
      "Epoch 97/2000\n",
      "Loss is:0.4948, Train_accuracy is 85.1233%, Test_accuracy is 85.6300%\n",
      "================================================================================\n",
      "Epoch 98/2000\n",
      "Loss is:0.4930, Train_accuracy is 85.5017%, Test_accuracy is 85.8900%\n",
      "================================================================================\n",
      "Epoch 99/2000\n",
      "Loss is:0.4878, Train_accuracy is 85.5350%, Test_accuracy is 85.9000%\n",
      "================================================================================\n",
      "Epoch 100/2000\n",
      "Loss is:0.4852, Train_accuracy is 85.4850%, Test_accuracy is 85.7500%\n",
      "================================================================================\n",
      "Epoch 101/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.4845, Train_accuracy is 85.4533%, Test_accuracy is 85.6800%\n",
      "================================================================================\n",
      "Epoch 102/2000\n",
      "Loss is:0.4805, Train_accuracy is 85.6550%, Test_accuracy is 86.1000%\n",
      "================================================================================\n",
      "Epoch 103/2000\n",
      "Loss is:0.4782, Train_accuracy is 85.7883%, Test_accuracy is 86.0300%\n",
      "================================================================================\n",
      "Epoch 104/2000\n",
      "Loss is:0.4734, Train_accuracy is 85.8250%, Test_accuracy is 86.2100%\n",
      "================================================================================\n",
      "Epoch 105/2000\n",
      "Loss is:0.4707, Train_accuracy is 86.0700%, Test_accuracy is 85.7600%\n",
      "================================================================================\n",
      "Epoch 106/2000\n",
      "Loss is:0.4694, Train_accuracy is 86.2167%, Test_accuracy is 86.4600%\n",
      "================================================================================\n",
      "Epoch 107/2000\n",
      "Loss is:0.4662, Train_accuracy is 86.1167%, Test_accuracy is 86.6700%\n",
      "================================================================================\n",
      "Epoch 108/2000\n",
      "Loss is:0.4638, Train_accuracy is 86.2467%, Test_accuracy is 86.5600%\n",
      "================================================================================\n",
      "Epoch 109/2000\n",
      "Loss is:0.4590, Train_accuracy is 86.4250%, Test_accuracy is 86.3500%\n",
      "================================================================================\n",
      "Epoch 110/2000\n",
      "Loss is:0.4569, Train_accuracy is 86.5400%, Test_accuracy is 87.0000%\n",
      "================================================================================\n",
      "Epoch 111/2000\n",
      "Loss is:0.4539, Train_accuracy is 86.4967%, Test_accuracy is 87.0400%\n",
      "================================================================================\n",
      "Epoch 112/2000\n",
      "Loss is:0.4530, Train_accuracy is 86.6533%, Test_accuracy is 86.9800%\n",
      "================================================================================\n",
      "Epoch 113/2000\n",
      "Loss is:0.4504, Train_accuracy is 86.7000%, Test_accuracy is 87.1200%\n",
      "================================================================================\n",
      "Epoch 114/2000\n",
      "Loss is:0.4481, Train_accuracy is 86.8750%, Test_accuracy is 86.8300%\n",
      "================================================================================\n",
      "Epoch 115/2000\n",
      "Loss is:0.4463, Train_accuracy is 86.7417%, Test_accuracy is 87.1900%\n",
      "================================================================================\n",
      "Epoch 116/2000\n",
      "Loss is:0.4447, Train_accuracy is 86.9633%, Test_accuracy is 87.3600%\n",
      "================================================================================\n",
      "Epoch 117/2000\n",
      "Loss is:0.4410, Train_accuracy is 86.9883%, Test_accuracy is 87.1300%\n",
      "================================================================================\n",
      "Epoch 118/2000\n",
      "Loss is:0.4392, Train_accuracy is 87.1167%, Test_accuracy is 87.1200%\n",
      "================================================================================\n",
      "Epoch 119/2000\n",
      "Loss is:0.4371, Train_accuracy is 87.1100%, Test_accuracy is 87.6900%\n",
      "================================================================================\n",
      "Epoch 120/2000\n",
      "Loss is:0.4365, Train_accuracy is 87.1700%, Test_accuracy is 87.5300%\n",
      "================================================================================\n",
      "Epoch 121/2000\n",
      "Loss is:0.4304, Train_accuracy is 87.3317%, Test_accuracy is 87.4500%\n",
      "================================================================================\n",
      "Epoch 122/2000\n",
      "Loss is:0.4305, Train_accuracy is 87.3867%, Test_accuracy is 87.4000%\n",
      "================================================================================\n",
      "Epoch 123/2000\n",
      "Loss is:0.4301, Train_accuracy is 87.4267%, Test_accuracy is 87.9300%\n",
      "================================================================================\n",
      "Epoch 124/2000\n",
      "Loss is:0.4276, Train_accuracy is 87.4633%, Test_accuracy is 87.9000%\n",
      "================================================================================\n",
      "Epoch 125/2000\n",
      "Loss is:0.4241, Train_accuracy is 87.6417%, Test_accuracy is 88.0500%\n",
      "================================================================================\n",
      "Epoch 126/2000\n",
      "Loss is:0.4211, Train_accuracy is 87.6533%, Test_accuracy is 88.2000%\n",
      "================================================================================\n",
      "Epoch 127/2000\n",
      "Loss is:0.4194, Train_accuracy is 87.5650%, Test_accuracy is 88.3300%\n",
      "================================================================================\n",
      "Epoch 128/2000\n",
      "Loss is:0.4187, Train_accuracy is 87.7517%, Test_accuracy is 87.9500%\n",
      "================================================================================\n",
      "Epoch 129/2000\n",
      "Loss is:0.4166, Train_accuracy is 87.6917%, Test_accuracy is 88.0200%\n",
      "================================================================================\n",
      "Epoch 130/2000\n",
      "Loss is:0.4168, Train_accuracy is 87.8567%, Test_accuracy is 88.4800%\n",
      "================================================================================\n",
      "Epoch 131/2000\n",
      "Loss is:0.4137, Train_accuracy is 87.9567%, Test_accuracy is 87.9800%\n",
      "================================================================================\n",
      "Epoch 132/2000\n",
      "Loss is:0.4091, Train_accuracy is 88.0383%, Test_accuracy is 88.2000%\n",
      "================================================================================\n",
      "Epoch 133/2000\n",
      "Loss is:0.4074, Train_accuracy is 88.1617%, Test_accuracy is 88.1600%\n",
      "================================================================================\n",
      "Epoch 134/2000\n",
      "Loss is:0.4069, Train_accuracy is 88.0767%, Test_accuracy is 88.3100%\n",
      "================================================================================\n",
      "Epoch 135/2000\n",
      "Loss is:0.4056, Train_accuracy is 88.1450%, Test_accuracy is 88.5100%\n",
      "================================================================================\n",
      "Epoch 136/2000\n",
      "Loss is:0.4028, Train_accuracy is 88.2967%, Test_accuracy is 88.1500%\n",
      "================================================================================\n",
      "Epoch 137/2000\n",
      "Loss is:0.4023, Train_accuracy is 88.2017%, Test_accuracy is 88.1300%\n",
      "================================================================================\n",
      "Epoch 138/2000\n",
      "Loss is:0.3972, Train_accuracy is 88.3583%, Test_accuracy is 88.7000%\n",
      "================================================================================\n",
      "Epoch 139/2000\n",
      "Loss is:0.3981, Train_accuracy is 88.3483%, Test_accuracy is 88.4500%\n",
      "================================================================================\n",
      "Epoch 140/2000\n",
      "Loss is:0.3977, Train_accuracy is 88.3867%, Test_accuracy is 88.7600%\n",
      "================================================================================\n",
      "Epoch 141/2000\n",
      "Loss is:0.3934, Train_accuracy is 88.5133%, Test_accuracy is 88.8500%\n",
      "================================================================================\n",
      "Epoch 142/2000\n",
      "Loss is:0.3957, Train_accuracy is 88.3333%, Test_accuracy is 88.8200%\n",
      "================================================================================\n",
      "Epoch 143/2000\n",
      "Loss is:0.3915, Train_accuracy is 88.6200%, Test_accuracy is 88.8600%\n",
      "================================================================================\n",
      "Epoch 144/2000\n",
      "Loss is:0.3896, Train_accuracy is 88.5767%, Test_accuracy is 88.7400%\n",
      "================================================================================\n",
      "Epoch 145/2000\n",
      "Loss is:0.3886, Train_accuracy is 88.6550%, Test_accuracy is 88.5400%\n",
      "================================================================================\n",
      "Epoch 146/2000\n",
      "Loss is:0.3872, Train_accuracy is 88.6167%, Test_accuracy is 89.1200%\n",
      "================================================================================\n",
      "Epoch 147/2000\n",
      "Loss is:0.3861, Train_accuracy is 88.8067%, Test_accuracy is 89.0400%\n",
      "================================================================================\n",
      "Epoch 148/2000\n",
      "Loss is:0.3838, Train_accuracy is 88.7100%, Test_accuracy is 88.8200%\n",
      "================================================================================\n",
      "Epoch 149/2000\n",
      "Loss is:0.3832, Train_accuracy is 88.7950%, Test_accuracy is 88.9400%\n",
      "================================================================================\n",
      "Epoch 150/2000\n",
      "Loss is:0.3800, Train_accuracy is 88.9567%, Test_accuracy is 89.3300%\n",
      "================================================================================\n",
      "Epoch 151/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.3807, Train_accuracy is 88.9117%, Test_accuracy is 89.1800%\n",
      "================================================================================\n",
      "Epoch 152/2000\n",
      "Loss is:0.3794, Train_accuracy is 88.9833%, Test_accuracy is 89.2400%\n",
      "================================================================================\n",
      "Epoch 153/2000\n",
      "Loss is:0.3778, Train_accuracy is 88.9650%, Test_accuracy is 89.2300%\n",
      "================================================================================\n",
      "Epoch 154/2000\n",
      "Loss is:0.3745, Train_accuracy is 88.9650%, Test_accuracy is 89.1800%\n",
      "================================================================================\n",
      "Epoch 155/2000\n",
      "Loss is:0.3745, Train_accuracy is 89.1783%, Test_accuracy is 89.2100%\n",
      "================================================================================\n",
      "Epoch 156/2000\n",
      "Loss is:0.3738, Train_accuracy is 89.2067%, Test_accuracy is 89.3800%\n",
      "================================================================================\n",
      "Epoch 157/2000\n",
      "Loss is:0.3699, Train_accuracy is 89.3167%, Test_accuracy is 89.4900%\n",
      "================================================================================\n",
      "Epoch 158/2000\n",
      "Loss is:0.3707, Train_accuracy is 89.2083%, Test_accuracy is 89.6000%\n",
      "================================================================================\n",
      "Epoch 159/2000\n",
      "Loss is:0.3672, Train_accuracy is 89.3550%, Test_accuracy is 89.5200%\n",
      "================================================================================\n",
      "Epoch 160/2000\n",
      "Loss is:0.3682, Train_accuracy is 89.2950%, Test_accuracy is 89.6000%\n",
      "================================================================================\n",
      "Epoch 161/2000\n",
      "Loss is:0.3652, Train_accuracy is 89.4133%, Test_accuracy is 89.4900%\n",
      "================================================================================\n",
      "Epoch 162/2000\n",
      "Loss is:0.3648, Train_accuracy is 89.2950%, Test_accuracy is 89.4500%\n",
      "================================================================================\n",
      "Epoch 163/2000\n",
      "Loss is:0.3645, Train_accuracy is 89.5200%, Test_accuracy is 89.5800%\n",
      "================================================================================\n",
      "Epoch 164/2000\n",
      "Loss is:0.3604, Train_accuracy is 89.4117%, Test_accuracy is 89.5500%\n",
      "================================================================================\n",
      "Epoch 165/2000\n",
      "Loss is:0.3604, Train_accuracy is 89.5000%, Test_accuracy is 89.8100%\n",
      "================================================================================\n",
      "Epoch 166/2000\n",
      "Loss is:0.3587, Train_accuracy is 89.4600%, Test_accuracy is 89.5500%\n",
      "================================================================================\n",
      "Epoch 167/2000\n",
      "Loss is:0.3579, Train_accuracy is 89.4483%, Test_accuracy is 89.4600%\n",
      "================================================================================\n",
      "Epoch 168/2000\n",
      "Loss is:0.3573, Train_accuracy is 89.5933%, Test_accuracy is 89.8200%\n",
      "================================================================================\n",
      "Epoch 169/2000\n",
      "Loss is:0.3555, Train_accuracy is 89.7500%, Test_accuracy is 89.6800%\n",
      "================================================================================\n",
      "Epoch 170/2000\n",
      "Loss is:0.3555, Train_accuracy is 89.7167%, Test_accuracy is 89.9500%\n",
      "================================================================================\n",
      "Epoch 171/2000\n",
      "Loss is:0.3517, Train_accuracy is 89.7833%, Test_accuracy is 89.8400%\n",
      "================================================================================\n",
      "Epoch 172/2000\n",
      "Loss is:0.3531, Train_accuracy is 89.7617%, Test_accuracy is 90.0800%\n",
      "================================================================================\n",
      "Epoch 173/2000\n",
      "Loss is:0.3536, Train_accuracy is 89.6033%, Test_accuracy is 89.9800%\n",
      "================================================================================\n",
      "Epoch 174/2000\n",
      "Loss is:0.3484, Train_accuracy is 89.8633%, Test_accuracy is 90.1700%\n",
      "================================================================================\n",
      "Epoch 175/2000\n",
      "Loss is:0.3490, Train_accuracy is 89.8317%, Test_accuracy is 90.2800%\n",
      "================================================================================\n",
      "Epoch 176/2000\n",
      "Loss is:0.3454, Train_accuracy is 90.0683%, Test_accuracy is 89.7300%\n",
      "================================================================================\n",
      "Epoch 177/2000\n",
      "Loss is:0.3458, Train_accuracy is 89.9533%, Test_accuracy is 90.3700%\n",
      "================================================================================\n",
      "Epoch 178/2000\n",
      "Loss is:0.3449, Train_accuracy is 90.0550%, Test_accuracy is 90.4800%\n",
      "================================================================================\n",
      "Epoch 179/2000\n",
      "Loss is:0.3449, Train_accuracy is 89.8550%, Test_accuracy is 90.3200%\n",
      "================================================================================\n",
      "Epoch 180/2000\n",
      "Loss is:0.3433, Train_accuracy is 90.0400%, Test_accuracy is 90.3800%\n",
      "================================================================================\n",
      "Epoch 181/2000\n",
      "Loss is:0.3410, Train_accuracy is 90.0517%, Test_accuracy is 90.0200%\n",
      "================================================================================\n",
      "Epoch 182/2000\n",
      "Loss is:0.3417, Train_accuracy is 89.9983%, Test_accuracy is 90.0200%\n",
      "================================================================================\n",
      "Epoch 183/2000\n",
      "Loss is:0.3395, Train_accuracy is 90.0467%, Test_accuracy is 90.4200%\n",
      "================================================================================\n",
      "Epoch 184/2000\n",
      "Loss is:0.3370, Train_accuracy is 90.2117%, Test_accuracy is 90.5200%\n",
      "================================================================================\n",
      "Epoch 185/2000\n",
      "Loss is:0.3377, Train_accuracy is 90.1883%, Test_accuracy is 90.8100%\n",
      "================================================================================\n",
      "Epoch 186/2000\n",
      "Loss is:0.3370, Train_accuracy is 90.2283%, Test_accuracy is 90.3000%\n",
      "================================================================================\n",
      "Epoch 187/2000\n",
      "Loss is:0.3363, Train_accuracy is 90.2700%, Test_accuracy is 90.2800%\n",
      "================================================================================\n",
      "Epoch 188/2000\n",
      "Loss is:0.3340, Train_accuracy is 90.2167%, Test_accuracy is 90.3300%\n",
      "================================================================================\n",
      "Epoch 189/2000\n",
      "Loss is:0.3325, Train_accuracy is 90.3617%, Test_accuracy is 90.2400%\n",
      "================================================================================\n",
      "Epoch 190/2000\n",
      "Loss is:0.3311, Train_accuracy is 90.4367%, Test_accuracy is 90.5900%\n",
      "================================================================================\n",
      "Epoch 191/2000\n",
      "Loss is:0.3301, Train_accuracy is 90.3783%, Test_accuracy is 90.5200%\n",
      "================================================================================\n",
      "Epoch 192/2000\n",
      "Loss is:0.3289, Train_accuracy is 90.4733%, Test_accuracy is 90.4800%\n",
      "================================================================================\n",
      "Epoch 193/2000\n",
      "Loss is:0.3291, Train_accuracy is 90.5383%, Test_accuracy is 90.6800%\n",
      "================================================================================\n",
      "Epoch 194/2000\n",
      "Loss is:0.3262, Train_accuracy is 90.4750%, Test_accuracy is 90.6600%\n",
      "================================================================================\n",
      "Epoch 195/2000\n",
      "Loss is:0.3269, Train_accuracy is 90.5350%, Test_accuracy is 90.5300%\n",
      "================================================================================\n",
      "Epoch 196/2000\n",
      "Loss is:0.3242, Train_accuracy is 90.6017%, Test_accuracy is 90.7700%\n",
      "================================================================================\n",
      "Epoch 197/2000\n",
      "Loss is:0.3239, Train_accuracy is 90.7533%, Test_accuracy is 90.6700%\n",
      "================================================================================\n",
      "Epoch 198/2000\n",
      "Loss is:0.3234, Train_accuracy is 90.6483%, Test_accuracy is 90.8200%\n",
      "================================================================================\n",
      "Epoch 199/2000\n",
      "Loss is:0.3216, Train_accuracy is 90.6967%, Test_accuracy is 90.6600%\n",
      "================================================================================\n",
      "Epoch 200/2000\n",
      "Loss is:0.3202, Train_accuracy is 90.7033%, Test_accuracy is 90.9900%\n",
      "================================================================================\n",
      "Epoch 201/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.3193, Train_accuracy is 90.6433%, Test_accuracy is 90.6600%\n",
      "================================================================================\n",
      "Epoch 202/2000\n",
      "Loss is:0.3199, Train_accuracy is 90.7283%, Test_accuracy is 90.9200%\n",
      "================================================================================\n",
      "Epoch 203/2000\n",
      "Loss is:0.3167, Train_accuracy is 90.7333%, Test_accuracy is 91.0700%\n",
      "================================================================================\n",
      "Epoch 204/2000\n",
      "Loss is:0.3190, Train_accuracy is 90.6267%, Test_accuracy is 90.8800%\n",
      "================================================================================\n",
      "Epoch 205/2000\n",
      "Loss is:0.3158, Train_accuracy is 90.8567%, Test_accuracy is 90.9800%\n",
      "================================================================================\n",
      "Epoch 206/2000\n",
      "Loss is:0.3161, Train_accuracy is 90.7833%, Test_accuracy is 91.1700%\n",
      "================================================================================\n",
      "Epoch 207/2000\n",
      "Loss is:0.3131, Train_accuracy is 90.9033%, Test_accuracy is 90.9300%\n",
      "================================================================================\n",
      "Epoch 208/2000\n",
      "Loss is:0.3116, Train_accuracy is 90.8550%, Test_accuracy is 91.1200%\n",
      "================================================================================\n",
      "Epoch 209/2000\n",
      "Loss is:0.3110, Train_accuracy is 90.9817%, Test_accuracy is 91.1200%\n",
      "================================================================================\n",
      "Epoch 210/2000\n",
      "Loss is:0.3112, Train_accuracy is 90.9733%, Test_accuracy is 90.9900%\n",
      "================================================================================\n",
      "Epoch 211/2000\n",
      "Loss is:0.3087, Train_accuracy is 91.0800%, Test_accuracy is 90.9600%\n",
      "================================================================================\n",
      "Epoch 212/2000\n",
      "Loss is:0.3090, Train_accuracy is 91.0350%, Test_accuracy is 91.3200%\n",
      "================================================================================\n",
      "Epoch 213/2000\n",
      "Loss is:0.3078, Train_accuracy is 91.0000%, Test_accuracy is 91.0800%\n",
      "================================================================================\n",
      "Epoch 214/2000\n",
      "Loss is:0.3054, Train_accuracy is 91.1683%, Test_accuracy is 91.1300%\n",
      "================================================================================\n",
      "Epoch 215/2000\n",
      "Loss is:0.3064, Train_accuracy is 91.1517%, Test_accuracy is 91.0200%\n",
      "================================================================================\n",
      "Epoch 216/2000\n",
      "Loss is:0.3058, Train_accuracy is 91.0650%, Test_accuracy is 91.1900%\n",
      "================================================================================\n",
      "Epoch 217/2000\n",
      "Loss is:0.3050, Train_accuracy is 91.1950%, Test_accuracy is 91.2300%\n",
      "================================================================================\n",
      "Epoch 218/2000\n",
      "Loss is:0.3050, Train_accuracy is 91.2183%, Test_accuracy is 91.3400%\n",
      "================================================================================\n",
      "Epoch 219/2000\n",
      "Loss is:0.3041, Train_accuracy is 91.1983%, Test_accuracy is 91.2600%\n",
      "================================================================================\n",
      "Epoch 220/2000\n",
      "Loss is:0.3011, Train_accuracy is 91.2550%, Test_accuracy is 91.0100%\n",
      "================================================================================\n",
      "Epoch 221/2000\n",
      "Loss is:0.3002, Train_accuracy is 91.2983%, Test_accuracy is 91.5400%\n",
      "================================================================================\n",
      "Epoch 222/2000\n",
      "Loss is:0.2994, Train_accuracy is 91.2600%, Test_accuracy is 91.4500%\n",
      "================================================================================\n",
      "Epoch 223/2000\n",
      "Loss is:0.2991, Train_accuracy is 91.3600%, Test_accuracy is 91.6100%\n",
      "================================================================================\n",
      "Epoch 224/2000\n",
      "Loss is:0.2970, Train_accuracy is 91.4517%, Test_accuracy is 91.3800%\n",
      "================================================================================\n",
      "Epoch 225/2000\n",
      "Loss is:0.2979, Train_accuracy is 91.3500%, Test_accuracy is 91.5600%\n",
      "================================================================================\n",
      "Epoch 226/2000\n",
      "Loss is:0.2953, Train_accuracy is 91.4450%, Test_accuracy is 91.6100%\n",
      "================================================================================\n",
      "Epoch 227/2000\n",
      "Loss is:0.2958, Train_accuracy is 91.4567%, Test_accuracy is 91.6000%\n",
      "================================================================================\n",
      "Epoch 228/2000\n",
      "Loss is:0.2926, Train_accuracy is 91.5567%, Test_accuracy is 91.5100%\n",
      "================================================================================\n",
      "Epoch 229/2000\n",
      "Loss is:0.2935, Train_accuracy is 91.5783%, Test_accuracy is 91.6900%\n",
      "================================================================================\n",
      "Epoch 230/2000\n",
      "Loss is:0.2916, Train_accuracy is 91.5900%, Test_accuracy is 91.5800%\n",
      "================================================================================\n",
      "Epoch 231/2000\n",
      "Loss is:0.2912, Train_accuracy is 91.5667%, Test_accuracy is 91.5000%\n",
      "================================================================================\n",
      "Epoch 232/2000\n",
      "Loss is:0.2907, Train_accuracy is 91.5017%, Test_accuracy is 91.8900%\n",
      "================================================================================\n",
      "Epoch 233/2000\n",
      "Loss is:0.2909, Train_accuracy is 91.5367%, Test_accuracy is 91.8700%\n",
      "================================================================================\n",
      "Epoch 234/2000\n",
      "Loss is:0.2888, Train_accuracy is 91.6200%, Test_accuracy is 91.5900%\n",
      "================================================================================\n",
      "Epoch 235/2000\n",
      "Loss is:0.2885, Train_accuracy is 91.5983%, Test_accuracy is 91.8000%\n",
      "================================================================================\n",
      "Epoch 236/2000\n",
      "Loss is:0.2878, Train_accuracy is 91.6533%, Test_accuracy is 91.6700%\n",
      "================================================================================\n",
      "Epoch 237/2000\n",
      "Loss is:0.2852, Train_accuracy is 91.7267%, Test_accuracy is 91.8200%\n",
      "================================================================================\n",
      "Epoch 238/2000\n",
      "Loss is:0.2857, Train_accuracy is 91.6883%, Test_accuracy is 91.8300%\n",
      "================================================================================\n",
      "Epoch 239/2000\n",
      "Loss is:0.2850, Train_accuracy is 91.7333%, Test_accuracy is 91.6000%\n",
      "================================================================================\n",
      "Epoch 240/2000\n",
      "Loss is:0.2851, Train_accuracy is 91.7583%, Test_accuracy is 91.9000%\n",
      "================================================================================\n",
      "Epoch 241/2000\n",
      "Loss is:0.2828, Train_accuracy is 91.7650%, Test_accuracy is 91.9500%\n",
      "================================================================================\n",
      "Epoch 242/2000\n",
      "Loss is:0.2822, Train_accuracy is 91.7367%, Test_accuracy is 91.7200%\n",
      "================================================================================\n",
      "Epoch 243/2000\n",
      "Loss is:0.2814, Train_accuracy is 91.8283%, Test_accuracy is 91.8600%\n",
      "================================================================================\n",
      "Epoch 244/2000\n",
      "Loss is:0.2821, Train_accuracy is 91.8683%, Test_accuracy is 91.9400%\n",
      "================================================================================\n",
      "Epoch 245/2000\n",
      "Loss is:0.2794, Train_accuracy is 91.8267%, Test_accuracy is 91.8200%\n",
      "================================================================================\n",
      "Epoch 246/2000\n",
      "Loss is:0.2781, Train_accuracy is 91.9433%, Test_accuracy is 91.9900%\n",
      "================================================================================\n",
      "Epoch 247/2000\n",
      "Loss is:0.2780, Train_accuracy is 91.9000%, Test_accuracy is 92.3300%\n",
      "================================================================================\n",
      "Epoch 248/2000\n",
      "Loss is:0.2777, Train_accuracy is 91.9600%, Test_accuracy is 92.0000%\n",
      "================================================================================\n",
      "Epoch 249/2000\n",
      "Loss is:0.2780, Train_accuracy is 91.8217%, Test_accuracy is 92.1200%\n",
      "================================================================================\n",
      "Epoch 250/2000\n",
      "Loss is:0.2772, Train_accuracy is 92.0017%, Test_accuracy is 92.0200%\n",
      "================================================================================\n",
      "Epoch 251/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.2747, Train_accuracy is 91.9167%, Test_accuracy is 92.1700%\n",
      "================================================================================\n",
      "Epoch 252/2000\n",
      "Loss is:0.2745, Train_accuracy is 92.0600%, Test_accuracy is 92.0300%\n",
      "================================================================================\n",
      "Epoch 253/2000\n",
      "Loss is:0.2723, Train_accuracy is 92.1200%, Test_accuracy is 91.9500%\n",
      "================================================================================\n",
      "Epoch 254/2000\n",
      "Loss is:0.2719, Train_accuracy is 92.1150%, Test_accuracy is 92.0800%\n",
      "================================================================================\n",
      "Epoch 255/2000\n",
      "Loss is:0.2721, Train_accuracy is 92.0783%, Test_accuracy is 92.3600%\n",
      "================================================================================\n",
      "Epoch 256/2000\n",
      "Loss is:0.2715, Train_accuracy is 92.0883%, Test_accuracy is 92.0500%\n",
      "================================================================================\n",
      "Epoch 257/2000\n",
      "Loss is:0.2699, Train_accuracy is 92.1867%, Test_accuracy is 92.4300%\n",
      "================================================================================\n",
      "Epoch 258/2000\n",
      "Loss is:0.2695, Train_accuracy is 92.1567%, Test_accuracy is 92.2400%\n",
      "================================================================================\n",
      "Epoch 259/2000\n",
      "Loss is:0.2672, Train_accuracy is 92.2850%, Test_accuracy is 92.2700%\n",
      "================================================================================\n",
      "Epoch 260/2000\n",
      "Loss is:0.2656, Train_accuracy is 92.2583%, Test_accuracy is 92.1100%\n",
      "================================================================================\n",
      "Epoch 261/2000\n",
      "Loss is:0.2678, Train_accuracy is 92.3050%, Test_accuracy is 92.5100%\n",
      "================================================================================\n",
      "Epoch 262/2000\n",
      "Loss is:0.2680, Train_accuracy is 92.1900%, Test_accuracy is 92.0300%\n",
      "================================================================================\n",
      "Epoch 263/2000\n",
      "Loss is:0.2663, Train_accuracy is 92.1600%, Test_accuracy is 92.0600%\n",
      "================================================================================\n",
      "Epoch 264/2000\n",
      "Loss is:0.2653, Train_accuracy is 92.2817%, Test_accuracy is 92.4800%\n",
      "================================================================================\n",
      "Epoch 265/2000\n",
      "Loss is:0.2630, Train_accuracy is 92.3133%, Test_accuracy is 92.4000%\n",
      "================================================================================\n",
      "Epoch 266/2000\n",
      "Loss is:0.2639, Train_accuracy is 92.2833%, Test_accuracy is 92.4400%\n",
      "================================================================================\n",
      "Epoch 267/2000\n",
      "Loss is:0.2641, Train_accuracy is 92.3433%, Test_accuracy is 92.4100%\n",
      "================================================================================\n",
      "Epoch 268/2000\n",
      "Loss is:0.2605, Train_accuracy is 92.4450%, Test_accuracy is 92.5600%\n",
      "================================================================================\n",
      "Epoch 269/2000\n",
      "Loss is:0.2616, Train_accuracy is 92.3833%, Test_accuracy is 92.5000%\n",
      "================================================================================\n",
      "Epoch 270/2000\n",
      "Loss is:0.2592, Train_accuracy is 92.4700%, Test_accuracy is 92.5300%\n",
      "================================================================================\n",
      "Epoch 271/2000\n",
      "Loss is:0.2596, Train_accuracy is 92.4650%, Test_accuracy is 92.5700%\n",
      "================================================================================\n",
      "Epoch 272/2000\n",
      "Loss is:0.2590, Train_accuracy is 92.5483%, Test_accuracy is 92.3100%\n",
      "================================================================================\n",
      "Epoch 273/2000\n",
      "Loss is:0.2572, Train_accuracy is 92.5267%, Test_accuracy is 92.4400%\n",
      "================================================================================\n",
      "Epoch 274/2000\n",
      "Loss is:0.2581, Train_accuracy is 92.5567%, Test_accuracy is 92.8300%\n",
      "================================================================================\n",
      "Epoch 275/2000\n",
      "Loss is:0.2564, Train_accuracy is 92.4733%, Test_accuracy is 92.4900%\n",
      "================================================================================\n",
      "Epoch 276/2000\n",
      "Loss is:0.2550, Train_accuracy is 92.5717%, Test_accuracy is 92.7100%\n",
      "================================================================================\n",
      "Epoch 277/2000\n",
      "Loss is:0.2563, Train_accuracy is 92.5650%, Test_accuracy is 92.5800%\n",
      "================================================================================\n",
      "Epoch 278/2000\n",
      "Loss is:0.2549, Train_accuracy is 92.6283%, Test_accuracy is 92.7400%\n",
      "================================================================================\n",
      "Epoch 279/2000\n",
      "Loss is:0.2536, Train_accuracy is 92.6783%, Test_accuracy is 92.4000%\n",
      "================================================================================\n",
      "Epoch 280/2000\n",
      "Loss is:0.2524, Train_accuracy is 92.6617%, Test_accuracy is 92.6500%\n",
      "================================================================================\n",
      "Epoch 281/2000\n",
      "Loss is:0.2517, Train_accuracy is 92.7267%, Test_accuracy is 92.6600%\n",
      "================================================================================\n",
      "Epoch 282/2000\n",
      "Loss is:0.2502, Train_accuracy is 92.7317%, Test_accuracy is 92.7100%\n",
      "================================================================================\n",
      "Epoch 283/2000\n",
      "Loss is:0.2512, Train_accuracy is 92.7867%, Test_accuracy is 92.7300%\n",
      "================================================================================\n",
      "Epoch 284/2000\n",
      "Loss is:0.2502, Train_accuracy is 92.7983%, Test_accuracy is 92.6600%\n",
      "================================================================================\n",
      "Epoch 285/2000\n",
      "Loss is:0.2489, Train_accuracy is 92.7383%, Test_accuracy is 92.6100%\n",
      "================================================================================\n",
      "Epoch 286/2000\n",
      "Loss is:0.2480, Train_accuracy is 92.7817%, Test_accuracy is 92.6000%\n",
      "================================================================================\n",
      "Epoch 287/2000\n",
      "Loss is:0.2491, Train_accuracy is 92.7267%, Test_accuracy is 92.8200%\n",
      "================================================================================\n",
      "Epoch 288/2000\n",
      "Loss is:0.2468, Train_accuracy is 92.8267%, Test_accuracy is 92.6700%\n",
      "================================================================================\n",
      "Epoch 289/2000\n",
      "Loss is:0.2467, Train_accuracy is 92.8583%, Test_accuracy is 92.8800%\n",
      "================================================================================\n",
      "Epoch 290/2000\n",
      "Loss is:0.2464, Train_accuracy is 92.8833%, Test_accuracy is 92.8500%\n",
      "================================================================================\n",
      "Epoch 291/2000\n",
      "Loss is:0.2427, Train_accuracy is 92.9300%, Test_accuracy is 92.8600%\n",
      "================================================================================\n",
      "Epoch 292/2000\n",
      "Loss is:0.2465, Train_accuracy is 92.8450%, Test_accuracy is 93.0200%\n",
      "================================================================================\n",
      "Epoch 293/2000\n",
      "Loss is:0.2448, Train_accuracy is 92.9117%, Test_accuracy is 92.9300%\n",
      "================================================================================\n",
      "Epoch 294/2000\n",
      "Loss is:0.2451, Train_accuracy is 92.9450%, Test_accuracy is 92.8300%\n",
      "================================================================================\n",
      "Epoch 295/2000\n",
      "Loss is:0.2428, Train_accuracy is 92.9267%, Test_accuracy is 92.7700%\n",
      "================================================================================\n",
      "Epoch 296/2000\n",
      "Loss is:0.2426, Train_accuracy is 92.9800%, Test_accuracy is 92.9100%\n",
      "================================================================================\n",
      "Epoch 297/2000\n",
      "Loss is:0.2404, Train_accuracy is 93.0417%, Test_accuracy is 93.0000%\n",
      "================================================================================\n",
      "Epoch 298/2000\n",
      "Loss is:0.2423, Train_accuracy is 93.0850%, Test_accuracy is 92.9300%\n",
      "================================================================================\n",
      "Epoch 299/2000\n",
      "Loss is:0.2392, Train_accuracy is 93.0250%, Test_accuracy is 93.0100%\n",
      "================================================================================\n",
      "Epoch 300/2000\n",
      "Loss is:0.2386, Train_accuracy is 93.1167%, Test_accuracy is 93.1200%\n",
      "================================================================================\n",
      "Epoch 301/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.2384, Train_accuracy is 93.1967%, Test_accuracy is 93.1900%\n",
      "================================================================================\n",
      "Epoch 302/2000\n",
      "Loss is:0.2380, Train_accuracy is 93.0700%, Test_accuracy is 93.2300%\n",
      "================================================================================\n",
      "Epoch 303/2000\n",
      "Loss is:0.2360, Train_accuracy is 93.1933%, Test_accuracy is 93.1900%\n",
      "================================================================================\n",
      "Epoch 304/2000\n",
      "Loss is:0.2372, Train_accuracy is 93.0167%, Test_accuracy is 93.0800%\n",
      "================================================================================\n",
      "Epoch 305/2000\n",
      "Loss is:0.2369, Train_accuracy is 93.1183%, Test_accuracy is 93.0200%\n",
      "================================================================================\n",
      "Epoch 306/2000\n",
      "Loss is:0.2349, Train_accuracy is 93.2117%, Test_accuracy is 92.9400%\n",
      "================================================================================\n",
      "Epoch 307/2000\n",
      "Loss is:0.2336, Train_accuracy is 93.2567%, Test_accuracy is 93.1500%\n",
      "================================================================================\n",
      "Epoch 308/2000\n",
      "Loss is:0.2340, Train_accuracy is 93.1817%, Test_accuracy is 93.0000%\n",
      "================================================================================\n",
      "Epoch 309/2000\n",
      "Loss is:0.2345, Train_accuracy is 93.1250%, Test_accuracy is 93.1200%\n",
      "================================================================================\n",
      "Epoch 310/2000\n",
      "Loss is:0.2341, Train_accuracy is 93.2900%, Test_accuracy is 93.0900%\n",
      "================================================================================\n",
      "Epoch 311/2000\n",
      "Loss is:0.2322, Train_accuracy is 93.2533%, Test_accuracy is 93.5100%\n",
      "================================================================================\n",
      "Epoch 312/2000\n",
      "Loss is:0.2313, Train_accuracy is 93.3217%, Test_accuracy is 93.1900%\n",
      "================================================================================\n",
      "Epoch 313/2000\n",
      "Loss is:0.2307, Train_accuracy is 93.3350%, Test_accuracy is 93.5900%\n",
      "================================================================================\n",
      "Epoch 314/2000\n",
      "Loss is:0.2301, Train_accuracy is 93.3333%, Test_accuracy is 93.3200%\n",
      "================================================================================\n",
      "Epoch 315/2000\n",
      "Loss is:0.2312, Train_accuracy is 93.3800%, Test_accuracy is 93.2100%\n",
      "================================================================================\n",
      "Epoch 316/2000\n",
      "Loss is:0.2294, Train_accuracy is 93.3233%, Test_accuracy is 92.9500%\n",
      "================================================================================\n",
      "Epoch 317/2000\n",
      "Loss is:0.2300, Train_accuracy is 93.2400%, Test_accuracy is 93.2700%\n",
      "================================================================================\n",
      "Epoch 318/2000\n",
      "Loss is:0.2272, Train_accuracy is 93.3300%, Test_accuracy is 93.1900%\n",
      "================================================================================\n",
      "Epoch 319/2000\n",
      "Loss is:0.2268, Train_accuracy is 93.4233%, Test_accuracy is 93.2200%\n",
      "================================================================================\n",
      "Epoch 320/2000\n",
      "Loss is:0.2269, Train_accuracy is 93.4483%, Test_accuracy is 93.2200%\n",
      "================================================================================\n",
      "Epoch 321/2000\n",
      "Loss is:0.2272, Train_accuracy is 93.4500%, Test_accuracy is 93.2900%\n",
      "================================================================================\n",
      "Epoch 322/2000\n",
      "Loss is:0.2259, Train_accuracy is 93.4967%, Test_accuracy is 93.4600%\n",
      "================================================================================\n",
      "Epoch 323/2000\n",
      "Loss is:0.2250, Train_accuracy is 93.4833%, Test_accuracy is 93.4000%\n",
      "================================================================================\n",
      "Epoch 324/2000\n",
      "Loss is:0.2266, Train_accuracy is 93.4150%, Test_accuracy is 93.4800%\n",
      "================================================================================\n",
      "Epoch 325/2000\n",
      "Loss is:0.2243, Train_accuracy is 93.5000%, Test_accuracy is 93.5000%\n",
      "================================================================================\n",
      "Epoch 326/2000\n",
      "Loss is:0.2237, Train_accuracy is 93.5017%, Test_accuracy is 93.4800%\n",
      "================================================================================\n",
      "Epoch 327/2000\n",
      "Loss is:0.2241, Train_accuracy is 93.5317%, Test_accuracy is 93.4300%\n",
      "================================================================================\n",
      "Epoch 328/2000\n",
      "Loss is:0.2231, Train_accuracy is 93.5317%, Test_accuracy is 93.4100%\n",
      "================================================================================\n",
      "Epoch 329/2000\n",
      "Loss is:0.2207, Train_accuracy is 93.6417%, Test_accuracy is 93.7100%\n",
      "================================================================================\n",
      "Epoch 330/2000\n",
      "Loss is:0.2222, Train_accuracy is 93.6017%, Test_accuracy is 93.5000%\n",
      "================================================================================\n",
      "Epoch 331/2000\n",
      "Loss is:0.2204, Train_accuracy is 93.6250%, Test_accuracy is 93.5100%\n",
      "================================================================================\n",
      "Epoch 332/2000\n",
      "Loss is:0.2221, Train_accuracy is 93.6017%, Test_accuracy is 93.3600%\n",
      "================================================================================\n",
      "Epoch 333/2000\n",
      "Loss is:0.2194, Train_accuracy is 93.6450%, Test_accuracy is 93.6300%\n",
      "================================================================================\n",
      "Epoch 334/2000\n",
      "Loss is:0.2177, Train_accuracy is 93.7583%, Test_accuracy is 93.6900%\n",
      "================================================================================\n",
      "Epoch 335/2000\n",
      "Loss is:0.2170, Train_accuracy is 93.6900%, Test_accuracy is 93.6600%\n",
      "================================================================================\n",
      "Epoch 336/2000\n",
      "Loss is:0.2178, Train_accuracy is 93.6533%, Test_accuracy is 93.5000%\n",
      "================================================================================\n",
      "Epoch 337/2000\n",
      "Loss is:0.2177, Train_accuracy is 93.6900%, Test_accuracy is 93.6400%\n",
      "================================================================================\n",
      "Epoch 338/2000\n",
      "Loss is:0.2161, Train_accuracy is 93.6850%, Test_accuracy is 93.6200%\n",
      "================================================================================\n",
      "Epoch 339/2000\n",
      "Loss is:0.2170, Train_accuracy is 93.7767%, Test_accuracy is 93.7100%\n",
      "================================================================================\n",
      "Epoch 340/2000\n",
      "Loss is:0.2162, Train_accuracy is 93.7050%, Test_accuracy is 93.7400%\n",
      "================================================================================\n",
      "Epoch 341/2000\n",
      "Loss is:0.2165, Train_accuracy is 93.7350%, Test_accuracy is 93.6500%\n",
      "================================================================================\n",
      "Epoch 342/2000\n",
      "Loss is:0.2133, Train_accuracy is 93.7450%, Test_accuracy is 93.7200%\n",
      "================================================================================\n",
      "Epoch 343/2000\n",
      "Loss is:0.2166, Train_accuracy is 93.7617%, Test_accuracy is 93.6500%\n",
      "================================================================================\n",
      "Epoch 344/2000\n",
      "Loss is:0.2146, Train_accuracy is 93.7650%, Test_accuracy is 93.7900%\n",
      "================================================================================\n",
      "Epoch 345/2000\n",
      "Loss is:0.2145, Train_accuracy is 93.7233%, Test_accuracy is 93.7000%\n",
      "================================================================================\n",
      "Epoch 346/2000\n",
      "Loss is:0.2135, Train_accuracy is 93.8033%, Test_accuracy is 93.9900%\n",
      "================================================================================\n",
      "Epoch 347/2000\n",
      "Loss is:0.2116, Train_accuracy is 93.8767%, Test_accuracy is 93.6500%\n",
      "================================================================================\n",
      "Epoch 348/2000\n",
      "Loss is:0.2124, Train_accuracy is 93.9250%, Test_accuracy is 93.6900%\n",
      "================================================================================\n",
      "Epoch 349/2000\n",
      "Loss is:0.2117, Train_accuracy is 93.8283%, Test_accuracy is 93.7600%\n",
      "================================================================================\n",
      "Epoch 350/2000\n",
      "Loss is:0.2115, Train_accuracy is 93.8933%, Test_accuracy is 93.7000%\n",
      "================================================================================\n",
      "Epoch 351/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.2092, Train_accuracy is 93.9200%, Test_accuracy is 93.8800%\n",
      "================================================================================\n",
      "Epoch 352/2000\n",
      "Loss is:0.2102, Train_accuracy is 93.8817%, Test_accuracy is 93.9100%\n",
      "================================================================================\n",
      "Epoch 353/2000\n",
      "Loss is:0.2087, Train_accuracy is 93.9917%, Test_accuracy is 93.8100%\n",
      "================================================================================\n",
      "Epoch 354/2000\n",
      "Loss is:0.2082, Train_accuracy is 93.9767%, Test_accuracy is 93.8300%\n",
      "================================================================================\n",
      "Epoch 355/2000\n",
      "Loss is:0.2088, Train_accuracy is 93.9267%, Test_accuracy is 94.0400%\n",
      "================================================================================\n",
      "Epoch 356/2000\n",
      "Loss is:0.2083, Train_accuracy is 94.0717%, Test_accuracy is 93.7600%\n",
      "================================================================================\n",
      "Epoch 357/2000\n",
      "Loss is:0.2086, Train_accuracy is 93.8900%, Test_accuracy is 93.9400%\n",
      "================================================================================\n",
      "Epoch 358/2000\n",
      "Loss is:0.2069, Train_accuracy is 94.0067%, Test_accuracy is 94.0900%\n",
      "================================================================================\n",
      "Epoch 359/2000\n",
      "Loss is:0.2063, Train_accuracy is 93.9833%, Test_accuracy is 93.9700%\n",
      "================================================================================\n",
      "Epoch 360/2000\n",
      "Loss is:0.2049, Train_accuracy is 94.0417%, Test_accuracy is 93.9200%\n",
      "================================================================================\n",
      "Epoch 361/2000\n",
      "Loss is:0.2067, Train_accuracy is 94.0150%, Test_accuracy is 93.8400%\n",
      "================================================================================\n",
      "Epoch 362/2000\n",
      "Loss is:0.2038, Train_accuracy is 94.0600%, Test_accuracy is 93.9900%\n",
      "================================================================================\n",
      "Epoch 363/2000\n",
      "Loss is:0.2028, Train_accuracy is 94.1367%, Test_accuracy is 94.0300%\n",
      "================================================================================\n",
      "Epoch 364/2000\n",
      "Loss is:0.2025, Train_accuracy is 94.0650%, Test_accuracy is 94.0800%\n",
      "================================================================================\n",
      "Epoch 365/2000\n",
      "Loss is:0.2012, Train_accuracy is 94.1300%, Test_accuracy is 93.9300%\n",
      "================================================================================\n",
      "Epoch 366/2000\n",
      "Loss is:0.2015, Train_accuracy is 94.2083%, Test_accuracy is 93.9300%\n",
      "================================================================================\n",
      "Epoch 367/2000\n",
      "Loss is:0.2021, Train_accuracy is 94.1450%, Test_accuracy is 94.2600%\n",
      "================================================================================\n",
      "Epoch 368/2000\n",
      "Loss is:0.2034, Train_accuracy is 94.0983%, Test_accuracy is 93.7700%\n",
      "================================================================================\n",
      "Epoch 369/2000\n",
      "Loss is:0.2028, Train_accuracy is 94.1033%, Test_accuracy is 93.9900%\n",
      "================================================================================\n",
      "Epoch 370/2000\n",
      "Loss is:0.2015, Train_accuracy is 94.1167%, Test_accuracy is 94.0800%\n",
      "================================================================================\n",
      "Epoch 371/2000\n",
      "Loss is:0.2011, Train_accuracy is 94.1433%, Test_accuracy is 94.0200%\n",
      "================================================================================\n",
      "Epoch 372/2000\n",
      "Loss is:0.2009, Train_accuracy is 94.2167%, Test_accuracy is 94.2300%\n",
      "================================================================================\n",
      "Epoch 373/2000\n",
      "Loss is:0.2005, Train_accuracy is 94.2167%, Test_accuracy is 93.8500%\n",
      "================================================================================\n",
      "Epoch 374/2000\n",
      "Loss is:0.2003, Train_accuracy is 94.1933%, Test_accuracy is 94.0200%\n",
      "================================================================================\n",
      "Epoch 375/2000\n",
      "Loss is:0.1982, Train_accuracy is 94.1633%, Test_accuracy is 93.8200%\n",
      "================================================================================\n",
      "Epoch 376/2000\n",
      "Loss is:0.1997, Train_accuracy is 94.1917%, Test_accuracy is 94.1800%\n",
      "================================================================================\n",
      "Epoch 377/2000\n",
      "Loss is:0.1963, Train_accuracy is 94.3983%, Test_accuracy is 94.3000%\n",
      "================================================================================\n",
      "Epoch 378/2000\n",
      "Loss is:0.1969, Train_accuracy is 94.2850%, Test_accuracy is 94.3500%\n",
      "================================================================================\n",
      "Epoch 379/2000\n",
      "Loss is:0.1962, Train_accuracy is 94.3517%, Test_accuracy is 94.3400%\n",
      "================================================================================\n",
      "Epoch 380/2000\n",
      "Loss is:0.1958, Train_accuracy is 94.3950%, Test_accuracy is 94.2300%\n",
      "================================================================================\n",
      "Epoch 381/2000\n",
      "Loss is:0.1963, Train_accuracy is 94.2750%, Test_accuracy is 94.0600%\n",
      "================================================================================\n",
      "Epoch 382/2000\n",
      "Loss is:0.1951, Train_accuracy is 94.4267%, Test_accuracy is 94.0200%\n",
      "================================================================================\n",
      "Epoch 383/2000\n",
      "Loss is:0.1948, Train_accuracy is 94.3600%, Test_accuracy is 94.2200%\n",
      "================================================================================\n",
      "Epoch 384/2000\n",
      "Loss is:0.1942, Train_accuracy is 94.3967%, Test_accuracy is 94.4900%\n",
      "================================================================================\n",
      "Epoch 385/2000\n",
      "Loss is:0.1949, Train_accuracy is 94.3700%, Test_accuracy is 94.0800%\n",
      "================================================================================\n",
      "Epoch 386/2000\n",
      "Loss is:0.1940, Train_accuracy is 94.3433%, Test_accuracy is 94.2100%\n",
      "================================================================================\n",
      "Epoch 387/2000\n",
      "Loss is:0.1919, Train_accuracy is 94.3667%, Test_accuracy is 94.1700%\n",
      "================================================================================\n",
      "Epoch 388/2000\n",
      "Loss is:0.1925, Train_accuracy is 94.3983%, Test_accuracy is 94.2300%\n",
      "================================================================================\n",
      "Epoch 389/2000\n",
      "Loss is:0.1941, Train_accuracy is 94.4050%, Test_accuracy is 94.3700%\n",
      "================================================================================\n",
      "Epoch 390/2000\n",
      "Loss is:0.1909, Train_accuracy is 94.5700%, Test_accuracy is 94.2100%\n",
      "================================================================================\n",
      "Epoch 391/2000\n",
      "Loss is:0.1941, Train_accuracy is 94.4783%, Test_accuracy is 94.4500%\n",
      "================================================================================\n",
      "Epoch 392/2000\n",
      "Loss is:0.1917, Train_accuracy is 94.3950%, Test_accuracy is 94.2000%\n",
      "================================================================================\n",
      "Epoch 393/2000\n",
      "Loss is:0.1907, Train_accuracy is 94.5300%, Test_accuracy is 94.5400%\n",
      "================================================================================\n",
      "Epoch 394/2000\n",
      "Loss is:0.1910, Train_accuracy is 94.4267%, Test_accuracy is 94.5200%\n",
      "================================================================================\n",
      "Epoch 395/2000\n",
      "Loss is:0.1879, Train_accuracy is 94.5617%, Test_accuracy is 94.2900%\n",
      "================================================================================\n",
      "Epoch 396/2000\n",
      "Loss is:0.1908, Train_accuracy is 94.4033%, Test_accuracy is 94.4400%\n",
      "================================================================================\n",
      "Epoch 397/2000\n",
      "Loss is:0.1892, Train_accuracy is 94.5800%, Test_accuracy is 94.5600%\n",
      "================================================================================\n",
      "Epoch 398/2000\n",
      "Loss is:0.1870, Train_accuracy is 94.5450%, Test_accuracy is 94.2600%\n",
      "================================================================================\n",
      "Epoch 399/2000\n",
      "Loss is:0.1895, Train_accuracy is 94.5100%, Test_accuracy is 94.5500%\n",
      "================================================================================\n",
      "Epoch 400/2000\n",
      "Loss is:0.1878, Train_accuracy is 94.5667%, Test_accuracy is 94.4300%\n",
      "================================================================================\n",
      "Epoch 401/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1873, Train_accuracy is 94.6133%, Test_accuracy is 94.2900%\n",
      "================================================================================\n",
      "Epoch 402/2000\n",
      "Loss is:0.1864, Train_accuracy is 94.5950%, Test_accuracy is 94.7000%\n",
      "================================================================================\n",
      "Epoch 403/2000\n",
      "Loss is:0.1865, Train_accuracy is 94.5700%, Test_accuracy is 94.4200%\n",
      "================================================================================\n",
      "Epoch 404/2000\n",
      "Loss is:0.1868, Train_accuracy is 94.5750%, Test_accuracy is 94.3500%\n",
      "================================================================================\n",
      "Epoch 405/2000\n",
      "Loss is:0.1857, Train_accuracy is 94.6150%, Test_accuracy is 94.2600%\n",
      "================================================================================\n",
      "Epoch 406/2000\n",
      "Loss is:0.1856, Train_accuracy is 94.6167%, Test_accuracy is 94.3600%\n",
      "================================================================================\n",
      "Epoch 407/2000\n",
      "Loss is:0.1841, Train_accuracy is 94.7017%, Test_accuracy is 94.4000%\n",
      "================================================================================\n",
      "Epoch 408/2000\n",
      "Loss is:0.1851, Train_accuracy is 94.5900%, Test_accuracy is 94.3400%\n",
      "================================================================================\n",
      "Epoch 409/2000\n",
      "Loss is:0.1844, Train_accuracy is 94.6700%, Test_accuracy is 94.4000%\n",
      "================================================================================\n",
      "Epoch 410/2000\n",
      "Loss is:0.1845, Train_accuracy is 94.6567%, Test_accuracy is 94.6900%\n",
      "================================================================================\n",
      "Epoch 411/2000\n",
      "Loss is:0.1828, Train_accuracy is 94.6333%, Test_accuracy is 94.5200%\n",
      "================================================================================\n",
      "Epoch 412/2000\n",
      "Loss is:0.1835, Train_accuracy is 94.6600%, Test_accuracy is 94.6000%\n",
      "================================================================================\n",
      "Epoch 413/2000\n",
      "Loss is:0.1822, Train_accuracy is 94.6467%, Test_accuracy is 94.5900%\n",
      "================================================================================\n",
      "Epoch 414/2000\n",
      "Loss is:0.1825, Train_accuracy is 94.7167%, Test_accuracy is 94.3500%\n",
      "================================================================================\n",
      "Epoch 415/2000\n",
      "Loss is:0.1821, Train_accuracy is 94.6533%, Test_accuracy is 94.3600%\n",
      "================================================================================\n",
      "Epoch 416/2000\n",
      "Loss is:0.1805, Train_accuracy is 94.8050%, Test_accuracy is 94.4600%\n",
      "================================================================================\n",
      "Epoch 417/2000\n",
      "Loss is:0.1799, Train_accuracy is 94.6917%, Test_accuracy is 94.6700%\n",
      "================================================================================\n",
      "Epoch 418/2000\n",
      "Loss is:0.1790, Train_accuracy is 94.8417%, Test_accuracy is 94.3400%\n",
      "================================================================================\n",
      "Epoch 419/2000\n",
      "Loss is:0.1808, Train_accuracy is 94.7933%, Test_accuracy is 94.5900%\n",
      "================================================================================\n",
      "Epoch 420/2000\n",
      "Loss is:0.1802, Train_accuracy is 94.8133%, Test_accuracy is 94.5200%\n",
      "================================================================================\n",
      "Epoch 421/2000\n",
      "Loss is:0.1790, Train_accuracy is 94.7783%, Test_accuracy is 94.6400%\n",
      "================================================================================\n",
      "Epoch 422/2000\n",
      "Loss is:0.1789, Train_accuracy is 94.7867%, Test_accuracy is 94.3900%\n",
      "================================================================================\n",
      "Epoch 423/2000\n",
      "Loss is:0.1782, Train_accuracy is 94.8300%, Test_accuracy is 94.7100%\n",
      "================================================================================\n",
      "Epoch 424/2000\n",
      "Loss is:0.1785, Train_accuracy is 94.8817%, Test_accuracy is 94.7100%\n",
      "================================================================================\n",
      "Epoch 425/2000\n",
      "Loss is:0.1779, Train_accuracy is 94.8800%, Test_accuracy is 94.7100%\n",
      "================================================================================\n",
      "Epoch 426/2000\n",
      "Loss is:0.1791, Train_accuracy is 94.7500%, Test_accuracy is 94.5500%\n",
      "================================================================================\n",
      "Epoch 427/2000\n",
      "Loss is:0.1785, Train_accuracy is 94.8350%, Test_accuracy is 94.6800%\n",
      "================================================================================\n",
      "Epoch 428/2000\n",
      "Loss is:0.1768, Train_accuracy is 94.8750%, Test_accuracy is 94.6500%\n",
      "================================================================================\n",
      "Epoch 429/2000\n",
      "Loss is:0.1782, Train_accuracy is 94.7950%, Test_accuracy is 94.7700%\n",
      "================================================================================\n",
      "Epoch 430/2000\n",
      "Loss is:0.1749, Train_accuracy is 94.9250%, Test_accuracy is 94.8100%\n",
      "================================================================================\n",
      "Epoch 431/2000\n",
      "Loss is:0.1746, Train_accuracy is 94.9367%, Test_accuracy is 94.8900%\n",
      "================================================================================\n",
      "Epoch 432/2000\n",
      "Loss is:0.1770, Train_accuracy is 94.8800%, Test_accuracy is 94.6900%\n",
      "================================================================================\n",
      "Epoch 433/2000\n",
      "Loss is:0.1739, Train_accuracy is 94.9500%, Test_accuracy is 94.6700%\n",
      "================================================================================\n",
      "Epoch 434/2000\n",
      "Loss is:0.1754, Train_accuracy is 94.9217%, Test_accuracy is 94.5000%\n",
      "================================================================================\n",
      "Epoch 435/2000\n",
      "Loss is:0.1747, Train_accuracy is 94.9600%, Test_accuracy is 94.8900%\n",
      "================================================================================\n",
      "Epoch 436/2000\n",
      "Loss is:0.1753, Train_accuracy is 94.9200%, Test_accuracy is 94.8500%\n",
      "================================================================================\n",
      "Epoch 437/2000\n",
      "Loss is:0.1731, Train_accuracy is 94.9667%, Test_accuracy is 95.0300%\n",
      "================================================================================\n",
      "Epoch 438/2000\n",
      "Loss is:0.1740, Train_accuracy is 94.9333%, Test_accuracy is 94.9000%\n",
      "================================================================================\n",
      "Epoch 439/2000\n",
      "Loss is:0.1731, Train_accuracy is 95.0067%, Test_accuracy is 94.7600%\n",
      "================================================================================\n",
      "Epoch 440/2000\n",
      "Loss is:0.1742, Train_accuracy is 94.9950%, Test_accuracy is 95.0000%\n",
      "================================================================================\n",
      "Epoch 441/2000\n",
      "Loss is:0.1716, Train_accuracy is 95.0517%, Test_accuracy is 94.9000%\n",
      "================================================================================\n",
      "Epoch 442/2000\n",
      "Loss is:0.1726, Train_accuracy is 95.0233%, Test_accuracy is 94.7600%\n",
      "================================================================================\n",
      "Epoch 443/2000\n",
      "Loss is:0.1726, Train_accuracy is 95.0133%, Test_accuracy is 94.8000%\n",
      "================================================================================\n",
      "Epoch 444/2000\n",
      "Loss is:0.1720, Train_accuracy is 95.0033%, Test_accuracy is 94.6400%\n",
      "================================================================================\n",
      "Epoch 445/2000\n",
      "Loss is:0.1715, Train_accuracy is 94.9733%, Test_accuracy is 94.5300%\n",
      "================================================================================\n",
      "Epoch 446/2000\n",
      "Loss is:0.1714, Train_accuracy is 95.0250%, Test_accuracy is 94.9000%\n",
      "================================================================================\n",
      "Epoch 447/2000\n",
      "Loss is:0.1708, Train_accuracy is 95.0600%, Test_accuracy is 94.7200%\n",
      "================================================================================\n",
      "Epoch 448/2000\n",
      "Loss is:0.1696, Train_accuracy is 95.1067%, Test_accuracy is 94.7400%\n",
      "================================================================================\n",
      "Epoch 449/2000\n",
      "Loss is:0.1690, Train_accuracy is 95.0500%, Test_accuracy is 94.6600%\n",
      "================================================================================\n",
      "Epoch 450/2000\n",
      "Loss is:0.1690, Train_accuracy is 95.0733%, Test_accuracy is 94.6500%\n",
      "================================================================================\n",
      "Epoch 451/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1686, Train_accuracy is 95.0417%, Test_accuracy is 95.0500%\n",
      "================================================================================\n",
      "Epoch 452/2000\n",
      "Loss is:0.1680, Train_accuracy is 95.1367%, Test_accuracy is 94.7700%\n",
      "================================================================================\n",
      "Epoch 453/2000\n",
      "Loss is:0.1683, Train_accuracy is 95.1150%, Test_accuracy is 94.8000%\n",
      "================================================================================\n",
      "Epoch 454/2000\n",
      "Loss is:0.1670, Train_accuracy is 95.1250%, Test_accuracy is 94.7400%\n",
      "================================================================================\n",
      "Epoch 455/2000\n",
      "Loss is:0.1688, Train_accuracy is 95.0633%, Test_accuracy is 95.0600%\n",
      "================================================================================\n",
      "Epoch 456/2000\n",
      "Loss is:0.1679, Train_accuracy is 95.1800%, Test_accuracy is 94.7300%\n",
      "================================================================================\n",
      "Epoch 457/2000\n",
      "Loss is:0.1681, Train_accuracy is 95.0967%, Test_accuracy is 94.7800%\n",
      "================================================================================\n",
      "Epoch 458/2000\n",
      "Loss is:0.1682, Train_accuracy is 95.1067%, Test_accuracy is 94.7900%\n",
      "================================================================================\n",
      "Epoch 459/2000\n",
      "Loss is:0.1663, Train_accuracy is 95.1567%, Test_accuracy is 94.9400%\n",
      "================================================================================\n",
      "Epoch 460/2000\n",
      "Loss is:0.1666, Train_accuracy is 95.2517%, Test_accuracy is 94.8400%\n",
      "================================================================================\n",
      "Epoch 461/2000\n",
      "Loss is:0.1662, Train_accuracy is 95.1300%, Test_accuracy is 95.1100%\n",
      "================================================================================\n",
      "Epoch 462/2000\n",
      "Loss is:0.1657, Train_accuracy is 95.1917%, Test_accuracy is 94.9300%\n",
      "================================================================================\n",
      "Epoch 463/2000\n",
      "Loss is:0.1650, Train_accuracy is 95.0967%, Test_accuracy is 94.8100%\n",
      "================================================================================\n",
      "Epoch 464/2000\n",
      "Loss is:0.1642, Train_accuracy is 95.2617%, Test_accuracy is 94.9300%\n",
      "================================================================================\n",
      "Epoch 465/2000\n",
      "Loss is:0.1626, Train_accuracy is 95.2900%, Test_accuracy is 94.9400%\n",
      "================================================================================\n",
      "Epoch 466/2000\n",
      "Loss is:0.1636, Train_accuracy is 95.2583%, Test_accuracy is 95.3000%\n",
      "================================================================================\n",
      "Epoch 467/2000\n",
      "Loss is:0.1648, Train_accuracy is 95.1883%, Test_accuracy is 95.1600%\n",
      "================================================================================\n",
      "Epoch 468/2000\n",
      "Loss is:0.1632, Train_accuracy is 95.2900%, Test_accuracy is 94.9400%\n",
      "================================================================================\n",
      "Epoch 469/2000\n",
      "Loss is:0.1628, Train_accuracy is 95.3567%, Test_accuracy is 95.2000%\n",
      "================================================================================\n",
      "Epoch 470/2000\n",
      "Loss is:0.1628, Train_accuracy is 95.2017%, Test_accuracy is 94.9100%\n",
      "================================================================================\n",
      "Epoch 471/2000\n",
      "Loss is:0.1605, Train_accuracy is 95.3583%, Test_accuracy is 95.0800%\n",
      "================================================================================\n",
      "Epoch 472/2000\n",
      "Loss is:0.1625, Train_accuracy is 95.3000%, Test_accuracy is 94.9100%\n",
      "================================================================================\n",
      "Epoch 473/2000\n",
      "Loss is:0.1615, Train_accuracy is 95.2933%, Test_accuracy is 94.9200%\n",
      "================================================================================\n",
      "Epoch 474/2000\n",
      "Loss is:0.1617, Train_accuracy is 95.3900%, Test_accuracy is 94.8900%\n",
      "================================================================================\n",
      "Epoch 475/2000\n",
      "Loss is:0.1610, Train_accuracy is 95.3683%, Test_accuracy is 95.0700%\n",
      "================================================================================\n",
      "Epoch 476/2000\n",
      "Loss is:0.1601, Train_accuracy is 95.3300%, Test_accuracy is 95.1000%\n",
      "================================================================================\n",
      "Epoch 477/2000\n",
      "Loss is:0.1593, Train_accuracy is 95.4267%, Test_accuracy is 95.0600%\n",
      "================================================================================\n",
      "Epoch 478/2000\n",
      "Loss is:0.1610, Train_accuracy is 95.4033%, Test_accuracy is 95.1100%\n",
      "================================================================================\n",
      "Epoch 479/2000\n",
      "Loss is:0.1600, Train_accuracy is 95.3100%, Test_accuracy is 94.9300%\n",
      "================================================================================\n",
      "Epoch 480/2000\n",
      "Loss is:0.1591, Train_accuracy is 95.3717%, Test_accuracy is 95.3200%\n",
      "================================================================================\n",
      "Epoch 481/2000\n",
      "Loss is:0.1581, Train_accuracy is 95.4733%, Test_accuracy is 95.1400%\n",
      "================================================================================\n",
      "Epoch 482/2000\n",
      "Loss is:0.1595, Train_accuracy is 95.3767%, Test_accuracy is 95.2600%\n",
      "================================================================================\n",
      "Epoch 483/2000\n",
      "Loss is:0.1562, Train_accuracy is 95.3867%, Test_accuracy is 95.1400%\n",
      "================================================================================\n",
      "Epoch 484/2000\n",
      "Loss is:0.1596, Train_accuracy is 95.3783%, Test_accuracy is 95.0600%\n",
      "================================================================================\n",
      "Epoch 485/2000\n",
      "Loss is:0.1593, Train_accuracy is 95.3833%, Test_accuracy is 95.3200%\n",
      "================================================================================\n",
      "Epoch 486/2000\n",
      "Loss is:0.1583, Train_accuracy is 95.3767%, Test_accuracy is 95.5300%\n",
      "================================================================================\n",
      "Epoch 487/2000\n",
      "Loss is:0.1573, Train_accuracy is 95.3833%, Test_accuracy is 95.1000%\n",
      "================================================================================\n",
      "Epoch 488/2000\n",
      "Loss is:0.1580, Train_accuracy is 95.3900%, Test_accuracy is 95.0800%\n",
      "================================================================================\n",
      "Epoch 489/2000\n",
      "Loss is:0.1576, Train_accuracy is 95.4467%, Test_accuracy is 95.1900%\n",
      "================================================================================\n",
      "Epoch 490/2000\n",
      "Loss is:0.1576, Train_accuracy is 95.4167%, Test_accuracy is 95.1200%\n",
      "================================================================================\n",
      "Epoch 491/2000\n",
      "Loss is:0.1559, Train_accuracy is 95.4000%, Test_accuracy is 95.0400%\n",
      "================================================================================\n",
      "Epoch 492/2000\n",
      "Loss is:0.1564, Train_accuracy is 95.4250%, Test_accuracy is 95.1500%\n",
      "================================================================================\n",
      "Epoch 493/2000\n",
      "Loss is:0.1544, Train_accuracy is 95.4700%, Test_accuracy is 95.1600%\n",
      "================================================================================\n",
      "Epoch 494/2000\n",
      "Loss is:0.1558, Train_accuracy is 95.5167%, Test_accuracy is 95.2200%\n",
      "================================================================================\n",
      "Epoch 495/2000\n",
      "Loss is:0.1549, Train_accuracy is 95.4700%, Test_accuracy is 94.9800%\n",
      "================================================================================\n",
      "Epoch 496/2000\n",
      "Loss is:0.1540, Train_accuracy is 95.5767%, Test_accuracy is 95.2600%\n",
      "================================================================================\n",
      "Epoch 497/2000\n",
      "Loss is:0.1543, Train_accuracy is 95.5233%, Test_accuracy is 95.2000%\n",
      "================================================================================\n",
      "Epoch 498/2000\n",
      "Loss is:0.1562, Train_accuracy is 95.4900%, Test_accuracy is 95.1900%\n",
      "================================================================================\n",
      "Epoch 499/2000\n",
      "Loss is:0.1533, Train_accuracy is 95.5100%, Test_accuracy is 95.3000%\n",
      "================================================================================\n",
      "Epoch 500/2000\n",
      "Loss is:0.1534, Train_accuracy is 95.6000%, Test_accuracy is 95.0000%\n",
      "================================================================================\n",
      "Epoch 501/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1544, Train_accuracy is 95.4267%, Test_accuracy is 95.2400%\n",
      "================================================================================\n",
      "Epoch 502/2000\n",
      "Loss is:0.1516, Train_accuracy is 95.5400%, Test_accuracy is 95.0800%\n",
      "================================================================================\n",
      "Epoch 503/2000\n",
      "Loss is:0.1533, Train_accuracy is 95.5017%, Test_accuracy is 95.2500%\n",
      "================================================================================\n",
      "Epoch 504/2000\n",
      "Loss is:0.1528, Train_accuracy is 95.5600%, Test_accuracy is 95.2400%\n",
      "================================================================================\n",
      "Epoch 505/2000\n",
      "Loss is:0.1519, Train_accuracy is 95.5700%, Test_accuracy is 95.0700%\n",
      "================================================================================\n",
      "Epoch 506/2000\n",
      "Loss is:0.1533, Train_accuracy is 95.6050%, Test_accuracy is 95.2300%\n",
      "================================================================================\n",
      "Epoch 507/2000\n",
      "Loss is:0.1513, Train_accuracy is 95.5517%, Test_accuracy is 95.2800%\n",
      "================================================================================\n",
      "Epoch 508/2000\n",
      "Loss is:0.1518, Train_accuracy is 95.5700%, Test_accuracy is 95.4000%\n",
      "================================================================================\n",
      "Epoch 509/2000\n",
      "Loss is:0.1520, Train_accuracy is 95.6200%, Test_accuracy is 95.1600%\n",
      "================================================================================\n",
      "Epoch 510/2000\n",
      "Loss is:0.1512, Train_accuracy is 95.5350%, Test_accuracy is 95.2000%\n",
      "================================================================================\n",
      "Epoch 511/2000\n",
      "Loss is:0.1500, Train_accuracy is 95.6900%, Test_accuracy is 95.2200%\n",
      "================================================================================\n",
      "Epoch 512/2000\n",
      "Loss is:0.1487, Train_accuracy is 95.6917%, Test_accuracy is 95.3100%\n",
      "================================================================================\n",
      "Epoch 513/2000\n",
      "Loss is:0.1507, Train_accuracy is 95.5700%, Test_accuracy is 95.0900%\n",
      "================================================================================\n",
      "Epoch 514/2000\n",
      "Loss is:0.1502, Train_accuracy is 95.5700%, Test_accuracy is 95.3700%\n",
      "================================================================================\n",
      "Epoch 515/2000\n",
      "Loss is:0.1482, Train_accuracy is 95.6800%, Test_accuracy is 95.3600%\n",
      "================================================================================\n",
      "Epoch 516/2000\n",
      "Loss is:0.1489, Train_accuracy is 95.6867%, Test_accuracy is 95.3400%\n",
      "================================================================================\n",
      "Epoch 517/2000\n",
      "Loss is:0.1495, Train_accuracy is 95.6550%, Test_accuracy is 95.5500%\n",
      "================================================================================\n",
      "Epoch 518/2000\n",
      "Loss is:0.1501, Train_accuracy is 95.6200%, Test_accuracy is 95.6300%\n",
      "================================================================================\n",
      "Epoch 519/2000\n",
      "Loss is:0.1493, Train_accuracy is 95.6650%, Test_accuracy is 95.4100%\n",
      "================================================================================\n",
      "Epoch 520/2000\n",
      "Loss is:0.1485, Train_accuracy is 95.7133%, Test_accuracy is 95.4000%\n",
      "================================================================================\n",
      "Epoch 521/2000\n",
      "Loss is:0.1467, Train_accuracy is 95.7817%, Test_accuracy is 95.3900%\n",
      "================================================================================\n",
      "Epoch 522/2000\n",
      "Loss is:0.1482, Train_accuracy is 95.7283%, Test_accuracy is 95.4900%\n",
      "================================================================================\n",
      "Epoch 523/2000\n",
      "Loss is:0.1480, Train_accuracy is 95.7017%, Test_accuracy is 95.5100%\n",
      "================================================================================\n",
      "Epoch 524/2000\n",
      "Loss is:0.1470, Train_accuracy is 95.7083%, Test_accuracy is 95.3800%\n",
      "================================================================================\n",
      "Epoch 525/2000\n",
      "Loss is:0.1450, Train_accuracy is 95.7200%, Test_accuracy is 95.4400%\n",
      "================================================================================\n",
      "Epoch 526/2000\n",
      "Loss is:0.1480, Train_accuracy is 95.6983%, Test_accuracy is 95.3600%\n",
      "================================================================================\n",
      "Epoch 527/2000\n",
      "Loss is:0.1470, Train_accuracy is 95.7067%, Test_accuracy is 95.6500%\n",
      "================================================================================\n",
      "Epoch 528/2000\n",
      "Loss is:0.1464, Train_accuracy is 95.7917%, Test_accuracy is 95.3400%\n",
      "================================================================================\n",
      "Epoch 529/2000\n",
      "Loss is:0.1458, Train_accuracy is 95.7667%, Test_accuracy is 95.4800%\n",
      "================================================================================\n",
      "Epoch 530/2000\n",
      "Loss is:0.1454, Train_accuracy is 95.7550%, Test_accuracy is 95.4800%\n",
      "================================================================================\n",
      "Epoch 531/2000\n",
      "Loss is:0.1485, Train_accuracy is 95.6517%, Test_accuracy is 95.5700%\n",
      "================================================================================\n",
      "Epoch 532/2000\n",
      "Loss is:0.1453, Train_accuracy is 95.7150%, Test_accuracy is 95.3600%\n",
      "================================================================================\n",
      "Epoch 533/2000\n",
      "Loss is:0.1451, Train_accuracy is 95.8033%, Test_accuracy is 95.5400%\n",
      "================================================================================\n",
      "Epoch 534/2000\n",
      "Loss is:0.1450, Train_accuracy is 95.7400%, Test_accuracy is 95.4100%\n",
      "================================================================================\n",
      "Epoch 535/2000\n",
      "Loss is:0.1430, Train_accuracy is 95.8500%, Test_accuracy is 95.6900%\n",
      "================================================================================\n",
      "Epoch 536/2000\n",
      "Loss is:0.1431, Train_accuracy is 95.7983%, Test_accuracy is 95.3600%\n",
      "================================================================================\n",
      "Epoch 537/2000\n",
      "Loss is:0.1460, Train_accuracy is 95.7450%, Test_accuracy is 95.5300%\n",
      "================================================================================\n",
      "Epoch 538/2000\n",
      "Loss is:0.1435, Train_accuracy is 95.8200%, Test_accuracy is 95.7200%\n",
      "================================================================================\n",
      "Epoch 539/2000\n",
      "Loss is:0.1437, Train_accuracy is 95.8867%, Test_accuracy is 95.3800%\n",
      "================================================================================\n",
      "Epoch 540/2000\n",
      "Loss is:0.1449, Train_accuracy is 95.7383%, Test_accuracy is 95.5900%\n",
      "================================================================================\n",
      "Epoch 541/2000\n",
      "Loss is:0.1430, Train_accuracy is 95.7983%, Test_accuracy is 95.5100%\n",
      "================================================================================\n",
      "Epoch 542/2000\n",
      "Loss is:0.1425, Train_accuracy is 95.9483%, Test_accuracy is 95.4000%\n",
      "================================================================================\n",
      "Epoch 543/2000\n",
      "Loss is:0.1423, Train_accuracy is 95.8550%, Test_accuracy is 95.3500%\n",
      "================================================================================\n",
      "Epoch 544/2000\n",
      "Loss is:0.1419, Train_accuracy is 95.8233%, Test_accuracy is 95.4000%\n",
      "================================================================================\n",
      "Epoch 545/2000\n",
      "Loss is:0.1435, Train_accuracy is 95.8533%, Test_accuracy is 95.7500%\n",
      "================================================================================\n",
      "Epoch 546/2000\n",
      "Loss is:0.1431, Train_accuracy is 95.7917%, Test_accuracy is 95.4800%\n",
      "================================================================================\n",
      "Epoch 547/2000\n",
      "Loss is:0.1419, Train_accuracy is 95.8300%, Test_accuracy is 95.5200%\n",
      "================================================================================\n",
      "Epoch 548/2000\n",
      "Loss is:0.1415, Train_accuracy is 95.9100%, Test_accuracy is 95.6400%\n",
      "================================================================================\n",
      "Epoch 549/2000\n",
      "Loss is:0.1397, Train_accuracy is 95.9617%, Test_accuracy is 95.4500%\n",
      "================================================================================\n",
      "Epoch 550/2000\n",
      "Loss is:0.1425, Train_accuracy is 95.8533%, Test_accuracy is 95.4700%\n",
      "================================================================================\n",
      "Epoch 551/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1420, Train_accuracy is 95.8733%, Test_accuracy is 95.5900%\n",
      "================================================================================\n",
      "Epoch 552/2000\n",
      "Loss is:0.1414, Train_accuracy is 95.8300%, Test_accuracy is 95.6100%\n",
      "================================================================================\n",
      "Epoch 553/2000\n",
      "Loss is:0.1399, Train_accuracy is 95.9700%, Test_accuracy is 95.5100%\n",
      "================================================================================\n",
      "Epoch 554/2000\n",
      "Loss is:0.1386, Train_accuracy is 95.9650%, Test_accuracy is 95.6100%\n",
      "================================================================================\n",
      "Epoch 555/2000\n",
      "Loss is:0.1394, Train_accuracy is 95.9400%, Test_accuracy is 95.5400%\n",
      "================================================================================\n",
      "Epoch 556/2000\n",
      "Loss is:0.1402, Train_accuracy is 95.8400%, Test_accuracy is 95.4000%\n",
      "================================================================================\n",
      "Epoch 557/2000\n",
      "Loss is:0.1380, Train_accuracy is 95.8933%, Test_accuracy is 95.6700%\n",
      "================================================================================\n",
      "Epoch 558/2000\n",
      "Loss is:0.1393, Train_accuracy is 95.9833%, Test_accuracy is 95.6500%\n",
      "================================================================================\n",
      "Epoch 559/2000\n",
      "Loss is:0.1380, Train_accuracy is 95.9783%, Test_accuracy is 95.7000%\n",
      "================================================================================\n",
      "Epoch 560/2000\n",
      "Loss is:0.1393, Train_accuracy is 95.9750%, Test_accuracy is 95.5300%\n",
      "================================================================================\n",
      "Epoch 561/2000\n",
      "Loss is:0.1387, Train_accuracy is 95.9800%, Test_accuracy is 95.4700%\n",
      "================================================================================\n",
      "Epoch 562/2000\n",
      "Loss is:0.1386, Train_accuracy is 95.9433%, Test_accuracy is 95.5100%\n",
      "================================================================================\n",
      "Epoch 563/2000\n",
      "Loss is:0.1380, Train_accuracy is 95.9283%, Test_accuracy is 95.6700%\n",
      "================================================================================\n",
      "Epoch 564/2000\n",
      "Loss is:0.1380, Train_accuracy is 95.9983%, Test_accuracy is 95.7500%\n",
      "================================================================================\n",
      "Epoch 565/2000\n",
      "Loss is:0.1363, Train_accuracy is 95.9583%, Test_accuracy is 95.7200%\n",
      "================================================================================\n",
      "Epoch 566/2000\n",
      "Loss is:0.1362, Train_accuracy is 96.0333%, Test_accuracy is 95.5700%\n",
      "================================================================================\n",
      "Epoch 567/2000\n",
      "Loss is:0.1383, Train_accuracy is 95.9800%, Test_accuracy is 95.3800%\n",
      "================================================================================\n",
      "Epoch 568/2000\n",
      "Loss is:0.1363, Train_accuracy is 96.0217%, Test_accuracy is 95.6000%\n",
      "================================================================================\n",
      "Epoch 569/2000\n",
      "Loss is:0.1363, Train_accuracy is 96.0117%, Test_accuracy is 95.5100%\n",
      "================================================================================\n",
      "Epoch 570/2000\n",
      "Loss is:0.1370, Train_accuracy is 96.0267%, Test_accuracy is 95.4600%\n",
      "================================================================================\n",
      "Epoch 571/2000\n",
      "Loss is:0.1342, Train_accuracy is 96.0400%, Test_accuracy is 95.6900%\n",
      "================================================================================\n",
      "Epoch 572/2000\n",
      "Loss is:0.1358, Train_accuracy is 96.0850%, Test_accuracy is 95.6800%\n",
      "================================================================================\n",
      "Epoch 573/2000\n",
      "Loss is:0.1356, Train_accuracy is 96.1017%, Test_accuracy is 95.7400%\n",
      "================================================================================\n",
      "Epoch 574/2000\n",
      "Loss is:0.1345, Train_accuracy is 96.1033%, Test_accuracy is 95.3600%\n",
      "================================================================================\n",
      "Epoch 575/2000\n",
      "Loss is:0.1358, Train_accuracy is 95.9967%, Test_accuracy is 95.9800%\n",
      "================================================================================\n",
      "Epoch 576/2000\n",
      "Loss is:0.1356, Train_accuracy is 96.0083%, Test_accuracy is 95.8400%\n",
      "================================================================================\n",
      "Epoch 577/2000\n",
      "Loss is:0.1342, Train_accuracy is 96.1083%, Test_accuracy is 95.6300%\n",
      "================================================================================\n",
      "Epoch 578/2000\n",
      "Loss is:0.1354, Train_accuracy is 96.0967%, Test_accuracy is 95.6300%\n",
      "================================================================================\n",
      "Epoch 579/2000\n",
      "Loss is:0.1341, Train_accuracy is 96.0800%, Test_accuracy is 95.5800%\n",
      "================================================================================\n",
      "Epoch 580/2000\n",
      "Loss is:0.1331, Train_accuracy is 96.1367%, Test_accuracy is 95.4800%\n",
      "================================================================================\n",
      "Epoch 581/2000\n",
      "Loss is:0.1339, Train_accuracy is 96.0283%, Test_accuracy is 95.6100%\n",
      "================================================================================\n",
      "Epoch 582/2000\n",
      "Loss is:0.1331, Train_accuracy is 96.1517%, Test_accuracy is 95.7000%\n",
      "================================================================================\n",
      "Epoch 583/2000\n",
      "Loss is:0.1343, Train_accuracy is 96.0433%, Test_accuracy is 95.5500%\n",
      "================================================================================\n",
      "Epoch 584/2000\n",
      "Loss is:0.1328, Train_accuracy is 96.0917%, Test_accuracy is 95.6600%\n",
      "================================================================================\n",
      "Epoch 585/2000\n",
      "Loss is:0.1341, Train_accuracy is 96.1217%, Test_accuracy is 95.4100%\n",
      "================================================================================\n",
      "Epoch 586/2000\n",
      "Loss is:0.1330, Train_accuracy is 96.1567%, Test_accuracy is 95.7900%\n",
      "================================================================================\n",
      "Epoch 587/2000\n",
      "Loss is:0.1324, Train_accuracy is 96.1500%, Test_accuracy is 95.7900%\n",
      "================================================================================\n",
      "Epoch 588/2000\n",
      "Loss is:0.1324, Train_accuracy is 96.1250%, Test_accuracy is 95.8900%\n",
      "================================================================================\n",
      "Epoch 589/2000\n",
      "Loss is:0.1328, Train_accuracy is 96.1167%, Test_accuracy is 95.8700%\n",
      "================================================================================\n",
      "Epoch 590/2000\n",
      "Loss is:0.1320, Train_accuracy is 96.0917%, Test_accuracy is 95.6700%\n",
      "================================================================================\n",
      "Epoch 591/2000\n",
      "Loss is:0.1309, Train_accuracy is 96.1467%, Test_accuracy is 95.5800%\n",
      "================================================================================\n",
      "Epoch 592/2000\n",
      "Loss is:0.1312, Train_accuracy is 96.2067%, Test_accuracy is 95.7100%\n",
      "================================================================================\n",
      "Epoch 593/2000\n",
      "Loss is:0.1318, Train_accuracy is 96.1467%, Test_accuracy is 95.9000%\n",
      "================================================================================\n",
      "Epoch 594/2000\n",
      "Loss is:0.1312, Train_accuracy is 96.1767%, Test_accuracy is 95.6200%\n",
      "================================================================================\n",
      "Epoch 595/2000\n",
      "Loss is:0.1297, Train_accuracy is 96.2050%, Test_accuracy is 95.7000%\n",
      "================================================================================\n",
      "Epoch 596/2000\n",
      "Loss is:0.1313, Train_accuracy is 96.1133%, Test_accuracy is 95.6400%\n",
      "================================================================================\n",
      "Epoch 597/2000\n",
      "Loss is:0.1320, Train_accuracy is 96.1517%, Test_accuracy is 95.9200%\n",
      "================================================================================\n",
      "Epoch 598/2000\n",
      "Loss is:0.1304, Train_accuracy is 96.1767%, Test_accuracy is 95.7800%\n",
      "================================================================================\n",
      "Epoch 599/2000\n",
      "Loss is:0.1312, Train_accuracy is 96.1667%, Test_accuracy is 95.5400%\n",
      "================================================================================\n",
      "Epoch 600/2000\n",
      "Loss is:0.1287, Train_accuracy is 96.2367%, Test_accuracy is 95.6200%\n",
      "================================================================================\n",
      "Epoch 601/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1303, Train_accuracy is 96.2083%, Test_accuracy is 95.6100%\n",
      "================================================================================\n",
      "Epoch 602/2000\n",
      "Loss is:0.1286, Train_accuracy is 96.2783%, Test_accuracy is 95.8500%\n",
      "================================================================================\n",
      "Epoch 603/2000\n",
      "Loss is:0.1289, Train_accuracy is 96.2333%, Test_accuracy is 95.7900%\n",
      "================================================================================\n",
      "Epoch 604/2000\n",
      "Loss is:0.1286, Train_accuracy is 96.2850%, Test_accuracy is 95.7100%\n",
      "================================================================================\n",
      "Epoch 605/2000\n",
      "Loss is:0.1300, Train_accuracy is 96.1850%, Test_accuracy is 95.5800%\n",
      "================================================================================\n",
      "Epoch 606/2000\n",
      "Loss is:0.1293, Train_accuracy is 96.3267%, Test_accuracy is 95.9300%\n",
      "================================================================================\n",
      "Epoch 607/2000\n",
      "Loss is:0.1288, Train_accuracy is 96.2250%, Test_accuracy is 95.7500%\n",
      "================================================================================\n",
      "Epoch 608/2000\n",
      "Loss is:0.1296, Train_accuracy is 96.1833%, Test_accuracy is 95.8900%\n",
      "================================================================================\n",
      "Epoch 609/2000\n",
      "Loss is:0.1270, Train_accuracy is 96.2950%, Test_accuracy is 95.9800%\n",
      "================================================================================\n",
      "Epoch 610/2000\n",
      "Loss is:0.1281, Train_accuracy is 96.3017%, Test_accuracy is 95.9400%\n",
      "================================================================================\n",
      "Epoch 611/2000\n",
      "Loss is:0.1270, Train_accuracy is 96.2600%, Test_accuracy is 95.9800%\n",
      "================================================================================\n",
      "Epoch 612/2000\n",
      "Loss is:0.1270, Train_accuracy is 96.2867%, Test_accuracy is 95.8200%\n",
      "================================================================================\n",
      "Epoch 613/2000\n",
      "Loss is:0.1271, Train_accuracy is 96.2600%, Test_accuracy is 95.7900%\n",
      "================================================================================\n",
      "Epoch 614/2000\n",
      "Loss is:0.1269, Train_accuracy is 96.2267%, Test_accuracy is 95.8200%\n",
      "================================================================================\n",
      "Epoch 615/2000\n",
      "Loss is:0.1272, Train_accuracy is 96.3000%, Test_accuracy is 95.9200%\n",
      "================================================================================\n",
      "Epoch 616/2000\n",
      "Loss is:0.1258, Train_accuracy is 96.2767%, Test_accuracy is 95.8600%\n",
      "================================================================================\n",
      "Epoch 617/2000\n",
      "Loss is:0.1260, Train_accuracy is 96.3250%, Test_accuracy is 95.9100%\n",
      "================================================================================\n",
      "Epoch 618/2000\n",
      "Loss is:0.1248, Train_accuracy is 96.3450%, Test_accuracy is 95.9100%\n",
      "================================================================================\n",
      "Epoch 619/2000\n",
      "Loss is:0.1259, Train_accuracy is 96.3517%, Test_accuracy is 95.8200%\n",
      "================================================================================\n",
      "Epoch 620/2000\n",
      "Loss is:0.1254, Train_accuracy is 96.3183%, Test_accuracy is 95.9900%\n",
      "================================================================================\n",
      "Epoch 621/2000\n",
      "Loss is:0.1260, Train_accuracy is 96.3300%, Test_accuracy is 95.9200%\n",
      "================================================================================\n",
      "Epoch 622/2000\n",
      "Loss is:0.1271, Train_accuracy is 96.3617%, Test_accuracy is 95.7400%\n",
      "================================================================================\n",
      "Epoch 623/2000\n",
      "Loss is:0.1254, Train_accuracy is 96.3300%, Test_accuracy is 95.9500%\n",
      "================================================================================\n",
      "Epoch 624/2000\n",
      "Loss is:0.1257, Train_accuracy is 96.3300%, Test_accuracy is 95.9300%\n",
      "================================================================================\n",
      "Epoch 625/2000\n",
      "Loss is:0.1251, Train_accuracy is 96.3867%, Test_accuracy is 95.7600%\n",
      "================================================================================\n",
      "Epoch 626/2000\n",
      "Loss is:0.1238, Train_accuracy is 96.3617%, Test_accuracy is 96.0000%\n",
      "================================================================================\n",
      "Epoch 627/2000\n",
      "Loss is:0.1249, Train_accuracy is 96.3183%, Test_accuracy is 96.0800%\n",
      "================================================================================\n",
      "Epoch 628/2000\n",
      "Loss is:0.1245, Train_accuracy is 96.4267%, Test_accuracy is 95.7900%\n",
      "================================================================================\n",
      "Epoch 629/2000\n",
      "Loss is:0.1231, Train_accuracy is 96.4717%, Test_accuracy is 95.9400%\n",
      "================================================================================\n",
      "Epoch 630/2000\n",
      "Loss is:0.1233, Train_accuracy is 96.4133%, Test_accuracy is 95.8600%\n",
      "================================================================================\n",
      "Epoch 631/2000\n",
      "Loss is:0.1249, Train_accuracy is 96.3133%, Test_accuracy is 95.7900%\n",
      "================================================================================\n",
      "Epoch 632/2000\n",
      "Loss is:0.1242, Train_accuracy is 96.3633%, Test_accuracy is 95.8700%\n",
      "================================================================================\n",
      "Epoch 633/2000\n",
      "Loss is:0.1238, Train_accuracy is 96.3917%, Test_accuracy is 95.7400%\n",
      "================================================================================\n",
      "Epoch 634/2000\n",
      "Loss is:0.1218, Train_accuracy is 96.4850%, Test_accuracy is 95.9400%\n",
      "================================================================================\n",
      "Epoch 635/2000\n",
      "Loss is:0.1231, Train_accuracy is 96.4167%, Test_accuracy is 95.9600%\n",
      "================================================================================\n",
      "Epoch 636/2000\n",
      "Loss is:0.1235, Train_accuracy is 96.3717%, Test_accuracy is 96.0300%\n",
      "================================================================================\n",
      "Epoch 637/2000\n",
      "Loss is:0.1221, Train_accuracy is 96.4033%, Test_accuracy is 96.0500%\n",
      "================================================================================\n",
      "Epoch 638/2000\n",
      "Loss is:0.1231, Train_accuracy is 96.4200%, Test_accuracy is 96.1200%\n",
      "================================================================================\n",
      "Epoch 639/2000\n",
      "Loss is:0.1242, Train_accuracy is 96.3917%, Test_accuracy is 96.0000%\n",
      "================================================================================\n",
      "Epoch 640/2000\n",
      "Loss is:0.1208, Train_accuracy is 96.5050%, Test_accuracy is 96.0400%\n",
      "================================================================================\n",
      "Epoch 641/2000\n",
      "Loss is:0.1215, Train_accuracy is 96.4833%, Test_accuracy is 95.8100%\n",
      "================================================================================\n",
      "Epoch 642/2000\n",
      "Loss is:0.1215, Train_accuracy is 96.4900%, Test_accuracy is 96.0100%\n",
      "================================================================================\n",
      "Epoch 643/2000\n",
      "Loss is:0.1213, Train_accuracy is 96.5250%, Test_accuracy is 96.2100%\n",
      "================================================================================\n",
      "Epoch 644/2000\n",
      "Loss is:0.1219, Train_accuracy is 96.4667%, Test_accuracy is 95.9200%\n",
      "================================================================================\n",
      "Epoch 645/2000\n",
      "Loss is:0.1221, Train_accuracy is 96.4217%, Test_accuracy is 95.8000%\n",
      "================================================================================\n",
      "Epoch 646/2000\n",
      "Loss is:0.1201, Train_accuracy is 96.5433%, Test_accuracy is 95.7900%\n",
      "================================================================================\n",
      "Epoch 647/2000\n",
      "Loss is:0.1212, Train_accuracy is 96.4433%, Test_accuracy is 95.7700%\n",
      "================================================================================\n",
      "Epoch 648/2000\n",
      "Loss is:0.1202, Train_accuracy is 96.5133%, Test_accuracy is 96.0400%\n",
      "================================================================================\n",
      "Epoch 649/2000\n",
      "Loss is:0.1204, Train_accuracy is 96.5200%, Test_accuracy is 96.1600%\n",
      "================================================================================\n",
      "Epoch 650/2000\n",
      "Loss is:0.1195, Train_accuracy is 96.5650%, Test_accuracy is 95.9000%\n",
      "================================================================================\n",
      "Epoch 651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1204, Train_accuracy is 96.4567%, Test_accuracy is 95.9600%\n",
      "================================================================================\n",
      "Epoch 652/2000\n",
      "Loss is:0.1207, Train_accuracy is 96.5083%, Test_accuracy is 95.9900%\n",
      "================================================================================\n",
      "Epoch 653/2000\n",
      "Loss is:0.1184, Train_accuracy is 96.6100%, Test_accuracy is 96.2200%\n",
      "================================================================================\n",
      "Epoch 654/2000\n",
      "Loss is:0.1203, Train_accuracy is 96.5367%, Test_accuracy is 96.1200%\n",
      "================================================================================\n",
      "Epoch 655/2000\n",
      "Loss is:0.1197, Train_accuracy is 96.5250%, Test_accuracy is 96.2200%\n",
      "================================================================================\n",
      "Epoch 656/2000\n",
      "Loss is:0.1193, Train_accuracy is 96.5533%, Test_accuracy is 96.0400%\n",
      "================================================================================\n",
      "Epoch 657/2000\n",
      "Loss is:0.1195, Train_accuracy is 96.4683%, Test_accuracy is 96.0400%\n",
      "================================================================================\n",
      "Epoch 658/2000\n",
      "Loss is:0.1189, Train_accuracy is 96.5583%, Test_accuracy is 96.1400%\n",
      "================================================================================\n",
      "Epoch 659/2000\n",
      "Loss is:0.1179, Train_accuracy is 96.5817%, Test_accuracy is 95.9300%\n",
      "================================================================================\n",
      "Epoch 660/2000\n",
      "Loss is:0.1191, Train_accuracy is 96.4983%, Test_accuracy is 96.1100%\n",
      "================================================================================\n",
      "Epoch 661/2000\n",
      "Loss is:0.1186, Train_accuracy is 96.5400%, Test_accuracy is 96.3000%\n",
      "================================================================================\n",
      "Epoch 662/2000\n",
      "Loss is:0.1177, Train_accuracy is 96.5333%, Test_accuracy is 96.1200%\n",
      "================================================================================\n",
      "Epoch 663/2000\n",
      "Loss is:0.1175, Train_accuracy is 96.6567%, Test_accuracy is 95.9600%\n",
      "================================================================================\n",
      "Epoch 664/2000\n",
      "Loss is:0.1185, Train_accuracy is 96.6000%, Test_accuracy is 96.0000%\n",
      "================================================================================\n",
      "Epoch 665/2000\n",
      "Loss is:0.1179, Train_accuracy is 96.5383%, Test_accuracy is 96.1000%\n",
      "================================================================================\n",
      "Epoch 666/2000\n",
      "Loss is:0.1182, Train_accuracy is 96.5100%, Test_accuracy is 95.9300%\n",
      "================================================================================\n",
      "Epoch 667/2000\n",
      "Loss is:0.1173, Train_accuracy is 96.6117%, Test_accuracy is 96.0600%\n",
      "================================================================================\n",
      "Epoch 668/2000\n",
      "Loss is:0.1164, Train_accuracy is 96.6083%, Test_accuracy is 95.8900%\n",
      "================================================================================\n",
      "Epoch 669/2000\n",
      "Loss is:0.1169, Train_accuracy is 96.5983%, Test_accuracy is 96.0900%\n",
      "================================================================================\n",
      "Epoch 670/2000\n",
      "Loss is:0.1172, Train_accuracy is 96.5800%, Test_accuracy is 96.0000%\n",
      "================================================================================\n",
      "Epoch 671/2000\n",
      "Loss is:0.1168, Train_accuracy is 96.5883%, Test_accuracy is 96.1700%\n",
      "================================================================================\n",
      "Epoch 672/2000\n",
      "Loss is:0.1181, Train_accuracy is 96.5183%, Test_accuracy is 96.0200%\n",
      "================================================================================\n",
      "Epoch 673/2000\n",
      "Loss is:0.1156, Train_accuracy is 96.5967%, Test_accuracy is 95.9800%\n",
      "================================================================================\n",
      "Epoch 674/2000\n",
      "Loss is:0.1155, Train_accuracy is 96.6567%, Test_accuracy is 96.1800%\n",
      "================================================================================\n",
      "Epoch 675/2000\n",
      "Loss is:0.1156, Train_accuracy is 96.6400%, Test_accuracy is 96.1800%\n",
      "================================================================================\n",
      "Epoch 676/2000\n",
      "Loss is:0.1159, Train_accuracy is 96.6033%, Test_accuracy is 95.9900%\n",
      "================================================================================\n",
      "Epoch 677/2000\n",
      "Loss is:0.1148, Train_accuracy is 96.6583%, Test_accuracy is 96.1800%\n",
      "================================================================================\n",
      "Epoch 678/2000\n",
      "Loss is:0.1159, Train_accuracy is 96.7167%, Test_accuracy is 96.0600%\n",
      "================================================================================\n",
      "Epoch 679/2000\n",
      "Loss is:0.1155, Train_accuracy is 96.6250%, Test_accuracy is 96.2600%\n",
      "================================================================================\n",
      "Epoch 680/2000\n",
      "Loss is:0.1143, Train_accuracy is 96.6733%, Test_accuracy is 95.9400%\n",
      "================================================================================\n",
      "Epoch 681/2000\n",
      "Loss is:0.1138, Train_accuracy is 96.6850%, Test_accuracy is 96.1900%\n",
      "================================================================================\n",
      "Epoch 682/2000\n",
      "Loss is:0.1148, Train_accuracy is 96.5950%, Test_accuracy is 96.2000%\n",
      "================================================================================\n",
      "Epoch 683/2000\n",
      "Loss is:0.1151, Train_accuracy is 96.6750%, Test_accuracy is 96.2400%\n",
      "================================================================================\n",
      "Epoch 684/2000\n",
      "Loss is:0.1140, Train_accuracy is 96.6450%, Test_accuracy is 96.1100%\n",
      "================================================================================\n",
      "Epoch 685/2000\n",
      "Loss is:0.1145, Train_accuracy is 96.7300%, Test_accuracy is 96.1800%\n",
      "================================================================================\n",
      "Epoch 686/2000\n",
      "Loss is:0.1144, Train_accuracy is 96.6567%, Test_accuracy is 96.2100%\n",
      "================================================================================\n",
      "Epoch 687/2000\n",
      "Loss is:0.1146, Train_accuracy is 96.6433%, Test_accuracy is 96.1400%\n",
      "================================================================================\n",
      "Epoch 688/2000\n",
      "Loss is:0.1135, Train_accuracy is 96.6967%, Test_accuracy is 96.2200%\n",
      "================================================================================\n",
      "Epoch 689/2000\n",
      "Loss is:0.1146, Train_accuracy is 96.6817%, Test_accuracy is 96.1800%\n",
      "================================================================================\n",
      "Epoch 690/2000\n",
      "Loss is:0.1131, Train_accuracy is 96.7083%, Test_accuracy is 96.1700%\n",
      "================================================================================\n",
      "Epoch 691/2000\n",
      "Loss is:0.1141, Train_accuracy is 96.6117%, Test_accuracy is 96.2600%\n",
      "================================================================================\n",
      "Epoch 692/2000\n",
      "Loss is:0.1127, Train_accuracy is 96.6900%, Test_accuracy is 96.1100%\n",
      "================================================================================\n",
      "Epoch 693/2000\n",
      "Loss is:0.1119, Train_accuracy is 96.7217%, Test_accuracy is 96.0700%\n",
      "================================================================================\n",
      "Epoch 694/2000\n",
      "Loss is:0.1127, Train_accuracy is 96.7050%, Test_accuracy is 96.2000%\n",
      "================================================================================\n",
      "Epoch 695/2000\n",
      "Loss is:0.1118, Train_accuracy is 96.8133%, Test_accuracy is 96.2200%\n",
      "================================================================================\n",
      "Epoch 696/2000\n",
      "Loss is:0.1117, Train_accuracy is 96.7267%, Test_accuracy is 96.1200%\n",
      "================================================================================\n",
      "Epoch 697/2000\n",
      "Loss is:0.1127, Train_accuracy is 96.7467%, Test_accuracy is 96.1700%\n",
      "================================================================================\n",
      "Epoch 698/2000\n",
      "Loss is:0.1133, Train_accuracy is 96.6717%, Test_accuracy is 96.3600%\n",
      "================================================================================\n",
      "Epoch 699/2000\n",
      "Loss is:0.1119, Train_accuracy is 96.7017%, Test_accuracy is 96.2200%\n",
      "================================================================================\n",
      "Epoch 700/2000\n",
      "Loss is:0.1110, Train_accuracy is 96.7517%, Test_accuracy is 96.2300%\n",
      "================================================================================\n",
      "Epoch 701/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1122, Train_accuracy is 96.7233%, Test_accuracy is 96.3900%\n",
      "================================================================================\n",
      "Epoch 702/2000\n",
      "Loss is:0.1123, Train_accuracy is 96.7067%, Test_accuracy is 96.2700%\n",
      "================================================================================\n",
      "Epoch 703/2000\n",
      "Loss is:0.1113, Train_accuracy is 96.7133%, Test_accuracy is 96.1100%\n",
      "================================================================================\n",
      "Epoch 704/2000\n",
      "Loss is:0.1111, Train_accuracy is 96.7483%, Test_accuracy is 96.0000%\n",
      "================================================================================\n",
      "Epoch 705/2000\n",
      "Loss is:0.1100, Train_accuracy is 96.8583%, Test_accuracy is 96.1800%\n",
      "================================================================================\n",
      "Epoch 706/2000\n",
      "Loss is:0.1108, Train_accuracy is 96.7750%, Test_accuracy is 96.0100%\n",
      "================================================================================\n",
      "Epoch 707/2000\n",
      "Loss is:0.1107, Train_accuracy is 96.8150%, Test_accuracy is 96.2500%\n",
      "================================================================================\n",
      "Epoch 708/2000\n",
      "Loss is:0.1113, Train_accuracy is 96.7617%, Test_accuracy is 96.1600%\n",
      "================================================================================\n",
      "Epoch 709/2000\n",
      "Loss is:0.1110, Train_accuracy is 96.7667%, Test_accuracy is 96.2100%\n",
      "================================================================================\n",
      "Epoch 710/2000\n",
      "Loss is:0.1094, Train_accuracy is 96.8083%, Test_accuracy is 96.3100%\n",
      "================================================================================\n",
      "Epoch 711/2000\n",
      "Loss is:0.1105, Train_accuracy is 96.8150%, Test_accuracy is 96.0300%\n",
      "================================================================================\n",
      "Epoch 712/2000\n",
      "Loss is:0.1101, Train_accuracy is 96.8533%, Test_accuracy is 96.1200%\n",
      "================================================================================\n",
      "Epoch 713/2000\n",
      "Loss is:0.1112, Train_accuracy is 96.7217%, Test_accuracy is 96.3000%\n",
      "================================================================================\n",
      "Epoch 714/2000\n",
      "Loss is:0.1099, Train_accuracy is 96.7383%, Test_accuracy is 96.2400%\n",
      "================================================================================\n",
      "Epoch 715/2000\n",
      "Loss is:0.1089, Train_accuracy is 96.8233%, Test_accuracy is 96.2500%\n",
      "================================================================================\n",
      "Epoch 716/2000\n",
      "Loss is:0.1089, Train_accuracy is 96.8300%, Test_accuracy is 96.2900%\n",
      "================================================================================\n",
      "Epoch 717/2000\n",
      "Loss is:0.1103, Train_accuracy is 96.7867%, Test_accuracy is 96.0100%\n",
      "================================================================================\n",
      "Epoch 718/2000\n",
      "Loss is:0.1110, Train_accuracy is 96.7450%, Test_accuracy is 96.0600%\n",
      "================================================================================\n",
      "Epoch 719/2000\n",
      "Loss is:0.1093, Train_accuracy is 96.7933%, Test_accuracy is 96.2300%\n",
      "================================================================================\n",
      "Epoch 720/2000\n",
      "Loss is:0.1085, Train_accuracy is 96.8800%, Test_accuracy is 96.4100%\n",
      "================================================================================\n",
      "Epoch 721/2000\n",
      "Loss is:0.1083, Train_accuracy is 96.8067%, Test_accuracy is 96.1500%\n",
      "================================================================================\n",
      "Epoch 722/2000\n",
      "Loss is:0.1095, Train_accuracy is 96.7767%, Test_accuracy is 96.1000%\n",
      "================================================================================\n",
      "Epoch 723/2000\n",
      "Loss is:0.1079, Train_accuracy is 96.8333%, Test_accuracy is 96.2800%\n",
      "================================================================================\n",
      "Epoch 724/2000\n",
      "Loss is:0.1088, Train_accuracy is 96.8017%, Test_accuracy is 96.3400%\n",
      "================================================================================\n",
      "Epoch 725/2000\n",
      "Loss is:0.1085, Train_accuracy is 96.8167%, Test_accuracy is 96.2700%\n",
      "================================================================================\n",
      "Epoch 726/2000\n",
      "Loss is:0.1088, Train_accuracy is 96.8533%, Test_accuracy is 96.2900%\n",
      "================================================================================\n",
      "Epoch 727/2000\n",
      "Loss is:0.1077, Train_accuracy is 96.8567%, Test_accuracy is 96.2700%\n",
      "================================================================================\n",
      "Epoch 728/2000\n",
      "Loss is:0.1086, Train_accuracy is 96.7850%, Test_accuracy is 96.2000%\n",
      "================================================================================\n",
      "Epoch 729/2000\n",
      "Loss is:0.1076, Train_accuracy is 96.7933%, Test_accuracy is 96.2300%\n",
      "================================================================================\n",
      "Epoch 730/2000\n",
      "Loss is:0.1076, Train_accuracy is 96.8450%, Test_accuracy is 96.2100%\n",
      "================================================================================\n",
      "Epoch 731/2000\n",
      "Loss is:0.1069, Train_accuracy is 96.9150%, Test_accuracy is 96.3400%\n",
      "================================================================================\n",
      "Epoch 732/2000\n",
      "Loss is:0.1077, Train_accuracy is 96.8500%, Test_accuracy is 96.1000%\n",
      "================================================================================\n",
      "Epoch 733/2000\n",
      "Loss is:0.1075, Train_accuracy is 96.8917%, Test_accuracy is 96.3300%\n",
      "================================================================================\n",
      "Epoch 734/2000\n",
      "Loss is:0.1063, Train_accuracy is 96.9283%, Test_accuracy is 96.2700%\n",
      "================================================================================\n",
      "Epoch 735/2000\n",
      "Loss is:0.1066, Train_accuracy is 96.8500%, Test_accuracy is 96.3400%\n",
      "================================================================================\n",
      "Epoch 736/2000\n",
      "Loss is:0.1077, Train_accuracy is 96.8417%, Test_accuracy is 96.2800%\n",
      "================================================================================\n",
      "Epoch 737/2000\n",
      "Loss is:0.1053, Train_accuracy is 96.9250%, Test_accuracy is 96.3500%\n",
      "================================================================================\n",
      "Epoch 738/2000\n",
      "Loss is:0.1060, Train_accuracy is 96.9050%, Test_accuracy is 96.2100%\n",
      "================================================================================\n",
      "Epoch 739/2000\n",
      "Loss is:0.1073, Train_accuracy is 96.8583%, Test_accuracy is 96.2100%\n",
      "================================================================================\n",
      "Epoch 740/2000\n",
      "Loss is:0.1053, Train_accuracy is 96.9450%, Test_accuracy is 96.3700%\n",
      "================================================================================\n",
      "Epoch 741/2000\n",
      "Loss is:0.1057, Train_accuracy is 96.8550%, Test_accuracy is 96.1700%\n",
      "================================================================================\n",
      "Epoch 742/2000\n",
      "Loss is:0.1050, Train_accuracy is 97.0100%, Test_accuracy is 96.3900%\n",
      "================================================================================\n",
      "Epoch 743/2000\n",
      "Loss is:0.1065, Train_accuracy is 96.8533%, Test_accuracy is 96.2200%\n",
      "================================================================================\n",
      "Epoch 744/2000\n",
      "Loss is:0.1058, Train_accuracy is 96.9750%, Test_accuracy is 96.1900%\n",
      "================================================================================\n",
      "Epoch 745/2000\n",
      "Loss is:0.1045, Train_accuracy is 96.9333%, Test_accuracy is 96.3000%\n",
      "================================================================================\n",
      "Epoch 746/2000\n",
      "Loss is:0.1049, Train_accuracy is 96.9717%, Test_accuracy is 96.3300%\n",
      "================================================================================\n",
      "Epoch 747/2000\n",
      "Loss is:0.1063, Train_accuracy is 96.8767%, Test_accuracy is 96.2900%\n",
      "================================================================================\n",
      "Epoch 748/2000\n",
      "Loss is:0.1050, Train_accuracy is 96.9233%, Test_accuracy is 96.2400%\n",
      "================================================================================\n",
      "Epoch 749/2000\n",
      "Loss is:0.1039, Train_accuracy is 96.9933%, Test_accuracy is 96.1200%\n",
      "================================================================================\n",
      "Epoch 750/2000\n",
      "Loss is:0.1028, Train_accuracy is 97.0133%, Test_accuracy is 96.4300%\n",
      "================================================================================\n",
      "Epoch 751/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.1029, Train_accuracy is 96.9833%, Test_accuracy is 96.3900%\n",
      "================================================================================\n",
      "Epoch 752/2000\n",
      "Loss is:0.1041, Train_accuracy is 96.9850%, Test_accuracy is 96.3300%\n",
      "================================================================================\n",
      "Epoch 753/2000\n",
      "Loss is:0.1040, Train_accuracy is 96.9650%, Test_accuracy is 96.5400%\n",
      "================================================================================\n",
      "Epoch 754/2000\n",
      "Loss is:0.1046, Train_accuracy is 96.9417%, Test_accuracy is 96.3300%\n",
      "================================================================================\n",
      "Epoch 755/2000\n",
      "Loss is:0.1037, Train_accuracy is 96.9717%, Test_accuracy is 96.5400%\n",
      "================================================================================\n",
      "Epoch 756/2000\n",
      "Loss is:0.1034, Train_accuracy is 96.9500%, Test_accuracy is 96.3300%\n",
      "================================================================================\n",
      "Epoch 757/2000\n",
      "Loss is:0.1026, Train_accuracy is 97.0217%, Test_accuracy is 96.4100%\n",
      "================================================================================\n",
      "Epoch 758/2000\n",
      "Loss is:0.1039, Train_accuracy is 96.9450%, Test_accuracy is 96.2900%\n",
      "================================================================================\n",
      "Epoch 759/2000\n",
      "Loss is:0.1026, Train_accuracy is 97.0167%, Test_accuracy is 96.4300%\n",
      "================================================================================\n",
      "Epoch 760/2000\n",
      "Loss is:0.1030, Train_accuracy is 96.9667%, Test_accuracy is 96.4500%\n",
      "================================================================================\n",
      "Epoch 761/2000\n",
      "Loss is:0.1028, Train_accuracy is 96.9983%, Test_accuracy is 96.3300%\n",
      "================================================================================\n",
      "Epoch 762/2000\n",
      "Loss is:0.1034, Train_accuracy is 97.0250%, Test_accuracy is 96.4500%\n",
      "================================================================================\n",
      "Epoch 763/2000\n",
      "Loss is:0.1023, Train_accuracy is 96.9917%, Test_accuracy is 96.1700%\n",
      "================================================================================\n",
      "Epoch 764/2000\n",
      "Loss is:0.1035, Train_accuracy is 96.9500%, Test_accuracy is 96.5300%\n",
      "================================================================================\n",
      "Epoch 765/2000\n",
      "Loss is:0.1024, Train_accuracy is 97.0283%, Test_accuracy is 96.5300%\n",
      "================================================================================\n",
      "Epoch 766/2000\n",
      "Loss is:0.1023, Train_accuracy is 97.0167%, Test_accuracy is 96.4300%\n",
      "================================================================================\n",
      "Epoch 767/2000\n",
      "Loss is:0.1012, Train_accuracy is 96.9617%, Test_accuracy is 96.3000%\n",
      "================================================================================\n",
      "Epoch 768/2000\n",
      "Loss is:0.1016, Train_accuracy is 97.0750%, Test_accuracy is 96.4400%\n",
      "================================================================================\n",
      "Epoch 769/2000\n",
      "Loss is:0.1013, Train_accuracy is 97.0950%, Test_accuracy is 96.3800%\n",
      "================================================================================\n",
      "Epoch 770/2000\n",
      "Loss is:0.1015, Train_accuracy is 97.0567%, Test_accuracy is 96.3700%\n",
      "================================================================================\n",
      "Epoch 771/2000\n",
      "Loss is:0.1014, Train_accuracy is 96.9950%, Test_accuracy is 96.5800%\n",
      "================================================================================\n",
      "Epoch 772/2000\n",
      "Loss is:0.1003, Train_accuracy is 97.0550%, Test_accuracy is 96.4700%\n",
      "================================================================================\n",
      "Epoch 773/2000\n",
      "Loss is:0.1006, Train_accuracy is 97.0550%, Test_accuracy is 96.3000%\n",
      "================================================================================\n",
      "Epoch 774/2000\n",
      "Loss is:0.1004, Train_accuracy is 97.0483%, Test_accuracy is 96.4900%\n",
      "================================================================================\n",
      "Epoch 775/2000\n",
      "Loss is:0.0996, Train_accuracy is 97.0950%, Test_accuracy is 96.4300%\n",
      "================================================================================\n",
      "Epoch 776/2000\n",
      "Loss is:0.1004, Train_accuracy is 97.0117%, Test_accuracy is 96.3800%\n",
      "================================================================================\n",
      "Epoch 777/2000\n",
      "Loss is:0.1001, Train_accuracy is 97.0883%, Test_accuracy is 96.2800%\n",
      "================================================================================\n",
      "Epoch 778/2000\n",
      "Loss is:0.0998, Train_accuracy is 97.0550%, Test_accuracy is 96.5900%\n",
      "================================================================================\n",
      "Epoch 779/2000\n",
      "Loss is:0.1012, Train_accuracy is 97.0067%, Test_accuracy is 96.4200%\n",
      "================================================================================\n",
      "Epoch 780/2000\n",
      "Loss is:0.1003, Train_accuracy is 97.0567%, Test_accuracy is 96.4400%\n",
      "================================================================================\n",
      "Epoch 781/2000\n",
      "Loss is:0.0989, Train_accuracy is 97.1117%, Test_accuracy is 96.5800%\n",
      "================================================================================\n",
      "Epoch 782/2000\n",
      "Loss is:0.1002, Train_accuracy is 97.0367%, Test_accuracy is 96.4900%\n",
      "================================================================================\n",
      "Epoch 783/2000\n",
      "Loss is:0.1007, Train_accuracy is 97.0867%, Test_accuracy is 96.4900%\n",
      "================================================================================\n",
      "Epoch 784/2000\n",
      "Loss is:0.0997, Train_accuracy is 97.0817%, Test_accuracy is 96.4700%\n",
      "================================================================================\n",
      "Epoch 785/2000\n",
      "Loss is:0.0999, Train_accuracy is 97.0617%, Test_accuracy is 96.4800%\n",
      "================================================================================\n",
      "Epoch 786/2000\n",
      "Loss is:0.0987, Train_accuracy is 97.1783%, Test_accuracy is 96.2800%\n",
      "================================================================================\n",
      "Epoch 787/2000\n",
      "Loss is:0.0994, Train_accuracy is 97.1300%, Test_accuracy is 96.3600%\n",
      "================================================================================\n",
      "Epoch 788/2000\n",
      "Loss is:0.0990, Train_accuracy is 97.1133%, Test_accuracy is 96.3800%\n",
      "================================================================================\n",
      "Epoch 789/2000\n",
      "Loss is:0.0994, Train_accuracy is 97.0783%, Test_accuracy is 96.3100%\n",
      "================================================================================\n",
      "Epoch 790/2000\n",
      "Loss is:0.0981, Train_accuracy is 97.0800%, Test_accuracy is 96.3700%\n",
      "================================================================================\n",
      "Epoch 791/2000\n",
      "Loss is:0.0990, Train_accuracy is 97.0833%, Test_accuracy is 96.2800%\n",
      "================================================================================\n",
      "Epoch 792/2000\n",
      "Loss is:0.0983, Train_accuracy is 97.1367%, Test_accuracy is 96.4600%\n",
      "================================================================================\n",
      "Epoch 793/2000\n",
      "Loss is:0.1002, Train_accuracy is 97.1067%, Test_accuracy is 96.5200%\n",
      "================================================================================\n",
      "Epoch 794/2000\n",
      "Loss is:0.0970, Train_accuracy is 97.1583%, Test_accuracy is 96.3200%\n",
      "================================================================================\n",
      "Epoch 795/2000\n",
      "Loss is:0.0984, Train_accuracy is 97.0933%, Test_accuracy is 96.4100%\n",
      "================================================================================\n",
      "Epoch 796/2000\n",
      "Loss is:0.0974, Train_accuracy is 97.1783%, Test_accuracy is 96.6200%\n",
      "================================================================================\n",
      "Epoch 797/2000\n",
      "Loss is:0.0974, Train_accuracy is 97.1467%, Test_accuracy is 96.2900%\n",
      "================================================================================\n",
      "Epoch 798/2000\n",
      "Loss is:0.0988, Train_accuracy is 97.1350%, Test_accuracy is 96.5400%\n",
      "================================================================================\n",
      "Epoch 799/2000\n",
      "Loss is:0.0989, Train_accuracy is 97.1067%, Test_accuracy is 96.3700%\n",
      "================================================================================\n",
      "Epoch 800/2000\n",
      "Loss is:0.0988, Train_accuracy is 97.1183%, Test_accuracy is 96.3900%\n",
      "================================================================================\n",
      "Epoch 801/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0973, Train_accuracy is 97.0933%, Test_accuracy is 96.5400%\n",
      "================================================================================\n",
      "Epoch 802/2000\n",
      "Loss is:0.0967, Train_accuracy is 97.1350%, Test_accuracy is 96.3300%\n",
      "================================================================================\n",
      "Epoch 803/2000\n",
      "Loss is:0.0974, Train_accuracy is 97.0967%, Test_accuracy is 96.6500%\n",
      "================================================================================\n",
      "Epoch 804/2000\n",
      "Loss is:0.0977, Train_accuracy is 97.1167%, Test_accuracy is 96.3100%\n",
      "================================================================================\n",
      "Epoch 805/2000\n",
      "Loss is:0.0964, Train_accuracy is 97.1217%, Test_accuracy is 96.2800%\n",
      "================================================================================\n",
      "Epoch 806/2000\n",
      "Loss is:0.0984, Train_accuracy is 97.1017%, Test_accuracy is 96.6400%\n",
      "================================================================================\n",
      "Epoch 807/2000\n",
      "Loss is:0.0963, Train_accuracy is 97.2367%, Test_accuracy is 96.5200%\n",
      "================================================================================\n",
      "Epoch 808/2000\n",
      "Loss is:0.0966, Train_accuracy is 97.1917%, Test_accuracy is 96.7300%\n",
      "================================================================================\n",
      "Epoch 809/2000\n",
      "Loss is:0.0969, Train_accuracy is 97.1450%, Test_accuracy is 96.4700%\n",
      "================================================================================\n",
      "Epoch 810/2000\n",
      "Loss is:0.0965, Train_accuracy is 97.2200%, Test_accuracy is 96.4900%\n",
      "================================================================================\n",
      "Epoch 811/2000\n",
      "Loss is:0.0970, Train_accuracy is 97.1600%, Test_accuracy is 96.5700%\n",
      "================================================================================\n",
      "Epoch 812/2000\n",
      "Loss is:0.0962, Train_accuracy is 97.2267%, Test_accuracy is 96.4100%\n",
      "================================================================================\n",
      "Epoch 813/2000\n",
      "Loss is:0.0974, Train_accuracy is 97.1367%, Test_accuracy is 96.4700%\n",
      "================================================================================\n",
      "Epoch 814/2000\n",
      "Loss is:0.0958, Train_accuracy is 97.1550%, Test_accuracy is 96.6100%\n",
      "================================================================================\n",
      "Epoch 815/2000\n",
      "Loss is:0.0954, Train_accuracy is 97.2650%, Test_accuracy is 96.5000%\n",
      "================================================================================\n",
      "Epoch 816/2000\n",
      "Loss is:0.0957, Train_accuracy is 97.2383%, Test_accuracy is 96.4800%\n",
      "================================================================================\n",
      "Epoch 817/2000\n",
      "Loss is:0.0949, Train_accuracy is 97.2500%, Test_accuracy is 96.5100%\n",
      "================================================================================\n",
      "Epoch 818/2000\n",
      "Loss is:0.0942, Train_accuracy is 97.2383%, Test_accuracy is 96.6500%\n",
      "================================================================================\n",
      "Epoch 819/2000\n",
      "Loss is:0.0945, Train_accuracy is 97.2867%, Test_accuracy is 96.5300%\n",
      "================================================================================\n",
      "Epoch 820/2000\n",
      "Loss is:0.0945, Train_accuracy is 97.2633%, Test_accuracy is 96.5100%\n",
      "================================================================================\n",
      "Epoch 821/2000\n",
      "Loss is:0.0950, Train_accuracy is 97.2567%, Test_accuracy is 96.4800%\n",
      "================================================================================\n",
      "Epoch 822/2000\n",
      "Loss is:0.0941, Train_accuracy is 97.2683%, Test_accuracy is 96.5400%\n",
      "================================================================================\n",
      "Epoch 823/2000\n",
      "Loss is:0.0952, Train_accuracy is 97.2100%, Test_accuracy is 96.5200%\n",
      "================================================================================\n",
      "Epoch 824/2000\n",
      "Loss is:0.0942, Train_accuracy is 97.2400%, Test_accuracy is 96.5300%\n",
      "================================================================================\n",
      "Epoch 825/2000\n",
      "Loss is:0.0947, Train_accuracy is 97.2167%, Test_accuracy is 96.5100%\n",
      "================================================================================\n",
      "Epoch 826/2000\n",
      "Loss is:0.0946, Train_accuracy is 97.2500%, Test_accuracy is 96.5300%\n",
      "================================================================================\n",
      "Epoch 827/2000\n",
      "Loss is:0.0950, Train_accuracy is 97.2350%, Test_accuracy is 96.4500%\n",
      "================================================================================\n",
      "Epoch 828/2000\n",
      "Loss is:0.0945, Train_accuracy is 97.2417%, Test_accuracy is 96.6400%\n",
      "================================================================================\n",
      "Epoch 829/2000\n",
      "Loss is:0.0948, Train_accuracy is 97.2450%, Test_accuracy is 96.4400%\n",
      "================================================================================\n",
      "Epoch 830/2000\n",
      "Loss is:0.0940, Train_accuracy is 97.1833%, Test_accuracy is 96.5200%\n",
      "================================================================================\n",
      "Epoch 831/2000\n",
      "Loss is:0.0941, Train_accuracy is 97.2750%, Test_accuracy is 96.5600%\n",
      "================================================================================\n",
      "Epoch 832/2000\n",
      "Loss is:0.0938, Train_accuracy is 97.2483%, Test_accuracy is 96.4900%\n",
      "================================================================================\n",
      "Epoch 833/2000\n",
      "Loss is:0.0940, Train_accuracy is 97.2733%, Test_accuracy is 96.4200%\n",
      "================================================================================\n",
      "Epoch 834/2000\n",
      "Loss is:0.0941, Train_accuracy is 97.2467%, Test_accuracy is 96.4300%\n",
      "================================================================================\n",
      "Epoch 835/2000\n",
      "Loss is:0.0951, Train_accuracy is 97.2167%, Test_accuracy is 96.4700%\n",
      "================================================================================\n",
      "Epoch 836/2000\n",
      "Loss is:0.0924, Train_accuracy is 97.3167%, Test_accuracy is 96.4700%\n",
      "================================================================================\n",
      "Epoch 837/2000\n",
      "Loss is:0.0941, Train_accuracy is 97.1783%, Test_accuracy is 96.5200%\n",
      "================================================================================\n",
      "Epoch 838/2000\n",
      "Loss is:0.0932, Train_accuracy is 97.2567%, Test_accuracy is 96.3800%\n",
      "================================================================================\n",
      "Epoch 839/2000\n",
      "Loss is:0.0925, Train_accuracy is 97.2767%, Test_accuracy is 96.6500%\n",
      "================================================================================\n",
      "Epoch 840/2000\n",
      "Loss is:0.0921, Train_accuracy is 97.3650%, Test_accuracy is 96.8200%\n",
      "================================================================================\n",
      "Epoch 841/2000\n",
      "Loss is:0.0920, Train_accuracy is 97.2850%, Test_accuracy is 96.5500%\n",
      "================================================================================\n",
      "Epoch 842/2000\n",
      "Loss is:0.0927, Train_accuracy is 97.2883%, Test_accuracy is 96.4700%\n",
      "================================================================================\n",
      "Epoch 843/2000\n",
      "Loss is:0.0935, Train_accuracy is 97.2917%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 844/2000\n",
      "Loss is:0.0923, Train_accuracy is 97.2967%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 845/2000\n",
      "Loss is:0.0907, Train_accuracy is 97.3867%, Test_accuracy is 96.5400%\n",
      "================================================================================\n",
      "Epoch 846/2000\n",
      "Loss is:0.0915, Train_accuracy is 97.3500%, Test_accuracy is 96.5200%\n",
      "================================================================================\n",
      "Epoch 847/2000\n",
      "Loss is:0.0913, Train_accuracy is 97.3700%, Test_accuracy is 96.4800%\n",
      "================================================================================\n",
      "Epoch 848/2000\n",
      "Loss is:0.0914, Train_accuracy is 97.3517%, Test_accuracy is 96.6300%\n",
      "================================================================================\n",
      "Epoch 849/2000\n",
      "Loss is:0.0918, Train_accuracy is 97.3567%, Test_accuracy is 96.5200%\n",
      "================================================================================\n",
      "Epoch 850/2000\n",
      "Loss is:0.0914, Train_accuracy is 97.3000%, Test_accuracy is 96.5300%\n",
      "================================================================================\n",
      "Epoch 851/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0925, Train_accuracy is 97.3117%, Test_accuracy is 96.7400%\n",
      "================================================================================\n",
      "Epoch 852/2000\n",
      "Loss is:0.0925, Train_accuracy is 97.2717%, Test_accuracy is 96.5900%\n",
      "================================================================================\n",
      "Epoch 853/2000\n",
      "Loss is:0.0924, Train_accuracy is 97.3317%, Test_accuracy is 96.5300%\n",
      "================================================================================\n",
      "Epoch 854/2000\n",
      "Loss is:0.0909, Train_accuracy is 97.3267%, Test_accuracy is 96.4500%\n",
      "================================================================================\n",
      "Epoch 855/2000\n",
      "Loss is:0.0906, Train_accuracy is 97.3567%, Test_accuracy is 96.6500%\n",
      "================================================================================\n",
      "Epoch 856/2000\n",
      "Loss is:0.0912, Train_accuracy is 97.3150%, Test_accuracy is 96.5700%\n",
      "================================================================================\n",
      "Epoch 857/2000\n",
      "Loss is:0.0903, Train_accuracy is 97.3150%, Test_accuracy is 96.7100%\n",
      "================================================================================\n",
      "Epoch 858/2000\n",
      "Loss is:0.0912, Train_accuracy is 97.3333%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 859/2000\n",
      "Loss is:0.0908, Train_accuracy is 97.3083%, Test_accuracy is 96.7900%\n",
      "================================================================================\n",
      "Epoch 860/2000\n",
      "Loss is:0.0903, Train_accuracy is 97.3050%, Test_accuracy is 96.5600%\n",
      "================================================================================\n",
      "Epoch 861/2000\n",
      "Loss is:0.0909, Train_accuracy is 97.3917%, Test_accuracy is 96.6900%\n",
      "================================================================================\n",
      "Epoch 862/2000\n",
      "Loss is:0.0908, Train_accuracy is 97.3400%, Test_accuracy is 96.7700%\n",
      "================================================================================\n",
      "Epoch 863/2000\n",
      "Loss is:0.0895, Train_accuracy is 97.3900%, Test_accuracy is 96.7800%\n",
      "================================================================================\n",
      "Epoch 864/2000\n",
      "Loss is:0.0901, Train_accuracy is 97.3150%, Test_accuracy is 96.5900%\n",
      "================================================================================\n",
      "Epoch 865/2000\n",
      "Loss is:0.0903, Train_accuracy is 97.3683%, Test_accuracy is 96.5400%\n",
      "================================================================================\n",
      "Epoch 866/2000\n",
      "Loss is:0.0898, Train_accuracy is 97.3850%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 867/2000\n",
      "Loss is:0.0905, Train_accuracy is 97.3733%, Test_accuracy is 96.5100%\n",
      "================================================================================\n",
      "Epoch 868/2000\n",
      "Loss is:0.0879, Train_accuracy is 97.3900%, Test_accuracy is 96.6800%\n",
      "================================================================================\n",
      "Epoch 869/2000\n",
      "Loss is:0.0894, Train_accuracy is 97.3867%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 870/2000\n",
      "Loss is:0.0898, Train_accuracy is 97.4100%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 871/2000\n",
      "Loss is:0.0887, Train_accuracy is 97.3867%, Test_accuracy is 96.5000%\n",
      "================================================================================\n",
      "Epoch 872/2000\n",
      "Loss is:0.0893, Train_accuracy is 97.3917%, Test_accuracy is 96.5800%\n",
      "================================================================================\n",
      "Epoch 873/2000\n",
      "Loss is:0.0892, Train_accuracy is 97.4200%, Test_accuracy is 96.6000%\n",
      "================================================================================\n",
      "Epoch 874/2000\n",
      "Loss is:0.0889, Train_accuracy is 97.3717%, Test_accuracy is 96.6500%\n",
      "================================================================================\n",
      "Epoch 875/2000\n",
      "Loss is:0.0886, Train_accuracy is 97.4300%, Test_accuracy is 96.6000%\n",
      "================================================================================\n",
      "Epoch 876/2000\n",
      "Loss is:0.0883, Train_accuracy is 97.4067%, Test_accuracy is 96.5800%\n",
      "================================================================================\n",
      "Epoch 877/2000\n",
      "Loss is:0.0890, Train_accuracy is 97.3983%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 878/2000\n",
      "Loss is:0.0881, Train_accuracy is 97.3833%, Test_accuracy is 96.4400%\n",
      "================================================================================\n",
      "Epoch 879/2000\n",
      "Loss is:0.0882, Train_accuracy is 97.3883%, Test_accuracy is 96.5600%\n",
      "================================================================================\n",
      "Epoch 880/2000\n",
      "Loss is:0.0875, Train_accuracy is 97.4150%, Test_accuracy is 96.5500%\n",
      "================================================================================\n",
      "Epoch 881/2000\n",
      "Loss is:0.0884, Train_accuracy is 97.4367%, Test_accuracy is 96.4300%\n",
      "================================================================================\n",
      "Epoch 882/2000\n",
      "Loss is:0.0890, Train_accuracy is 97.3817%, Test_accuracy is 96.7900%\n",
      "================================================================================\n",
      "Epoch 883/2000\n",
      "Loss is:0.0893, Train_accuracy is 97.4450%, Test_accuracy is 96.6200%\n",
      "================================================================================\n",
      "Epoch 884/2000\n",
      "Loss is:0.0875, Train_accuracy is 97.4917%, Test_accuracy is 96.6600%\n",
      "================================================================================\n",
      "Epoch 885/2000\n",
      "Loss is:0.0869, Train_accuracy is 97.4750%, Test_accuracy is 96.5800%\n",
      "================================================================================\n",
      "Epoch 886/2000\n",
      "Loss is:0.0885, Train_accuracy is 97.4050%, Test_accuracy is 96.6700%\n",
      "================================================================================\n",
      "Epoch 887/2000\n",
      "Loss is:0.0894, Train_accuracy is 97.3683%, Test_accuracy is 96.7100%\n",
      "================================================================================\n",
      "Epoch 888/2000\n",
      "Loss is:0.0892, Train_accuracy is 97.3750%, Test_accuracy is 96.7300%\n",
      "================================================================================\n",
      "Epoch 889/2000\n",
      "Loss is:0.0867, Train_accuracy is 97.4967%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 890/2000\n",
      "Loss is:0.0885, Train_accuracy is 97.4217%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 891/2000\n",
      "Loss is:0.0872, Train_accuracy is 97.4667%, Test_accuracy is 96.6100%\n",
      "================================================================================\n",
      "Epoch 892/2000\n",
      "Loss is:0.0870, Train_accuracy is 97.4533%, Test_accuracy is 96.6900%\n",
      "================================================================================\n",
      "Epoch 893/2000\n",
      "Loss is:0.0878, Train_accuracy is 97.4233%, Test_accuracy is 96.7100%\n",
      "================================================================================\n",
      "Epoch 894/2000\n",
      "Loss is:0.0875, Train_accuracy is 97.4783%, Test_accuracy is 96.6900%\n",
      "================================================================================\n",
      "Epoch 895/2000\n",
      "Loss is:0.0880, Train_accuracy is 97.4150%, Test_accuracy is 96.6800%\n",
      "================================================================================\n",
      "Epoch 896/2000\n",
      "Loss is:0.0864, Train_accuracy is 97.4783%, Test_accuracy is 96.6100%\n",
      "================================================================================\n",
      "Epoch 897/2000\n",
      "Loss is:0.0866, Train_accuracy is 97.4367%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 898/2000\n",
      "Loss is:0.0864, Train_accuracy is 97.4800%, Test_accuracy is 96.6800%\n",
      "================================================================================\n",
      "Epoch 899/2000\n",
      "Loss is:0.0874, Train_accuracy is 97.4833%, Test_accuracy is 96.6400%\n",
      "================================================================================\n",
      "Epoch 900/2000\n",
      "Loss is:0.0865, Train_accuracy is 97.4617%, Test_accuracy is 96.7400%\n",
      "================================================================================\n",
      "Epoch 901/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0858, Train_accuracy is 97.4700%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 902/2000\n",
      "Loss is:0.0861, Train_accuracy is 97.4233%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 903/2000\n",
      "Loss is:0.0860, Train_accuracy is 97.5100%, Test_accuracy is 96.7800%\n",
      "================================================================================\n",
      "Epoch 904/2000\n",
      "Loss is:0.0856, Train_accuracy is 97.4850%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 905/2000\n",
      "Loss is:0.0861, Train_accuracy is 97.4100%, Test_accuracy is 96.5900%\n",
      "================================================================================\n",
      "Epoch 906/2000\n",
      "Loss is:0.0867, Train_accuracy is 97.4417%, Test_accuracy is 96.6400%\n",
      "================================================================================\n",
      "Epoch 907/2000\n",
      "Loss is:0.0848, Train_accuracy is 97.5100%, Test_accuracy is 96.8300%\n",
      "================================================================================\n",
      "Epoch 908/2000\n",
      "Loss is:0.0854, Train_accuracy is 97.5317%, Test_accuracy is 96.8200%\n",
      "================================================================================\n",
      "Epoch 909/2000\n",
      "Loss is:0.0854, Train_accuracy is 97.4600%, Test_accuracy is 96.7100%\n",
      "================================================================================\n",
      "Epoch 910/2000\n",
      "Loss is:0.0866, Train_accuracy is 97.5100%, Test_accuracy is 96.7900%\n",
      "================================================================================\n",
      "Epoch 911/2000\n",
      "Loss is:0.0857, Train_accuracy is 97.4650%, Test_accuracy is 96.7700%\n",
      "================================================================================\n",
      "Epoch 912/2000\n",
      "Loss is:0.0858, Train_accuracy is 97.4517%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 913/2000\n",
      "Loss is:0.0856, Train_accuracy is 97.5017%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 914/2000\n",
      "Loss is:0.0851, Train_accuracy is 97.5317%, Test_accuracy is 96.6800%\n",
      "================================================================================\n",
      "Epoch 915/2000\n",
      "Loss is:0.0844, Train_accuracy is 97.5183%, Test_accuracy is 96.6500%\n",
      "================================================================================\n",
      "Epoch 916/2000\n",
      "Loss is:0.0842, Train_accuracy is 97.5183%, Test_accuracy is 96.6900%\n",
      "================================================================================\n",
      "Epoch 917/2000\n",
      "Loss is:0.0859, Train_accuracy is 97.5133%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 918/2000\n",
      "Loss is:0.0845, Train_accuracy is 97.5233%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 919/2000\n",
      "Loss is:0.0834, Train_accuracy is 97.5633%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 920/2000\n",
      "Loss is:0.0824, Train_accuracy is 97.5550%, Test_accuracy is 96.8000%\n",
      "================================================================================\n",
      "Epoch 921/2000\n",
      "Loss is:0.0839, Train_accuracy is 97.5400%, Test_accuracy is 96.8300%\n",
      "================================================================================\n",
      "Epoch 922/2000\n",
      "Loss is:0.0842, Train_accuracy is 97.4883%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 923/2000\n",
      "Loss is:0.0852, Train_accuracy is 97.5117%, Test_accuracy is 96.7400%\n",
      "================================================================================\n",
      "Epoch 924/2000\n",
      "Loss is:0.0845, Train_accuracy is 97.5067%, Test_accuracy is 96.7300%\n",
      "================================================================================\n",
      "Epoch 925/2000\n",
      "Loss is:0.0837, Train_accuracy is 97.5767%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 926/2000\n",
      "Loss is:0.0840, Train_accuracy is 97.5200%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 927/2000\n",
      "Loss is:0.0831, Train_accuracy is 97.5467%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 928/2000\n",
      "Loss is:0.0839, Train_accuracy is 97.5400%, Test_accuracy is 96.7700%\n",
      "================================================================================\n",
      "Epoch 929/2000\n",
      "Loss is:0.0853, Train_accuracy is 97.4650%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 930/2000\n",
      "Loss is:0.0837, Train_accuracy is 97.5400%, Test_accuracy is 96.6600%\n",
      "================================================================================\n",
      "Epoch 931/2000\n",
      "Loss is:0.0836, Train_accuracy is 97.5600%, Test_accuracy is 96.7800%\n",
      "================================================================================\n",
      "Epoch 932/2000\n",
      "Loss is:0.0831, Train_accuracy is 97.5517%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 933/2000\n",
      "Loss is:0.0834, Train_accuracy is 97.5217%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 934/2000\n",
      "Loss is:0.0840, Train_accuracy is 97.6017%, Test_accuracy is 96.6100%\n",
      "================================================================================\n",
      "Epoch 935/2000\n",
      "Loss is:0.0848, Train_accuracy is 97.4550%, Test_accuracy is 96.7300%\n",
      "================================================================================\n",
      "Epoch 936/2000\n",
      "Loss is:0.0818, Train_accuracy is 97.5667%, Test_accuracy is 96.7800%\n",
      "================================================================================\n",
      "Epoch 937/2000\n",
      "Loss is:0.0822, Train_accuracy is 97.6300%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 938/2000\n",
      "Loss is:0.0816, Train_accuracy is 97.6267%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 939/2000\n",
      "Loss is:0.0828, Train_accuracy is 97.5867%, Test_accuracy is 96.7400%\n",
      "================================================================================\n",
      "Epoch 940/2000\n",
      "Loss is:0.0833, Train_accuracy is 97.5417%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 941/2000\n",
      "Loss is:0.0817, Train_accuracy is 97.5683%, Test_accuracy is 96.7100%\n",
      "================================================================================\n",
      "Epoch 942/2000\n",
      "Loss is:0.0808, Train_accuracy is 97.6050%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 943/2000\n",
      "Loss is:0.0829, Train_accuracy is 97.5583%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 944/2000\n",
      "Loss is:0.0817, Train_accuracy is 97.5350%, Test_accuracy is 96.6800%\n",
      "================================================================================\n",
      "Epoch 945/2000\n",
      "Loss is:0.0837, Train_accuracy is 97.5500%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 946/2000\n",
      "Loss is:0.0819, Train_accuracy is 97.5600%, Test_accuracy is 96.8000%\n",
      "================================================================================\n",
      "Epoch 947/2000\n",
      "Loss is:0.0820, Train_accuracy is 97.6183%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 948/2000\n",
      "Loss is:0.0824, Train_accuracy is 97.5533%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 949/2000\n",
      "Loss is:0.0812, Train_accuracy is 97.6033%, Test_accuracy is 96.6900%\n",
      "================================================================================\n",
      "Epoch 950/2000\n",
      "Loss is:0.0802, Train_accuracy is 97.6467%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 951/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0804, Train_accuracy is 97.6617%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 952/2000\n",
      "Loss is:0.0820, Train_accuracy is 97.5283%, Test_accuracy is 96.7600%\n",
      "================================================================================\n",
      "Epoch 953/2000\n",
      "Loss is:0.0821, Train_accuracy is 97.6100%, Test_accuracy is 96.9300%\n",
      "================================================================================\n",
      "Epoch 954/2000\n",
      "Loss is:0.0799, Train_accuracy is 97.6650%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 955/2000\n",
      "Loss is:0.0799, Train_accuracy is 97.6517%, Test_accuracy is 96.7600%\n",
      "================================================================================\n",
      "Epoch 956/2000\n",
      "Loss is:0.0802, Train_accuracy is 97.6383%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 957/2000\n",
      "Loss is:0.0808, Train_accuracy is 97.6083%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 958/2000\n",
      "Loss is:0.0822, Train_accuracy is 97.5633%, Test_accuracy is 96.7700%\n",
      "================================================================================\n",
      "Epoch 959/2000\n",
      "Loss is:0.0812, Train_accuracy is 97.6233%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 960/2000\n",
      "Loss is:0.0798, Train_accuracy is 97.6333%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 961/2000\n",
      "Loss is:0.0797, Train_accuracy is 97.6417%, Test_accuracy is 96.6200%\n",
      "================================================================================\n",
      "Epoch 962/2000\n",
      "Loss is:0.0796, Train_accuracy is 97.6750%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 963/2000\n",
      "Loss is:0.0809, Train_accuracy is 97.6500%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 964/2000\n",
      "Loss is:0.0806, Train_accuracy is 97.6483%, Test_accuracy is 96.7000%\n",
      "================================================================================\n",
      "Epoch 965/2000\n",
      "Loss is:0.0795, Train_accuracy is 97.6467%, Test_accuracy is 96.7400%\n",
      "================================================================================\n",
      "Epoch 966/2000\n",
      "Loss is:0.0799, Train_accuracy is 97.6200%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 967/2000\n",
      "Loss is:0.0794, Train_accuracy is 97.6517%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 968/2000\n",
      "Loss is:0.0797, Train_accuracy is 97.6467%, Test_accuracy is 96.6200%\n",
      "================================================================================\n",
      "Epoch 969/2000\n",
      "Loss is:0.0794, Train_accuracy is 97.6533%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 970/2000\n",
      "Loss is:0.0796, Train_accuracy is 97.6850%, Test_accuracy is 96.8600%\n",
      "================================================================================\n",
      "Epoch 971/2000\n",
      "Loss is:0.0803, Train_accuracy is 97.6400%, Test_accuracy is 96.6900%\n",
      "================================================================================\n",
      "Epoch 972/2000\n",
      "Loss is:0.0807, Train_accuracy is 97.6517%, Test_accuracy is 96.8200%\n",
      "================================================================================\n",
      "Epoch 973/2000\n",
      "Loss is:0.0793, Train_accuracy is 97.7117%, Test_accuracy is 96.8600%\n",
      "================================================================================\n",
      "Epoch 974/2000\n",
      "Loss is:0.0790, Train_accuracy is 97.6733%, Test_accuracy is 96.8600%\n",
      "================================================================================\n",
      "Epoch 975/2000\n",
      "Loss is:0.0789, Train_accuracy is 97.6717%, Test_accuracy is 96.9000%\n",
      "================================================================================\n",
      "Epoch 976/2000\n",
      "Loss is:0.0794, Train_accuracy is 97.6500%, Test_accuracy is 96.8200%\n",
      "================================================================================\n",
      "Epoch 977/2000\n",
      "Loss is:0.0800, Train_accuracy is 97.7017%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 978/2000\n",
      "Loss is:0.0788, Train_accuracy is 97.6500%, Test_accuracy is 96.7200%\n",
      "================================================================================\n",
      "Epoch 979/2000\n",
      "Loss is:0.0800, Train_accuracy is 97.6500%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 980/2000\n",
      "Loss is:0.0797, Train_accuracy is 97.6950%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 981/2000\n",
      "Loss is:0.0795, Train_accuracy is 97.6100%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 982/2000\n",
      "Loss is:0.0795, Train_accuracy is 97.6583%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 983/2000\n",
      "Loss is:0.0782, Train_accuracy is 97.7700%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 984/2000\n",
      "Loss is:0.0789, Train_accuracy is 97.6833%, Test_accuracy is 96.9000%\n",
      "================================================================================\n",
      "Epoch 985/2000\n",
      "Loss is:0.0789, Train_accuracy is 97.6367%, Test_accuracy is 96.7700%\n",
      "================================================================================\n",
      "Epoch 986/2000\n",
      "Loss is:0.0782, Train_accuracy is 97.7500%, Test_accuracy is 96.8200%\n",
      "================================================================================\n",
      "Epoch 987/2000\n",
      "Loss is:0.0785, Train_accuracy is 97.6750%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 988/2000\n",
      "Loss is:0.0776, Train_accuracy is 97.7600%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 989/2000\n",
      "Loss is:0.0788, Train_accuracy is 97.6933%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 990/2000\n",
      "Loss is:0.0784, Train_accuracy is 97.6750%, Test_accuracy is 96.8600%\n",
      "================================================================================\n",
      "Epoch 991/2000\n",
      "Loss is:0.0769, Train_accuracy is 97.7433%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 992/2000\n",
      "Loss is:0.0774, Train_accuracy is 97.7317%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 993/2000\n",
      "Loss is:0.0772, Train_accuracy is 97.7233%, Test_accuracy is 96.9700%\n",
      "================================================================================\n",
      "Epoch 994/2000\n",
      "Loss is:0.0774, Train_accuracy is 97.7100%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 995/2000\n",
      "Loss is:0.0772, Train_accuracy is 97.7650%, Test_accuracy is 96.9100%\n",
      "================================================================================\n",
      "Epoch 996/2000\n",
      "Loss is:0.0771, Train_accuracy is 97.7000%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 997/2000\n",
      "Loss is:0.0770, Train_accuracy is 97.7617%, Test_accuracy is 96.7100%\n",
      "================================================================================\n",
      "Epoch 998/2000\n",
      "Loss is:0.0768, Train_accuracy is 97.7200%, Test_accuracy is 96.7900%\n",
      "================================================================================\n",
      "Epoch 999/2000\n",
      "Loss is:0.0764, Train_accuracy is 97.7317%, Test_accuracy is 96.8600%\n",
      "================================================================================\n",
      "Epoch 1000/2000\n",
      "Loss is:0.0763, Train_accuracy is 97.7967%, Test_accuracy is 96.8600%\n",
      "================================================================================\n",
      "Epoch 1001/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0778, Train_accuracy is 97.7633%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1002/2000\n",
      "Loss is:0.0772, Train_accuracy is 97.7500%, Test_accuracy is 96.7700%\n",
      "================================================================================\n",
      "Epoch 1003/2000\n",
      "Loss is:0.0762, Train_accuracy is 97.7367%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 1004/2000\n",
      "Loss is:0.0766, Train_accuracy is 97.7217%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 1005/2000\n",
      "Loss is:0.0764, Train_accuracy is 97.7150%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1006/2000\n",
      "Loss is:0.0767, Train_accuracy is 97.7500%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 1007/2000\n",
      "Loss is:0.0770, Train_accuracy is 97.7733%, Test_accuracy is 96.7900%\n",
      "================================================================================\n",
      "Epoch 1008/2000\n",
      "Loss is:0.0755, Train_accuracy is 97.8150%, Test_accuracy is 97.0200%\n",
      "================================================================================\n",
      "Epoch 1009/2000\n",
      "Loss is:0.0761, Train_accuracy is 97.7717%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1010/2000\n",
      "Loss is:0.0759, Train_accuracy is 97.7883%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 1011/2000\n",
      "Loss is:0.0757, Train_accuracy is 97.7517%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1012/2000\n",
      "Loss is:0.0759, Train_accuracy is 97.7567%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 1013/2000\n",
      "Loss is:0.0747, Train_accuracy is 97.8383%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 1014/2000\n",
      "Loss is:0.0735, Train_accuracy is 97.9200%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1015/2000\n",
      "Loss is:0.0764, Train_accuracy is 97.7767%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1016/2000\n",
      "Loss is:0.0759, Train_accuracy is 97.7433%, Test_accuracy is 96.9000%\n",
      "================================================================================\n",
      "Epoch 1017/2000\n",
      "Loss is:0.0763, Train_accuracy is 97.7100%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 1018/2000\n",
      "Loss is:0.0752, Train_accuracy is 97.7683%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1019/2000\n",
      "Loss is:0.0762, Train_accuracy is 97.7783%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 1020/2000\n",
      "Loss is:0.0745, Train_accuracy is 97.8083%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 1021/2000\n",
      "Loss is:0.0746, Train_accuracy is 97.8200%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 1022/2000\n",
      "Loss is:0.0754, Train_accuracy is 97.7617%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1023/2000\n",
      "Loss is:0.0751, Train_accuracy is 97.8000%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1024/2000\n",
      "Loss is:0.0755, Train_accuracy is 97.7433%, Test_accuracy is 96.7900%\n",
      "================================================================================\n",
      "Epoch 1025/2000\n",
      "Loss is:0.0734, Train_accuracy is 97.8450%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1026/2000\n",
      "Loss is:0.0745, Train_accuracy is 97.8283%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1027/2000\n",
      "Loss is:0.0734, Train_accuracy is 97.8517%, Test_accuracy is 96.8200%\n",
      "================================================================================\n",
      "Epoch 1028/2000\n",
      "Loss is:0.0738, Train_accuracy is 97.8200%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1029/2000\n",
      "Loss is:0.0746, Train_accuracy is 97.7717%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 1030/2000\n",
      "Loss is:0.0745, Train_accuracy is 97.8400%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 1031/2000\n",
      "Loss is:0.0747, Train_accuracy is 97.8050%, Test_accuracy is 96.8200%\n",
      "================================================================================\n",
      "Epoch 1032/2000\n",
      "Loss is:0.0739, Train_accuracy is 97.8900%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1033/2000\n",
      "Loss is:0.0749, Train_accuracy is 97.8400%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1034/2000\n",
      "Loss is:0.0731, Train_accuracy is 97.8683%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1035/2000\n",
      "Loss is:0.0745, Train_accuracy is 97.8250%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1036/2000\n",
      "Loss is:0.0744, Train_accuracy is 97.7583%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1037/2000\n",
      "Loss is:0.0743, Train_accuracy is 97.8183%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1038/2000\n",
      "Loss is:0.0730, Train_accuracy is 97.8400%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1039/2000\n",
      "Loss is:0.0742, Train_accuracy is 97.7700%, Test_accuracy is 96.8300%\n",
      "================================================================================\n",
      "Epoch 1040/2000\n",
      "Loss is:0.0735, Train_accuracy is 97.8533%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 1041/2000\n",
      "Loss is:0.0732, Train_accuracy is 97.8367%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 1042/2000\n",
      "Loss is:0.0748, Train_accuracy is 97.7483%, Test_accuracy is 96.9800%\n",
      "================================================================================\n",
      "Epoch 1043/2000\n",
      "Loss is:0.0735, Train_accuracy is 97.8383%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1044/2000\n",
      "Loss is:0.0735, Train_accuracy is 97.8250%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1045/2000\n",
      "Loss is:0.0740, Train_accuracy is 97.7850%, Test_accuracy is 96.8800%\n",
      "================================================================================\n",
      "Epoch 1046/2000\n",
      "Loss is:0.0739, Train_accuracy is 97.8517%, Test_accuracy is 96.9800%\n",
      "================================================================================\n",
      "Epoch 1047/2000\n",
      "Loss is:0.0746, Train_accuracy is 97.8617%, Test_accuracy is 97.0200%\n",
      "================================================================================\n",
      "Epoch 1048/2000\n",
      "Loss is:0.0737, Train_accuracy is 97.8633%, Test_accuracy is 96.9300%\n",
      "================================================================================\n",
      "Epoch 1049/2000\n",
      "Loss is:0.0726, Train_accuracy is 97.8517%, Test_accuracy is 96.7800%\n",
      "================================================================================\n",
      "Epoch 1050/2000\n",
      "Loss is:0.0731, Train_accuracy is 97.8500%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 1051/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0725, Train_accuracy is 97.8683%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 1052/2000\n",
      "Loss is:0.0738, Train_accuracy is 97.8683%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1053/2000\n",
      "Loss is:0.0722, Train_accuracy is 97.8800%, Test_accuracy is 97.0400%\n",
      "================================================================================\n",
      "Epoch 1054/2000\n",
      "Loss is:0.0710, Train_accuracy is 97.9050%, Test_accuracy is 97.0200%\n",
      "================================================================================\n",
      "Epoch 1055/2000\n",
      "Loss is:0.0712, Train_accuracy is 97.9567%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1056/2000\n",
      "Loss is:0.0725, Train_accuracy is 97.8600%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1057/2000\n",
      "Loss is:0.0727, Train_accuracy is 97.8867%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 1058/2000\n",
      "Loss is:0.0732, Train_accuracy is 97.7967%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1059/2000\n",
      "Loss is:0.0724, Train_accuracy is 97.8433%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1060/2000\n",
      "Loss is:0.0717, Train_accuracy is 97.8650%, Test_accuracy is 96.9100%\n",
      "================================================================================\n",
      "Epoch 1061/2000\n",
      "Loss is:0.0729, Train_accuracy is 97.8517%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1062/2000\n",
      "Loss is:0.0708, Train_accuracy is 97.9050%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1063/2000\n",
      "Loss is:0.0722, Train_accuracy is 97.8900%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1064/2000\n",
      "Loss is:0.0715, Train_accuracy is 97.8700%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1065/2000\n",
      "Loss is:0.0706, Train_accuracy is 97.9433%, Test_accuracy is 96.9000%\n",
      "================================================================================\n",
      "Epoch 1066/2000\n",
      "Loss is:0.0710, Train_accuracy is 97.9083%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1067/2000\n",
      "Loss is:0.0708, Train_accuracy is 97.9367%, Test_accuracy is 96.7500%\n",
      "================================================================================\n",
      "Epoch 1068/2000\n",
      "Loss is:0.0713, Train_accuracy is 97.8883%, Test_accuracy is 96.9300%\n",
      "================================================================================\n",
      "Epoch 1069/2000\n",
      "Loss is:0.0698, Train_accuracy is 97.9383%, Test_accuracy is 97.0200%\n",
      "================================================================================\n",
      "Epoch 1070/2000\n",
      "Loss is:0.0726, Train_accuracy is 97.8583%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1071/2000\n",
      "Loss is:0.0711, Train_accuracy is 97.8883%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1072/2000\n",
      "Loss is:0.0723, Train_accuracy is 97.7933%, Test_accuracy is 96.7900%\n",
      "================================================================================\n",
      "Epoch 1073/2000\n",
      "Loss is:0.0708, Train_accuracy is 97.9450%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1074/2000\n",
      "Loss is:0.0718, Train_accuracy is 97.8533%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1075/2000\n",
      "Loss is:0.0703, Train_accuracy is 97.9750%, Test_accuracy is 96.8900%\n",
      "================================================================================\n",
      "Epoch 1076/2000\n",
      "Loss is:0.0704, Train_accuracy is 97.8917%, Test_accuracy is 97.0200%\n",
      "================================================================================\n",
      "Epoch 1077/2000\n",
      "Loss is:0.0725, Train_accuracy is 97.8467%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1078/2000\n",
      "Loss is:0.0718, Train_accuracy is 97.9267%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1079/2000\n",
      "Loss is:0.0703, Train_accuracy is 97.9167%, Test_accuracy is 96.8100%\n",
      "================================================================================\n",
      "Epoch 1080/2000\n",
      "Loss is:0.0709, Train_accuracy is 97.8750%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1081/2000\n",
      "Loss is:0.0708, Train_accuracy is 97.9350%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1082/2000\n",
      "Loss is:0.0701, Train_accuracy is 97.8867%, Test_accuracy is 96.8500%\n",
      "================================================================================\n",
      "Epoch 1083/2000\n",
      "Loss is:0.0708, Train_accuracy is 97.9667%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1084/2000\n",
      "Loss is:0.0699, Train_accuracy is 97.9267%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1085/2000\n",
      "Loss is:0.0698, Train_accuracy is 97.9817%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 1086/2000\n",
      "Loss is:0.0706, Train_accuracy is 97.8950%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 1087/2000\n",
      "Loss is:0.0707, Train_accuracy is 97.9533%, Test_accuracy is 96.9100%\n",
      "================================================================================\n",
      "Epoch 1088/2000\n",
      "Loss is:0.0703, Train_accuracy is 97.8767%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 1089/2000\n",
      "Loss is:0.0708, Train_accuracy is 97.9250%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1090/2000\n",
      "Loss is:0.0702, Train_accuracy is 97.9617%, Test_accuracy is 96.8600%\n",
      "================================================================================\n",
      "Epoch 1091/2000\n",
      "Loss is:0.0711, Train_accuracy is 97.9200%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1092/2000\n",
      "Loss is:0.0702, Train_accuracy is 97.9317%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1093/2000\n",
      "Loss is:0.0700, Train_accuracy is 98.0033%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1094/2000\n",
      "Loss is:0.0688, Train_accuracy is 97.9900%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1095/2000\n",
      "Loss is:0.0699, Train_accuracy is 97.9317%, Test_accuracy is 96.9300%\n",
      "================================================================================\n",
      "Epoch 1096/2000\n",
      "Loss is:0.0700, Train_accuracy is 97.9767%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1097/2000\n",
      "Loss is:0.0687, Train_accuracy is 97.9733%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1098/2000\n",
      "Loss is:0.0694, Train_accuracy is 97.9900%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1099/2000\n",
      "Loss is:0.0692, Train_accuracy is 97.9150%, Test_accuracy is 97.0400%\n",
      "================================================================================\n",
      "Epoch 1100/2000\n",
      "Loss is:0.0683, Train_accuracy is 98.0183%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1101/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0683, Train_accuracy is 97.9800%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1102/2000\n",
      "Loss is:0.0693, Train_accuracy is 97.9700%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1103/2000\n",
      "Loss is:0.0689, Train_accuracy is 97.9717%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1104/2000\n",
      "Loss is:0.0685, Train_accuracy is 97.9867%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1105/2000\n",
      "Loss is:0.0681, Train_accuracy is 98.0383%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1106/2000\n",
      "Loss is:0.0697, Train_accuracy is 97.9483%, Test_accuracy is 97.0900%\n",
      "================================================================================\n",
      "Epoch 1107/2000\n",
      "Loss is:0.0686, Train_accuracy is 98.0517%, Test_accuracy is 96.9300%\n",
      "================================================================================\n",
      "Epoch 1108/2000\n",
      "Loss is:0.0675, Train_accuracy is 97.9867%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1109/2000\n",
      "Loss is:0.0681, Train_accuracy is 97.9683%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1110/2000\n",
      "Loss is:0.0694, Train_accuracy is 97.9650%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1111/2000\n",
      "Loss is:0.0695, Train_accuracy is 97.9383%, Test_accuracy is 96.9300%\n",
      "================================================================================\n",
      "Epoch 1112/2000\n",
      "Loss is:0.0688, Train_accuracy is 97.9850%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1113/2000\n",
      "Loss is:0.0680, Train_accuracy is 98.0233%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1114/2000\n",
      "Loss is:0.0676, Train_accuracy is 98.0650%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1115/2000\n",
      "Loss is:0.0680, Train_accuracy is 97.9983%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1116/2000\n",
      "Loss is:0.0678, Train_accuracy is 97.9717%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1117/2000\n",
      "Loss is:0.0683, Train_accuracy is 98.0367%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1118/2000\n",
      "Loss is:0.0680, Train_accuracy is 97.9617%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 1119/2000\n",
      "Loss is:0.0677, Train_accuracy is 98.0617%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1120/2000\n",
      "Loss is:0.0680, Train_accuracy is 97.9833%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1121/2000\n",
      "Loss is:0.0679, Train_accuracy is 98.0100%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1122/2000\n",
      "Loss is:0.0681, Train_accuracy is 97.9983%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1123/2000\n",
      "Loss is:0.0675, Train_accuracy is 98.0367%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1124/2000\n",
      "Loss is:0.0674, Train_accuracy is 98.0000%, Test_accuracy is 96.9700%\n",
      "================================================================================\n",
      "Epoch 1125/2000\n",
      "Loss is:0.0677, Train_accuracy is 97.9633%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1126/2000\n",
      "Loss is:0.0663, Train_accuracy is 98.0650%, Test_accuracy is 97.0400%\n",
      "================================================================================\n",
      "Epoch 1127/2000\n",
      "Loss is:0.0658, Train_accuracy is 98.0683%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1128/2000\n",
      "Loss is:0.0688, Train_accuracy is 98.0117%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1129/2000\n",
      "Loss is:0.0679, Train_accuracy is 98.0233%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1130/2000\n",
      "Loss is:0.0667, Train_accuracy is 98.0467%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1131/2000\n",
      "Loss is:0.0676, Train_accuracy is 98.0033%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1132/2000\n",
      "Loss is:0.0649, Train_accuracy is 98.1150%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1133/2000\n",
      "Loss is:0.0665, Train_accuracy is 98.0150%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1134/2000\n",
      "Loss is:0.0663, Train_accuracy is 98.0850%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1135/2000\n",
      "Loss is:0.0662, Train_accuracy is 98.0267%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 1136/2000\n",
      "Loss is:0.0669, Train_accuracy is 98.0050%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1137/2000\n",
      "Loss is:0.0669, Train_accuracy is 98.0267%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1138/2000\n",
      "Loss is:0.0659, Train_accuracy is 98.1067%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1139/2000\n",
      "Loss is:0.0663, Train_accuracy is 98.0550%, Test_accuracy is 97.0200%\n",
      "================================================================================\n",
      "Epoch 1140/2000\n",
      "Loss is:0.0661, Train_accuracy is 98.1167%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1141/2000\n",
      "Loss is:0.0663, Train_accuracy is 98.0550%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1142/2000\n",
      "Loss is:0.0651, Train_accuracy is 98.0917%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1143/2000\n",
      "Loss is:0.0665, Train_accuracy is 98.0050%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1144/2000\n",
      "Loss is:0.0669, Train_accuracy is 97.9883%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1145/2000\n",
      "Loss is:0.0654, Train_accuracy is 98.0750%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1146/2000\n",
      "Loss is:0.0660, Train_accuracy is 98.0517%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1147/2000\n",
      "Loss is:0.0658, Train_accuracy is 98.0033%, Test_accuracy is 96.8700%\n",
      "================================================================================\n",
      "Epoch 1148/2000\n",
      "Loss is:0.0646, Train_accuracy is 98.0450%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1149/2000\n",
      "Loss is:0.0659, Train_accuracy is 98.0100%, Test_accuracy is 96.8400%\n",
      "================================================================================\n",
      "Epoch 1150/2000\n",
      "Loss is:0.0664, Train_accuracy is 98.0717%, Test_accuracy is 97.0900%\n",
      "================================================================================\n",
      "Epoch 1151/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0658, Train_accuracy is 98.0350%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1152/2000\n",
      "Loss is:0.0660, Train_accuracy is 98.0300%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1153/2000\n",
      "Loss is:0.0664, Train_accuracy is 98.0150%, Test_accuracy is 97.0400%\n",
      "================================================================================\n",
      "Epoch 1154/2000\n",
      "Loss is:0.0652, Train_accuracy is 98.0533%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1155/2000\n",
      "Loss is:0.0643, Train_accuracy is 98.0683%, Test_accuracy is 97.0900%\n",
      "================================================================================\n",
      "Epoch 1156/2000\n",
      "Loss is:0.0646, Train_accuracy is 98.1017%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1157/2000\n",
      "Loss is:0.0647, Train_accuracy is 98.1250%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1158/2000\n",
      "Loss is:0.0657, Train_accuracy is 98.0733%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1159/2000\n",
      "Loss is:0.0651, Train_accuracy is 98.0683%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1160/2000\n",
      "Loss is:0.0657, Train_accuracy is 98.0917%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1161/2000\n",
      "Loss is:0.0641, Train_accuracy is 98.0983%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1162/2000\n",
      "Loss is:0.0654, Train_accuracy is 98.0650%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1163/2000\n",
      "Loss is:0.0658, Train_accuracy is 98.0433%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1164/2000\n",
      "Loss is:0.0640, Train_accuracy is 98.0583%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1165/2000\n",
      "Loss is:0.0647, Train_accuracy is 98.1067%, Test_accuracy is 96.9000%\n",
      "================================================================================\n",
      "Epoch 1166/2000\n",
      "Loss is:0.0632, Train_accuracy is 98.1917%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1167/2000\n",
      "Loss is:0.0642, Train_accuracy is 98.1200%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1168/2000\n",
      "Loss is:0.0640, Train_accuracy is 98.1033%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1169/2000\n",
      "Loss is:0.0644, Train_accuracy is 98.1067%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1170/2000\n",
      "Loss is:0.0642, Train_accuracy is 98.0917%, Test_accuracy is 96.9400%\n",
      "================================================================================\n",
      "Epoch 1171/2000\n",
      "Loss is:0.0652, Train_accuracy is 98.0850%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1172/2000\n",
      "Loss is:0.0641, Train_accuracy is 98.1000%, Test_accuracy is 97.0400%\n",
      "================================================================================\n",
      "Epoch 1173/2000\n",
      "Loss is:0.0647, Train_accuracy is 98.0667%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1174/2000\n",
      "Loss is:0.0637, Train_accuracy is 98.0850%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1175/2000\n",
      "Loss is:0.0637, Train_accuracy is 98.1317%, Test_accuracy is 96.9600%\n",
      "================================================================================\n",
      "Epoch 1176/2000\n",
      "Loss is:0.0638, Train_accuracy is 98.1367%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1177/2000\n",
      "Loss is:0.0644, Train_accuracy is 98.0750%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1178/2000\n",
      "Loss is:0.0640, Train_accuracy is 98.1200%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1179/2000\n",
      "Loss is:0.0634, Train_accuracy is 98.1150%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1180/2000\n",
      "Loss is:0.0629, Train_accuracy is 98.1633%, Test_accuracy is 97.0400%\n",
      "================================================================================\n",
      "Epoch 1181/2000\n",
      "Loss is:0.0642, Train_accuracy is 98.0750%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1182/2000\n",
      "Loss is:0.0638, Train_accuracy is 98.0917%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1183/2000\n",
      "Loss is:0.0631, Train_accuracy is 98.1333%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1184/2000\n",
      "Loss is:0.0637, Train_accuracy is 98.0950%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1185/2000\n",
      "Loss is:0.0625, Train_accuracy is 98.1917%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1186/2000\n",
      "Loss is:0.0645, Train_accuracy is 98.1150%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1187/2000\n",
      "Loss is:0.0637, Train_accuracy is 98.0733%, Test_accuracy is 97.0900%\n",
      "================================================================================\n",
      "Epoch 1188/2000\n",
      "Loss is:0.0618, Train_accuracy is 98.1567%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1189/2000\n",
      "Loss is:0.0626, Train_accuracy is 98.1533%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1190/2000\n",
      "Loss is:0.0618, Train_accuracy is 98.2033%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1191/2000\n",
      "Loss is:0.0623, Train_accuracy is 98.1917%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1192/2000\n",
      "Loss is:0.0621, Train_accuracy is 98.1783%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1193/2000\n",
      "Loss is:0.0622, Train_accuracy is 98.1600%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1194/2000\n",
      "Loss is:0.0619, Train_accuracy is 98.2050%, Test_accuracy is 96.9200%\n",
      "================================================================================\n",
      "Epoch 1195/2000\n",
      "Loss is:0.0637, Train_accuracy is 98.0933%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1196/2000\n",
      "Loss is:0.0619, Train_accuracy is 98.1917%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1197/2000\n",
      "Loss is:0.0630, Train_accuracy is 98.1333%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1198/2000\n",
      "Loss is:0.0622, Train_accuracy is 98.1350%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1199/2000\n",
      "Loss is:0.0626, Train_accuracy is 98.1383%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1200/2000\n",
      "Loss is:0.0629, Train_accuracy is 98.1400%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1201/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0625, Train_accuracy is 98.2083%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1202/2000\n",
      "Loss is:0.0620, Train_accuracy is 98.1333%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1203/2000\n",
      "Loss is:0.0629, Train_accuracy is 98.1767%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1204/2000\n",
      "Loss is:0.0614, Train_accuracy is 98.2367%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1205/2000\n",
      "Loss is:0.0626, Train_accuracy is 98.1617%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1206/2000\n",
      "Loss is:0.0623, Train_accuracy is 98.1350%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1207/2000\n",
      "Loss is:0.0626, Train_accuracy is 98.0967%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1208/2000\n",
      "Loss is:0.0614, Train_accuracy is 98.2033%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1209/2000\n",
      "Loss is:0.0612, Train_accuracy is 98.1800%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1210/2000\n",
      "Loss is:0.0612, Train_accuracy is 98.1633%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1211/2000\n",
      "Loss is:0.0624, Train_accuracy is 98.1000%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1212/2000\n",
      "Loss is:0.0620, Train_accuracy is 98.2183%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1213/2000\n",
      "Loss is:0.0622, Train_accuracy is 98.1567%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1214/2000\n",
      "Loss is:0.0618, Train_accuracy is 98.2000%, Test_accuracy is 96.9800%\n",
      "================================================================================\n",
      "Epoch 1215/2000\n",
      "Loss is:0.0608, Train_accuracy is 98.2000%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1216/2000\n",
      "Loss is:0.0611, Train_accuracy is 98.1700%, Test_accuracy is 97.0000%\n",
      "================================================================================\n",
      "Epoch 1217/2000\n",
      "Loss is:0.0626, Train_accuracy is 98.1350%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1218/2000\n",
      "Loss is:0.0607, Train_accuracy is 98.2217%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1219/2000\n",
      "Loss is:0.0598, Train_accuracy is 98.2350%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1220/2000\n",
      "Loss is:0.0612, Train_accuracy is 98.2267%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1221/2000\n",
      "Loss is:0.0605, Train_accuracy is 98.1867%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1222/2000\n",
      "Loss is:0.0599, Train_accuracy is 98.2250%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1223/2000\n",
      "Loss is:0.0611, Train_accuracy is 98.2300%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1224/2000\n",
      "Loss is:0.0595, Train_accuracy is 98.2517%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1225/2000\n",
      "Loss is:0.0614, Train_accuracy is 98.2817%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1226/2000\n",
      "Loss is:0.0605, Train_accuracy is 98.2367%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1227/2000\n",
      "Loss is:0.0596, Train_accuracy is 98.2233%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1228/2000\n",
      "Loss is:0.0605, Train_accuracy is 98.1700%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1229/2000\n",
      "Loss is:0.0597, Train_accuracy is 98.1617%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1230/2000\n",
      "Loss is:0.0606, Train_accuracy is 98.2317%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1231/2000\n",
      "Loss is:0.0605, Train_accuracy is 98.1533%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1232/2000\n",
      "Loss is:0.0602, Train_accuracy is 98.2267%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1233/2000\n",
      "Loss is:0.0620, Train_accuracy is 98.1400%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1234/2000\n",
      "Loss is:0.0606, Train_accuracy is 98.2217%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1235/2000\n",
      "Loss is:0.0607, Train_accuracy is 98.2150%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1236/2000\n",
      "Loss is:0.0601, Train_accuracy is 98.2233%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1237/2000\n",
      "Loss is:0.0610, Train_accuracy is 98.1667%, Test_accuracy is 96.9800%\n",
      "================================================================================\n",
      "Epoch 1238/2000\n",
      "Loss is:0.0598, Train_accuracy is 98.2317%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1239/2000\n",
      "Loss is:0.0601, Train_accuracy is 98.2417%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1240/2000\n",
      "Loss is:0.0594, Train_accuracy is 98.2400%, Test_accuracy is 97.0300%\n",
      "================================================================================\n",
      "Epoch 1241/2000\n",
      "Loss is:0.0600, Train_accuracy is 98.2850%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1242/2000\n",
      "Loss is:0.0609, Train_accuracy is 98.1717%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1243/2000\n",
      "Loss is:0.0595, Train_accuracy is 98.2533%, Test_accuracy is 97.0100%\n",
      "================================================================================\n",
      "Epoch 1244/2000\n",
      "Loss is:0.0593, Train_accuracy is 98.2150%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1245/2000\n",
      "Loss is:0.0598, Train_accuracy is 98.2083%, Test_accuracy is 97.0200%\n",
      "================================================================================\n",
      "Epoch 1246/2000\n",
      "Loss is:0.0600, Train_accuracy is 98.1833%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1247/2000\n",
      "Loss is:0.0600, Train_accuracy is 98.1650%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1248/2000\n",
      "Loss is:0.0594, Train_accuracy is 98.2517%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1249/2000\n",
      "Loss is:0.0583, Train_accuracy is 98.3133%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1250/2000\n",
      "Loss is:0.0600, Train_accuracy is 98.1967%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1251/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0592, Train_accuracy is 98.3183%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1252/2000\n",
      "Loss is:0.0593, Train_accuracy is 98.2883%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1253/2000\n",
      "Loss is:0.0600, Train_accuracy is 98.2450%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1254/2000\n",
      "Loss is:0.0598, Train_accuracy is 98.2450%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1255/2000\n",
      "Loss is:0.0593, Train_accuracy is 98.2167%, Test_accuracy is 96.9900%\n",
      "================================================================================\n",
      "Epoch 1256/2000\n",
      "Loss is:0.0586, Train_accuracy is 98.2950%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1257/2000\n",
      "Loss is:0.0585, Train_accuracy is 98.2667%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1258/2000\n",
      "Loss is:0.0589, Train_accuracy is 98.1633%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1259/2000\n",
      "Loss is:0.0598, Train_accuracy is 98.2283%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1260/2000\n",
      "Loss is:0.0583, Train_accuracy is 98.2817%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1261/2000\n",
      "Loss is:0.0602, Train_accuracy is 98.2433%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1262/2000\n",
      "Loss is:0.0586, Train_accuracy is 98.2833%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1263/2000\n",
      "Loss is:0.0581, Train_accuracy is 98.2800%, Test_accuracy is 97.0600%\n",
      "================================================================================\n",
      "Epoch 1264/2000\n",
      "Loss is:0.0587, Train_accuracy is 98.2350%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1265/2000\n",
      "Loss is:0.0579, Train_accuracy is 98.2633%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1266/2000\n",
      "Loss is:0.0580, Train_accuracy is 98.2700%, Test_accuracy is 97.1300%\n",
      "================================================================================\n",
      "Epoch 1267/2000\n",
      "Loss is:0.0583, Train_accuracy is 98.2483%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1268/2000\n",
      "Loss is:0.0575, Train_accuracy is 98.3817%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1269/2000\n",
      "Loss is:0.0587, Train_accuracy is 98.2800%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1270/2000\n",
      "Loss is:0.0577, Train_accuracy is 98.3167%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1271/2000\n",
      "Loss is:0.0589, Train_accuracy is 98.2683%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1272/2000\n",
      "Loss is:0.0582, Train_accuracy is 98.3317%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1273/2000\n",
      "Loss is:0.0585, Train_accuracy is 98.2567%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1274/2000\n",
      "Loss is:0.0581, Train_accuracy is 98.2683%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1275/2000\n",
      "Loss is:0.0588, Train_accuracy is 98.2750%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1276/2000\n",
      "Loss is:0.0577, Train_accuracy is 98.3433%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1277/2000\n",
      "Loss is:0.0567, Train_accuracy is 98.2867%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1278/2000\n",
      "Loss is:0.0577, Train_accuracy is 98.3367%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1279/2000\n",
      "Loss is:0.0578, Train_accuracy is 98.2900%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1280/2000\n",
      "Loss is:0.0573, Train_accuracy is 98.2983%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1281/2000\n",
      "Loss is:0.0571, Train_accuracy is 98.3067%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1282/2000\n",
      "Loss is:0.0565, Train_accuracy is 98.3500%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1283/2000\n",
      "Loss is:0.0580, Train_accuracy is 98.2883%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1284/2000\n",
      "Loss is:0.0574, Train_accuracy is 98.2883%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1285/2000\n",
      "Loss is:0.0572, Train_accuracy is 98.3250%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1286/2000\n",
      "Loss is:0.0572, Train_accuracy is 98.2900%, Test_accuracy is 96.9500%\n",
      "================================================================================\n",
      "Epoch 1287/2000\n",
      "Loss is:0.0564, Train_accuracy is 98.3600%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1288/2000\n",
      "Loss is:0.0570, Train_accuracy is 98.2900%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1289/2000\n",
      "Loss is:0.0579, Train_accuracy is 98.2183%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1290/2000\n",
      "Loss is:0.0565, Train_accuracy is 98.3483%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1291/2000\n",
      "Loss is:0.0588, Train_accuracy is 98.2400%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1292/2000\n",
      "Loss is:0.0571, Train_accuracy is 98.3883%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1293/2000\n",
      "Loss is:0.0569, Train_accuracy is 98.3217%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1294/2000\n",
      "Loss is:0.0568, Train_accuracy is 98.2983%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1295/2000\n",
      "Loss is:0.0570, Train_accuracy is 98.2717%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1296/2000\n",
      "Loss is:0.0581, Train_accuracy is 98.2700%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1297/2000\n",
      "Loss is:0.0564, Train_accuracy is 98.2767%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1298/2000\n",
      "Loss is:0.0565, Train_accuracy is 98.2850%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1299/2000\n",
      "Loss is:0.0570, Train_accuracy is 98.2917%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1300/2000\n",
      "Loss is:0.0572, Train_accuracy is 98.3300%, Test_accuracy is 97.0500%\n",
      "================================================================================\n",
      "Epoch 1301/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0566, Train_accuracy is 98.3433%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1302/2000\n",
      "Loss is:0.0555, Train_accuracy is 98.3617%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1303/2000\n",
      "Loss is:0.0574, Train_accuracy is 98.2633%, Test_accuracy is 97.0800%\n",
      "================================================================================\n",
      "Epoch 1304/2000\n",
      "Loss is:0.0559, Train_accuracy is 98.2900%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1305/2000\n",
      "Loss is:0.0555, Train_accuracy is 98.3867%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1306/2000\n",
      "Loss is:0.0568, Train_accuracy is 98.3183%, Test_accuracy is 97.0900%\n",
      "================================================================================\n",
      "Epoch 1307/2000\n",
      "Loss is:0.0554, Train_accuracy is 98.3883%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1308/2000\n",
      "Loss is:0.0558, Train_accuracy is 98.3950%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1309/2000\n",
      "Loss is:0.0562, Train_accuracy is 98.3233%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1310/2000\n",
      "Loss is:0.0559, Train_accuracy is 98.3850%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1311/2000\n",
      "Loss is:0.0561, Train_accuracy is 98.3383%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1312/2000\n",
      "Loss is:0.0559, Train_accuracy is 98.3267%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1313/2000\n",
      "Loss is:0.0560, Train_accuracy is 98.3217%, Test_accuracy is 97.0900%\n",
      "================================================================================\n",
      "Epoch 1314/2000\n",
      "Loss is:0.0545, Train_accuracy is 98.3467%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1315/2000\n",
      "Loss is:0.0561, Train_accuracy is 98.4300%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1316/2000\n",
      "Loss is:0.0562, Train_accuracy is 98.3317%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1317/2000\n",
      "Loss is:0.0558, Train_accuracy is 98.3483%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1318/2000\n",
      "Loss is:0.0549, Train_accuracy is 98.3317%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1319/2000\n",
      "Loss is:0.0557, Train_accuracy is 98.3483%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1320/2000\n",
      "Loss is:0.0564, Train_accuracy is 98.3450%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1321/2000\n",
      "Loss is:0.0553, Train_accuracy is 98.3500%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1322/2000\n",
      "Loss is:0.0548, Train_accuracy is 98.3367%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1323/2000\n",
      "Loss is:0.0547, Train_accuracy is 98.4083%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1324/2000\n",
      "Loss is:0.0554, Train_accuracy is 98.3717%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1325/2000\n",
      "Loss is:0.0542, Train_accuracy is 98.4517%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1326/2000\n",
      "Loss is:0.0549, Train_accuracy is 98.4150%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1327/2000\n",
      "Loss is:0.0554, Train_accuracy is 98.3300%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1328/2000\n",
      "Loss is:0.0555, Train_accuracy is 98.3783%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1329/2000\n",
      "Loss is:0.0550, Train_accuracy is 98.3550%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1330/2000\n",
      "Loss is:0.0547, Train_accuracy is 98.3933%, Test_accuracy is 97.0700%\n",
      "================================================================================\n",
      "Epoch 1331/2000\n",
      "Loss is:0.0549, Train_accuracy is 98.3717%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1332/2000\n",
      "Loss is:0.0532, Train_accuracy is 98.4383%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1333/2000\n",
      "Loss is:0.0552, Train_accuracy is 98.3333%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1334/2000\n",
      "Loss is:0.0547, Train_accuracy is 98.4233%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1335/2000\n",
      "Loss is:0.0545, Train_accuracy is 98.3983%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1336/2000\n",
      "Loss is:0.0544, Train_accuracy is 98.3700%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1337/2000\n",
      "Loss is:0.0545, Train_accuracy is 98.4050%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1338/2000\n",
      "Loss is:0.0543, Train_accuracy is 98.4333%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1339/2000\n",
      "Loss is:0.0538, Train_accuracy is 98.4533%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1340/2000\n",
      "Loss is:0.0547, Train_accuracy is 98.3450%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1341/2000\n",
      "Loss is:0.0537, Train_accuracy is 98.4050%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1342/2000\n",
      "Loss is:0.0549, Train_accuracy is 98.4183%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1343/2000\n",
      "Loss is:0.0558, Train_accuracy is 98.3050%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1344/2000\n",
      "Loss is:0.0543, Train_accuracy is 98.3583%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1345/2000\n",
      "Loss is:0.0548, Train_accuracy is 98.4233%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1346/2000\n",
      "Loss is:0.0551, Train_accuracy is 98.3667%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1347/2000\n",
      "Loss is:0.0531, Train_accuracy is 98.4500%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1348/2000\n",
      "Loss is:0.0545, Train_accuracy is 98.3800%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1349/2000\n",
      "Loss is:0.0550, Train_accuracy is 98.3500%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1350/2000\n",
      "Loss is:0.0536, Train_accuracy is 98.4100%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1351/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0532, Train_accuracy is 98.4917%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1352/2000\n",
      "Loss is:0.0543, Train_accuracy is 98.4067%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1353/2000\n",
      "Loss is:0.0537, Train_accuracy is 98.3900%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1354/2000\n",
      "Loss is:0.0532, Train_accuracy is 98.4583%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1355/2000\n",
      "Loss is:0.0541, Train_accuracy is 98.4033%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1356/2000\n",
      "Loss is:0.0533, Train_accuracy is 98.4100%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1357/2000\n",
      "Loss is:0.0531, Train_accuracy is 98.4233%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1358/2000\n",
      "Loss is:0.0546, Train_accuracy is 98.3633%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1359/2000\n",
      "Loss is:0.0536, Train_accuracy is 98.4233%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1360/2000\n",
      "Loss is:0.0546, Train_accuracy is 98.3933%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1361/2000\n",
      "Loss is:0.0541, Train_accuracy is 98.4400%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1362/2000\n",
      "Loss is:0.0532, Train_accuracy is 98.4467%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1363/2000\n",
      "Loss is:0.0523, Train_accuracy is 98.4117%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1364/2000\n",
      "Loss is:0.0523, Train_accuracy is 98.4417%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1365/2000\n",
      "Loss is:0.0536, Train_accuracy is 98.4433%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1366/2000\n",
      "Loss is:0.0526, Train_accuracy is 98.3983%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1367/2000\n",
      "Loss is:0.0530, Train_accuracy is 98.3950%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1368/2000\n",
      "Loss is:0.0537, Train_accuracy is 98.4100%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1369/2000\n",
      "Loss is:0.0526, Train_accuracy is 98.4433%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1370/2000\n",
      "Loss is:0.0529, Train_accuracy is 98.3933%, Test_accuracy is 97.1200%\n",
      "================================================================================\n",
      "Epoch 1371/2000\n",
      "Loss is:0.0518, Train_accuracy is 98.5617%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1372/2000\n",
      "Loss is:0.0526, Train_accuracy is 98.4317%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1373/2000\n",
      "Loss is:0.0525, Train_accuracy is 98.4983%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1374/2000\n",
      "Loss is:0.0527, Train_accuracy is 98.5067%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1375/2000\n",
      "Loss is:0.0513, Train_accuracy is 98.5067%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1376/2000\n",
      "Loss is:0.0533, Train_accuracy is 98.4250%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1377/2000\n",
      "Loss is:0.0524, Train_accuracy is 98.4300%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1378/2000\n",
      "Loss is:0.0519, Train_accuracy is 98.4717%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1379/2000\n",
      "Loss is:0.0531, Train_accuracy is 98.4133%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1380/2000\n",
      "Loss is:0.0530, Train_accuracy is 98.4300%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1381/2000\n",
      "Loss is:0.0518, Train_accuracy is 98.5250%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1382/2000\n",
      "Loss is:0.0522, Train_accuracy is 98.4900%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1383/2000\n",
      "Loss is:0.0528, Train_accuracy is 98.4200%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1384/2000\n",
      "Loss is:0.0518, Train_accuracy is 98.4567%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1385/2000\n",
      "Loss is:0.0514, Train_accuracy is 98.4917%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1386/2000\n",
      "Loss is:0.0535, Train_accuracy is 98.3750%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1387/2000\n",
      "Loss is:0.0525, Train_accuracy is 98.4700%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1388/2000\n",
      "Loss is:0.0521, Train_accuracy is 98.4450%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1389/2000\n",
      "Loss is:0.0514, Train_accuracy is 98.4950%, Test_accuracy is 97.0900%\n",
      "================================================================================\n",
      "Epoch 1390/2000\n",
      "Loss is:0.0505, Train_accuracy is 98.5250%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1391/2000\n",
      "Loss is:0.0531, Train_accuracy is 98.4167%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1392/2000\n",
      "Loss is:0.0516, Train_accuracy is 98.5250%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1393/2000\n",
      "Loss is:0.0527, Train_accuracy is 98.4900%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1394/2000\n",
      "Loss is:0.0515, Train_accuracy is 98.5033%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1395/2000\n",
      "Loss is:0.0506, Train_accuracy is 98.5400%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1396/2000\n",
      "Loss is:0.0509, Train_accuracy is 98.5267%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1397/2000\n",
      "Loss is:0.0519, Train_accuracy is 98.4517%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1398/2000\n",
      "Loss is:0.0509, Train_accuracy is 98.4450%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1399/2000\n",
      "Loss is:0.0506, Train_accuracy is 98.4817%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1400/2000\n",
      "Loss is:0.0517, Train_accuracy is 98.4467%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1401/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0508, Train_accuracy is 98.5250%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1402/2000\n",
      "Loss is:0.0512, Train_accuracy is 98.4700%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1403/2000\n",
      "Loss is:0.0505, Train_accuracy is 98.5317%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1404/2000\n",
      "Loss is:0.0513, Train_accuracy is 98.4883%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1405/2000\n",
      "Loss is:0.0502, Train_accuracy is 98.5150%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1406/2000\n",
      "Loss is:0.0512, Train_accuracy is 98.4867%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1407/2000\n",
      "Loss is:0.0519, Train_accuracy is 98.4500%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1408/2000\n",
      "Loss is:0.0513, Train_accuracy is 98.4767%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1409/2000\n",
      "Loss is:0.0510, Train_accuracy is 98.5033%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1410/2000\n",
      "Loss is:0.0507, Train_accuracy is 98.4967%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1411/2000\n",
      "Loss is:0.0505, Train_accuracy is 98.5183%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1412/2000\n",
      "Loss is:0.0506, Train_accuracy is 98.4683%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1413/2000\n",
      "Loss is:0.0506, Train_accuracy is 98.4983%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1414/2000\n",
      "Loss is:0.0503, Train_accuracy is 98.5450%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1415/2000\n",
      "Loss is:0.0509, Train_accuracy is 98.4850%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1416/2000\n",
      "Loss is:0.0502, Train_accuracy is 98.5017%, Test_accuracy is 97.1100%\n",
      "================================================================================\n",
      "Epoch 1417/2000\n",
      "Loss is:0.0515, Train_accuracy is 98.4833%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1418/2000\n",
      "Loss is:0.0511, Train_accuracy is 98.4500%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1419/2000\n",
      "Loss is:0.0501, Train_accuracy is 98.5317%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1420/2000\n",
      "Loss is:0.0511, Train_accuracy is 98.4583%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1421/2000\n",
      "Loss is:0.0513, Train_accuracy is 98.4983%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1422/2000\n",
      "Loss is:0.0506, Train_accuracy is 98.5217%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1423/2000\n",
      "Loss is:0.0497, Train_accuracy is 98.5283%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1424/2000\n",
      "Loss is:0.0504, Train_accuracy is 98.5150%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1425/2000\n",
      "Loss is:0.0500, Train_accuracy is 98.5183%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1426/2000\n",
      "Loss is:0.0498, Train_accuracy is 98.5617%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1427/2000\n",
      "Loss is:0.0501, Train_accuracy is 98.5250%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1428/2000\n",
      "Loss is:0.0496, Train_accuracy is 98.4933%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1429/2000\n",
      "Loss is:0.0492, Train_accuracy is 98.6133%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1430/2000\n",
      "Loss is:0.0504, Train_accuracy is 98.4983%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1431/2000\n",
      "Loss is:0.0516, Train_accuracy is 98.4800%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1432/2000\n",
      "Loss is:0.0503, Train_accuracy is 98.4983%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1433/2000\n",
      "Loss is:0.0499, Train_accuracy is 98.5300%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1434/2000\n",
      "Loss is:0.0489, Train_accuracy is 98.5733%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1435/2000\n",
      "Loss is:0.0500, Train_accuracy is 98.4800%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1436/2000\n",
      "Loss is:0.0502, Train_accuracy is 98.5233%, Test_accuracy is 97.1400%\n",
      "================================================================================\n",
      "Epoch 1437/2000\n",
      "Loss is:0.0507, Train_accuracy is 98.4717%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1438/2000\n",
      "Loss is:0.0496, Train_accuracy is 98.5767%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1439/2000\n",
      "Loss is:0.0510, Train_accuracy is 98.4850%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1440/2000\n",
      "Loss is:0.0503, Train_accuracy is 98.4567%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1441/2000\n",
      "Loss is:0.0491, Train_accuracy is 98.5833%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1442/2000\n",
      "Loss is:0.0501, Train_accuracy is 98.5433%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1443/2000\n",
      "Loss is:0.0496, Train_accuracy is 98.5500%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1444/2000\n",
      "Loss is:0.0488, Train_accuracy is 98.5533%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1445/2000\n",
      "Loss is:0.0501, Train_accuracy is 98.5317%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1446/2000\n",
      "Loss is:0.0498, Train_accuracy is 98.5133%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1447/2000\n",
      "Loss is:0.0497, Train_accuracy is 98.5150%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1448/2000\n",
      "Loss is:0.0495, Train_accuracy is 98.6017%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1449/2000\n",
      "Loss is:0.0485, Train_accuracy is 98.5550%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1450/2000\n",
      "Loss is:0.0498, Train_accuracy is 98.5450%, Test_accuracy is 97.1600%\n",
      "================================================================================\n",
      "Epoch 1451/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0490, Train_accuracy is 98.5167%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1452/2000\n",
      "Loss is:0.0492, Train_accuracy is 98.5433%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1453/2000\n",
      "Loss is:0.0488, Train_accuracy is 98.5683%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1454/2000\n",
      "Loss is:0.0493, Train_accuracy is 98.5350%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1455/2000\n",
      "Loss is:0.0488, Train_accuracy is 98.5850%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1456/2000\n",
      "Loss is:0.0485, Train_accuracy is 98.5983%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1457/2000\n",
      "Loss is:0.0486, Train_accuracy is 98.5550%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1458/2000\n",
      "Loss is:0.0486, Train_accuracy is 98.6200%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1459/2000\n",
      "Loss is:0.0489, Train_accuracy is 98.5050%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1460/2000\n",
      "Loss is:0.0495, Train_accuracy is 98.5600%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1461/2000\n",
      "Loss is:0.0491, Train_accuracy is 98.5783%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1462/2000\n",
      "Loss is:0.0479, Train_accuracy is 98.6200%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1463/2000\n",
      "Loss is:0.0491, Train_accuracy is 98.5367%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1464/2000\n",
      "Loss is:0.0482, Train_accuracy is 98.5633%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1465/2000\n",
      "Loss is:0.0485, Train_accuracy is 98.6050%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1466/2000\n",
      "Loss is:0.0477, Train_accuracy is 98.5433%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1467/2000\n",
      "Loss is:0.0492, Train_accuracy is 98.5400%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1468/2000\n",
      "Loss is:0.0474, Train_accuracy is 98.6550%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1469/2000\n",
      "Loss is:0.0489, Train_accuracy is 98.5783%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1470/2000\n",
      "Loss is:0.0479, Train_accuracy is 98.5867%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1471/2000\n",
      "Loss is:0.0501, Train_accuracy is 98.4550%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1472/2000\n",
      "Loss is:0.0475, Train_accuracy is 98.6017%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1473/2000\n",
      "Loss is:0.0491, Train_accuracy is 98.5083%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1474/2000\n",
      "Loss is:0.0474, Train_accuracy is 98.6500%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1475/2000\n",
      "Loss is:0.0503, Train_accuracy is 98.5067%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1476/2000\n",
      "Loss is:0.0481, Train_accuracy is 98.5717%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1477/2000\n",
      "Loss is:0.0484, Train_accuracy is 98.5983%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1478/2000\n",
      "Loss is:0.0476, Train_accuracy is 98.6283%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1479/2000\n",
      "Loss is:0.0478, Train_accuracy is 98.5733%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1480/2000\n",
      "Loss is:0.0473, Train_accuracy is 98.5867%, Test_accuracy is 97.1900%\n",
      "================================================================================\n",
      "Epoch 1481/2000\n",
      "Loss is:0.0470, Train_accuracy is 98.5783%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1482/2000\n",
      "Loss is:0.0479, Train_accuracy is 98.5567%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1483/2000\n",
      "Loss is:0.0474, Train_accuracy is 98.6733%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1484/2000\n",
      "Loss is:0.0468, Train_accuracy is 98.6233%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1485/2000\n",
      "Loss is:0.0472, Train_accuracy is 98.6333%, Test_accuracy is 97.1500%\n",
      "================================================================================\n",
      "Epoch 1486/2000\n",
      "Loss is:0.0483, Train_accuracy is 98.5983%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1487/2000\n",
      "Loss is:0.0471, Train_accuracy is 98.5517%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1488/2000\n",
      "Loss is:0.0472, Train_accuracy is 98.6167%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1489/2000\n",
      "Loss is:0.0473, Train_accuracy is 98.6217%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1490/2000\n",
      "Loss is:0.0475, Train_accuracy is 98.6150%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1491/2000\n",
      "Loss is:0.0478, Train_accuracy is 98.5750%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1492/2000\n",
      "Loss is:0.0475, Train_accuracy is 98.5817%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1493/2000\n",
      "Loss is:0.0475, Train_accuracy is 98.6167%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1494/2000\n",
      "Loss is:0.0472, Train_accuracy is 98.6200%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1495/2000\n",
      "Loss is:0.0471, Train_accuracy is 98.5967%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1496/2000\n",
      "Loss is:0.0472, Train_accuracy is 98.6367%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1497/2000\n",
      "Loss is:0.0469, Train_accuracy is 98.6133%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1498/2000\n",
      "Loss is:0.0467, Train_accuracy is 98.6050%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1499/2000\n",
      "Loss is:0.0472, Train_accuracy is 98.5950%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1500/2000\n",
      "Loss is:0.0460, Train_accuracy is 98.6617%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1501/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0469, Train_accuracy is 98.6467%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1502/2000\n",
      "Loss is:0.0468, Train_accuracy is 98.6317%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1503/2000\n",
      "Loss is:0.0469, Train_accuracy is 98.6350%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1504/2000\n",
      "Loss is:0.0466, Train_accuracy is 98.6467%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1505/2000\n",
      "Loss is:0.0464, Train_accuracy is 98.6917%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1506/2000\n",
      "Loss is:0.0467, Train_accuracy is 98.6617%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1507/2000\n",
      "Loss is:0.0463, Train_accuracy is 98.6283%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1508/2000\n",
      "Loss is:0.0468, Train_accuracy is 98.6117%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1509/2000\n",
      "Loss is:0.0486, Train_accuracy is 98.5700%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1510/2000\n",
      "Loss is:0.0462, Train_accuracy is 98.6350%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1511/2000\n",
      "Loss is:0.0461, Train_accuracy is 98.5933%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1512/2000\n",
      "Loss is:0.0470, Train_accuracy is 98.5867%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1513/2000\n",
      "Loss is:0.0468, Train_accuracy is 98.6167%, Test_accuracy is 97.1000%\n",
      "================================================================================\n",
      "Epoch 1514/2000\n",
      "Loss is:0.0463, Train_accuracy is 98.6350%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1515/2000\n",
      "Loss is:0.0471, Train_accuracy is 98.6267%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1516/2000\n",
      "Loss is:0.0461, Train_accuracy is 98.6300%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1517/2000\n",
      "Loss is:0.0469, Train_accuracy is 98.6000%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1518/2000\n",
      "Loss is:0.0462, Train_accuracy is 98.6683%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1519/2000\n",
      "Loss is:0.0467, Train_accuracy is 98.6217%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1520/2000\n",
      "Loss is:0.0459, Train_accuracy is 98.6167%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1521/2000\n",
      "Loss is:0.0457, Train_accuracy is 98.6600%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1522/2000\n",
      "Loss is:0.0454, Train_accuracy is 98.6350%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1523/2000\n",
      "Loss is:0.0455, Train_accuracy is 98.6433%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1524/2000\n",
      "Loss is:0.0457, Train_accuracy is 98.6050%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1525/2000\n",
      "Loss is:0.0459, Train_accuracy is 98.6650%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1526/2000\n",
      "Loss is:0.0454, Train_accuracy is 98.6283%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1527/2000\n",
      "Loss is:0.0459, Train_accuracy is 98.6400%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1528/2000\n",
      "Loss is:0.0451, Train_accuracy is 98.7100%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1529/2000\n",
      "Loss is:0.0462, Train_accuracy is 98.6633%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1530/2000\n",
      "Loss is:0.0452, Train_accuracy is 98.6833%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1531/2000\n",
      "Loss is:0.0451, Train_accuracy is 98.7167%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1532/2000\n",
      "Loss is:0.0456, Train_accuracy is 98.6367%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1533/2000\n",
      "Loss is:0.0445, Train_accuracy is 98.6600%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1534/2000\n",
      "Loss is:0.0454, Train_accuracy is 98.6917%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1535/2000\n",
      "Loss is:0.0455, Train_accuracy is 98.6333%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1536/2000\n",
      "Loss is:0.0454, Train_accuracy is 98.6467%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1537/2000\n",
      "Loss is:0.0458, Train_accuracy is 98.6600%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1538/2000\n",
      "Loss is:0.0457, Train_accuracy is 98.6383%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1539/2000\n",
      "Loss is:0.0452, Train_accuracy is 98.6717%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1540/2000\n",
      "Loss is:0.0448, Train_accuracy is 98.6483%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1541/2000\n",
      "Loss is:0.0450, Train_accuracy is 98.6617%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1542/2000\n",
      "Loss is:0.0449, Train_accuracy is 98.6700%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1543/2000\n",
      "Loss is:0.0457, Train_accuracy is 98.7117%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1544/2000\n",
      "Loss is:0.0443, Train_accuracy is 98.6967%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1545/2000\n",
      "Loss is:0.0456, Train_accuracy is 98.6117%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1546/2000\n",
      "Loss is:0.0447, Train_accuracy is 98.6733%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1547/2000\n",
      "Loss is:0.0450, Train_accuracy is 98.7183%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1548/2000\n",
      "Loss is:0.0456, Train_accuracy is 98.6633%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1549/2000\n",
      "Loss is:0.0449, Train_accuracy is 98.6600%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1550/2000\n",
      "Loss is:0.0451, Train_accuracy is 98.7150%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1551/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0452, Train_accuracy is 98.7100%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1552/2000\n",
      "Loss is:0.0451, Train_accuracy is 98.6917%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1553/2000\n",
      "Loss is:0.0456, Train_accuracy is 98.6550%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1554/2000\n",
      "Loss is:0.0445, Train_accuracy is 98.6983%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1555/2000\n",
      "Loss is:0.0439, Train_accuracy is 98.7450%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1556/2000\n",
      "Loss is:0.0454, Train_accuracy is 98.6350%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1557/2000\n",
      "Loss is:0.0448, Train_accuracy is 98.6883%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1558/2000\n",
      "Loss is:0.0456, Train_accuracy is 98.6250%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1559/2000\n",
      "Loss is:0.0448, Train_accuracy is 98.6383%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1560/2000\n",
      "Loss is:0.0445, Train_accuracy is 98.6650%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1561/2000\n",
      "Loss is:0.0443, Train_accuracy is 98.7833%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1562/2000\n",
      "Loss is:0.0450, Train_accuracy is 98.6600%, Test_accuracy is 97.2500%\n",
      "================================================================================\n",
      "Epoch 1563/2000\n",
      "Loss is:0.0449, Train_accuracy is 98.6583%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1564/2000\n",
      "Loss is:0.0445, Train_accuracy is 98.6717%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1565/2000\n",
      "Loss is:0.0443, Train_accuracy is 98.7167%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1566/2000\n",
      "Loss is:0.0430, Train_accuracy is 98.7467%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1567/2000\n",
      "Loss is:0.0436, Train_accuracy is 98.6717%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1568/2000\n",
      "Loss is:0.0439, Train_accuracy is 98.6983%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1569/2000\n",
      "Loss is:0.0448, Train_accuracy is 98.6817%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1570/2000\n",
      "Loss is:0.0453, Train_accuracy is 98.6400%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1571/2000\n",
      "Loss is:0.0435, Train_accuracy is 98.7083%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1572/2000\n",
      "Loss is:0.0437, Train_accuracy is 98.7533%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1573/2000\n",
      "Loss is:0.0436, Train_accuracy is 98.7650%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1574/2000\n",
      "Loss is:0.0445, Train_accuracy is 98.7033%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1575/2000\n",
      "Loss is:0.0438, Train_accuracy is 98.7100%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1576/2000\n",
      "Loss is:0.0439, Train_accuracy is 98.6683%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1577/2000\n",
      "Loss is:0.0440, Train_accuracy is 98.7100%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1578/2000\n",
      "Loss is:0.0440, Train_accuracy is 98.7133%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1579/2000\n",
      "Loss is:0.0439, Train_accuracy is 98.7133%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1580/2000\n",
      "Loss is:0.0434, Train_accuracy is 98.7250%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1581/2000\n",
      "Loss is:0.0430, Train_accuracy is 98.7533%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1582/2000\n",
      "Loss is:0.0445, Train_accuracy is 98.6683%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1583/2000\n",
      "Loss is:0.0440, Train_accuracy is 98.7583%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1584/2000\n",
      "Loss is:0.0444, Train_accuracy is 98.7433%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1585/2000\n",
      "Loss is:0.0435, Train_accuracy is 98.7100%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1586/2000\n",
      "Loss is:0.0428, Train_accuracy is 98.7350%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1587/2000\n",
      "Loss is:0.0436, Train_accuracy is 98.7233%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1588/2000\n",
      "Loss is:0.0422, Train_accuracy is 98.7733%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1589/2000\n",
      "Loss is:0.0434, Train_accuracy is 98.6950%, Test_accuracy is 97.2700%\n",
      "================================================================================\n",
      "Epoch 1590/2000\n",
      "Loss is:0.0442, Train_accuracy is 98.7183%, Test_accuracy is 97.7800%\n",
      "================================================================================\n",
      "Epoch 1591/2000\n",
      "Loss is:0.0435, Train_accuracy is 98.7083%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1592/2000\n",
      "Loss is:0.0430, Train_accuracy is 98.7417%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1593/2000\n",
      "Loss is:0.0428, Train_accuracy is 98.7650%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1594/2000\n",
      "Loss is:0.0439, Train_accuracy is 98.7150%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1595/2000\n",
      "Loss is:0.0433, Train_accuracy is 98.7383%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1596/2000\n",
      "Loss is:0.0432, Train_accuracy is 98.7367%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1597/2000\n",
      "Loss is:0.0428, Train_accuracy is 98.7450%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1598/2000\n",
      "Loss is:0.0421, Train_accuracy is 98.7183%, Test_accuracy is 97.5900%\n",
      "================================================================================\n",
      "Epoch 1599/2000\n",
      "Loss is:0.0430, Train_accuracy is 98.7417%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1600/2000\n",
      "Loss is:0.0428, Train_accuracy is 98.7483%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1601/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0429, Train_accuracy is 98.7183%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1602/2000\n",
      "Loss is:0.0422, Train_accuracy is 98.7400%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1603/2000\n",
      "Loss is:0.0424, Train_accuracy is 98.7483%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1604/2000\n",
      "Loss is:0.0442, Train_accuracy is 98.7283%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1605/2000\n",
      "Loss is:0.0429, Train_accuracy is 98.7450%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1606/2000\n",
      "Loss is:0.0433, Train_accuracy is 98.7050%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1607/2000\n",
      "Loss is:0.0431, Train_accuracy is 98.7850%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1608/2000\n",
      "Loss is:0.0425, Train_accuracy is 98.7817%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1609/2000\n",
      "Loss is:0.0432, Train_accuracy is 98.7050%, Test_accuracy is 97.2000%\n",
      "================================================================================\n",
      "Epoch 1610/2000\n",
      "Loss is:0.0430, Train_accuracy is 98.7000%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1611/2000\n",
      "Loss is:0.0436, Train_accuracy is 98.6950%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1612/2000\n",
      "Loss is:0.0416, Train_accuracy is 98.8100%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1613/2000\n",
      "Loss is:0.0417, Train_accuracy is 98.7900%, Test_accuracy is 97.1800%\n",
      "================================================================================\n",
      "Epoch 1614/2000\n",
      "Loss is:0.0413, Train_accuracy is 98.7800%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1615/2000\n",
      "Loss is:0.0422, Train_accuracy is 98.7867%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1616/2000\n",
      "Loss is:0.0422, Train_accuracy is 98.7633%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1617/2000\n",
      "Loss is:0.0417, Train_accuracy is 98.7450%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1618/2000\n",
      "Loss is:0.0419, Train_accuracy is 98.7717%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1619/2000\n",
      "Loss is:0.0421, Train_accuracy is 98.7083%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1620/2000\n",
      "Loss is:0.0426, Train_accuracy is 98.7283%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1621/2000\n",
      "Loss is:0.0436, Train_accuracy is 98.7067%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1622/2000\n",
      "Loss is:0.0422, Train_accuracy is 98.7500%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1623/2000\n",
      "Loss is:0.0434, Train_accuracy is 98.6867%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1624/2000\n",
      "Loss is:0.0428, Train_accuracy is 98.7100%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1625/2000\n",
      "Loss is:0.0410, Train_accuracy is 98.7950%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1626/2000\n",
      "Loss is:0.0423, Train_accuracy is 98.7517%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1627/2000\n",
      "Loss is:0.0423, Train_accuracy is 98.7250%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1628/2000\n",
      "Loss is:0.0420, Train_accuracy is 98.7517%, Test_accuracy is 97.6600%\n",
      "================================================================================\n",
      "Epoch 1629/2000\n",
      "Loss is:0.0417, Train_accuracy is 98.7383%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1630/2000\n",
      "Loss is:0.0421, Train_accuracy is 98.7833%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1631/2000\n",
      "Loss is:0.0425, Train_accuracy is 98.7567%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1632/2000\n",
      "Loss is:0.0421, Train_accuracy is 98.7367%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1633/2000\n",
      "Loss is:0.0418, Train_accuracy is 98.7917%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1634/2000\n",
      "Loss is:0.0413, Train_accuracy is 98.7967%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1635/2000\n",
      "Loss is:0.0422, Train_accuracy is 98.7567%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1636/2000\n",
      "Loss is:0.0430, Train_accuracy is 98.7267%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1637/2000\n",
      "Loss is:0.0419, Train_accuracy is 98.7433%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1638/2000\n",
      "Loss is:0.0420, Train_accuracy is 98.7683%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1639/2000\n",
      "Loss is:0.0418, Train_accuracy is 98.7750%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1640/2000\n",
      "Loss is:0.0403, Train_accuracy is 98.7983%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1641/2000\n",
      "Loss is:0.0414, Train_accuracy is 98.7500%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1642/2000\n",
      "Loss is:0.0415, Train_accuracy is 98.7600%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1643/2000\n",
      "Loss is:0.0420, Train_accuracy is 98.7717%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1644/2000\n",
      "Loss is:0.0409, Train_accuracy is 98.7983%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1645/2000\n",
      "Loss is:0.0408, Train_accuracy is 98.7783%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1646/2000\n",
      "Loss is:0.0400, Train_accuracy is 98.8550%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1647/2000\n",
      "Loss is:0.0411, Train_accuracy is 98.7967%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1648/2000\n",
      "Loss is:0.0420, Train_accuracy is 98.7383%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1649/2000\n",
      "Loss is:0.0415, Train_accuracy is 98.7800%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1650/2000\n",
      "Loss is:0.0399, Train_accuracy is 98.8150%, Test_accuracy is 97.1700%\n",
      "================================================================================\n",
      "Epoch 1651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0418, Train_accuracy is 98.7633%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1652/2000\n",
      "Loss is:0.0416, Train_accuracy is 98.7867%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1653/2000\n",
      "Loss is:0.0418, Train_accuracy is 98.7467%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1654/2000\n",
      "Loss is:0.0410, Train_accuracy is 98.8000%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1655/2000\n",
      "Loss is:0.0416, Train_accuracy is 98.8167%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1656/2000\n",
      "Loss is:0.0407, Train_accuracy is 98.8350%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1657/2000\n",
      "Loss is:0.0403, Train_accuracy is 98.8433%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1658/2000\n",
      "Loss is:0.0414, Train_accuracy is 98.7600%, Test_accuracy is 97.2100%\n",
      "================================================================================\n",
      "Epoch 1659/2000\n",
      "Loss is:0.0413, Train_accuracy is 98.8183%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1660/2000\n",
      "Loss is:0.0404, Train_accuracy is 98.7900%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1661/2000\n",
      "Loss is:0.0414, Train_accuracy is 98.7350%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1662/2000\n",
      "Loss is:0.0407, Train_accuracy is 98.7817%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1663/2000\n",
      "Loss is:0.0409, Train_accuracy is 98.7600%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1664/2000\n",
      "Loss is:0.0405, Train_accuracy is 98.7983%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1665/2000\n",
      "Loss is:0.0408, Train_accuracy is 98.8417%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1666/2000\n",
      "Loss is:0.0401, Train_accuracy is 98.8433%, Test_accuracy is 97.6300%\n",
      "================================================================================\n",
      "Epoch 1667/2000\n",
      "Loss is:0.0403, Train_accuracy is 98.8067%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1668/2000\n",
      "Loss is:0.0407, Train_accuracy is 98.7833%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1669/2000\n",
      "Loss is:0.0401, Train_accuracy is 98.8050%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1670/2000\n",
      "Loss is:0.0416, Train_accuracy is 98.7667%, Test_accuracy is 97.2200%\n",
      "================================================================================\n",
      "Epoch 1671/2000\n",
      "Loss is:0.0405, Train_accuracy is 98.8450%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1672/2000\n",
      "Loss is:0.0410, Train_accuracy is 98.8400%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1673/2000\n",
      "Loss is:0.0406, Train_accuracy is 98.7900%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1674/2000\n",
      "Loss is:0.0411, Train_accuracy is 98.7750%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1675/2000\n",
      "Loss is:0.0398, Train_accuracy is 98.8117%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1676/2000\n",
      "Loss is:0.0414, Train_accuracy is 98.7733%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1677/2000\n",
      "Loss is:0.0402, Train_accuracy is 98.8100%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1678/2000\n",
      "Loss is:0.0396, Train_accuracy is 98.8650%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1679/2000\n",
      "Loss is:0.0408, Train_accuracy is 98.8033%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1680/2000\n",
      "Loss is:0.0407, Train_accuracy is 98.8017%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1681/2000\n",
      "Loss is:0.0393, Train_accuracy is 98.8783%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1682/2000\n",
      "Loss is:0.0403, Train_accuracy is 98.7967%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1683/2000\n",
      "Loss is:0.0395, Train_accuracy is 98.8400%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1684/2000\n",
      "Loss is:0.0403, Train_accuracy is 98.7917%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1685/2000\n",
      "Loss is:0.0406, Train_accuracy is 98.8050%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1686/2000\n",
      "Loss is:0.0408, Train_accuracy is 98.8400%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1687/2000\n",
      "Loss is:0.0396, Train_accuracy is 98.8383%, Test_accuracy is 97.2300%\n",
      "================================================================================\n",
      "Epoch 1688/2000\n",
      "Loss is:0.0393, Train_accuracy is 98.8300%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1689/2000\n",
      "Loss is:0.0398, Train_accuracy is 98.8817%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1690/2000\n",
      "Loss is:0.0395, Train_accuracy is 98.8167%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1691/2000\n",
      "Loss is:0.0399, Train_accuracy is 98.8083%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1692/2000\n",
      "Loss is:0.0401, Train_accuracy is 98.8717%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1693/2000\n",
      "Loss is:0.0397, Train_accuracy is 98.8250%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1694/2000\n",
      "Loss is:0.0398, Train_accuracy is 98.8067%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1695/2000\n",
      "Loss is:0.0407, Train_accuracy is 98.8133%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1696/2000\n",
      "Loss is:0.0394, Train_accuracy is 98.8650%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1697/2000\n",
      "Loss is:0.0395, Train_accuracy is 98.7983%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1698/2000\n",
      "Loss is:0.0391, Train_accuracy is 98.8533%, Test_accuracy is 97.7400%\n",
      "================================================================================\n",
      "Epoch 1699/2000\n",
      "Loss is:0.0391, Train_accuracy is 98.8483%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1700/2000\n",
      "Loss is:0.0403, Train_accuracy is 98.8300%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1701/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0387, Train_accuracy is 98.8000%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1702/2000\n",
      "Loss is:0.0394, Train_accuracy is 98.8200%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1703/2000\n",
      "Loss is:0.0386, Train_accuracy is 98.9083%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1704/2000\n",
      "Loss is:0.0395, Train_accuracy is 98.8633%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1705/2000\n",
      "Loss is:0.0408, Train_accuracy is 98.7983%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1706/2000\n",
      "Loss is:0.0398, Train_accuracy is 98.8650%, Test_accuracy is 97.6200%\n",
      "================================================================================\n",
      "Epoch 1707/2000\n",
      "Loss is:0.0395, Train_accuracy is 98.8450%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1708/2000\n",
      "Loss is:0.0395, Train_accuracy is 98.8567%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1709/2000\n",
      "Loss is:0.0392, Train_accuracy is 98.8617%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1710/2000\n",
      "Loss is:0.0397, Train_accuracy is 98.8450%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1711/2000\n",
      "Loss is:0.0390, Train_accuracy is 98.8167%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1712/2000\n",
      "Loss is:0.0396, Train_accuracy is 98.8317%, Test_accuracy is 97.2400%\n",
      "================================================================================\n",
      "Epoch 1713/2000\n",
      "Loss is:0.0396, Train_accuracy is 98.8350%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1714/2000\n",
      "Loss is:0.0378, Train_accuracy is 98.8667%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1715/2000\n",
      "Loss is:0.0398, Train_accuracy is 98.8317%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1716/2000\n",
      "Loss is:0.0398, Train_accuracy is 98.8000%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1717/2000\n",
      "Loss is:0.0387, Train_accuracy is 98.8867%, Test_accuracy is 97.7000%\n",
      "================================================================================\n",
      "Epoch 1718/2000\n",
      "Loss is:0.0388, Train_accuracy is 98.8300%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1719/2000\n",
      "Loss is:0.0389, Train_accuracy is 98.8667%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1720/2000\n",
      "Loss is:0.0389, Train_accuracy is 98.8650%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1721/2000\n",
      "Loss is:0.0379, Train_accuracy is 98.9033%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1722/2000\n",
      "Loss is:0.0387, Train_accuracy is 98.8600%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1723/2000\n",
      "Loss is:0.0386, Train_accuracy is 98.9200%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1724/2000\n",
      "Loss is:0.0391, Train_accuracy is 98.8650%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1725/2000\n",
      "Loss is:0.0386, Train_accuracy is 98.8333%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1726/2000\n",
      "Loss is:0.0382, Train_accuracy is 98.9200%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1727/2000\n",
      "Loss is:0.0390, Train_accuracy is 98.8767%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1728/2000\n",
      "Loss is:0.0380, Train_accuracy is 98.8550%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1729/2000\n",
      "Loss is:0.0382, Train_accuracy is 98.8533%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1730/2000\n",
      "Loss is:0.0379, Train_accuracy is 98.8867%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1731/2000\n",
      "Loss is:0.0383, Train_accuracy is 98.8750%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1732/2000\n",
      "Loss is:0.0377, Train_accuracy is 98.8883%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1733/2000\n",
      "Loss is:0.0378, Train_accuracy is 98.8533%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1734/2000\n",
      "Loss is:0.0390, Train_accuracy is 98.8233%, Test_accuracy is 97.6300%\n",
      "================================================================================\n",
      "Epoch 1735/2000\n",
      "Loss is:0.0368, Train_accuracy is 98.9167%, Test_accuracy is 97.2900%\n",
      "================================================================================\n",
      "Epoch 1736/2000\n",
      "Loss is:0.0381, Train_accuracy is 98.8567%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1737/2000\n",
      "Loss is:0.0386, Train_accuracy is 98.8750%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1738/2000\n",
      "Loss is:0.0384, Train_accuracy is 98.8867%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1739/2000\n",
      "Loss is:0.0389, Train_accuracy is 98.8550%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1740/2000\n",
      "Loss is:0.0369, Train_accuracy is 98.9200%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1741/2000\n",
      "Loss is:0.0384, Train_accuracy is 98.8750%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1742/2000\n",
      "Loss is:0.0389, Train_accuracy is 98.8533%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1743/2000\n",
      "Loss is:0.0375, Train_accuracy is 98.8717%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1744/2000\n",
      "Loss is:0.0380, Train_accuracy is 98.8867%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1745/2000\n",
      "Loss is:0.0379, Train_accuracy is 98.9083%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1746/2000\n",
      "Loss is:0.0383, Train_accuracy is 98.8267%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1747/2000\n",
      "Loss is:0.0371, Train_accuracy is 98.9250%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1748/2000\n",
      "Loss is:0.0383, Train_accuracy is 98.8600%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1749/2000\n",
      "Loss is:0.0368, Train_accuracy is 98.9583%, Test_accuracy is 97.3000%\n",
      "================================================================================\n",
      "Epoch 1750/2000\n",
      "Loss is:0.0383, Train_accuracy is 98.8650%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1751/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0377, Train_accuracy is 98.9000%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1752/2000\n",
      "Loss is:0.0378, Train_accuracy is 98.8900%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1753/2000\n",
      "Loss is:0.0381, Train_accuracy is 98.8733%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1754/2000\n",
      "Loss is:0.0376, Train_accuracy is 98.9167%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1755/2000\n",
      "Loss is:0.0374, Train_accuracy is 98.8983%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1756/2000\n",
      "Loss is:0.0379, Train_accuracy is 98.8983%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1757/2000\n",
      "Loss is:0.0389, Train_accuracy is 98.8333%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1758/2000\n",
      "Loss is:0.0378, Train_accuracy is 98.9100%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1759/2000\n",
      "Loss is:0.0373, Train_accuracy is 98.8950%, Test_accuracy is 97.6500%\n",
      "================================================================================\n",
      "Epoch 1760/2000\n",
      "Loss is:0.0384, Train_accuracy is 98.8617%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1761/2000\n",
      "Loss is:0.0375, Train_accuracy is 98.8767%, Test_accuracy is 97.5900%\n",
      "================================================================================\n",
      "Epoch 1762/2000\n",
      "Loss is:0.0373, Train_accuracy is 98.9200%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1763/2000\n",
      "Loss is:0.0382, Train_accuracy is 98.8633%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1764/2000\n",
      "Loss is:0.0371, Train_accuracy is 98.9383%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1765/2000\n",
      "Loss is:0.0375, Train_accuracy is 98.9850%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1766/2000\n",
      "Loss is:0.0372, Train_accuracy is 98.9000%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1767/2000\n",
      "Loss is:0.0371, Train_accuracy is 98.9000%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1768/2000\n",
      "Loss is:0.0372, Train_accuracy is 98.9350%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1769/2000\n",
      "Loss is:0.0377, Train_accuracy is 98.9033%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1770/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9833%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1771/2000\n",
      "Loss is:0.0378, Train_accuracy is 98.8533%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1772/2000\n",
      "Loss is:0.0372, Train_accuracy is 98.9017%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1773/2000\n",
      "Loss is:0.0371, Train_accuracy is 98.9233%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1774/2000\n",
      "Loss is:0.0364, Train_accuracy is 98.9317%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1775/2000\n",
      "Loss is:0.0362, Train_accuracy is 98.9500%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1776/2000\n",
      "Loss is:0.0363, Train_accuracy is 98.9933%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1777/2000\n",
      "Loss is:0.0369, Train_accuracy is 98.9517%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1778/2000\n",
      "Loss is:0.0372, Train_accuracy is 98.8850%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1779/2000\n",
      "Loss is:0.0365, Train_accuracy is 98.9433%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1780/2000\n",
      "Loss is:0.0368, Train_accuracy is 98.9500%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1781/2000\n",
      "Loss is:0.0372, Train_accuracy is 98.8833%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1782/2000\n",
      "Loss is:0.0364, Train_accuracy is 98.9367%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1783/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9500%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1784/2000\n",
      "Loss is:0.0359, Train_accuracy is 98.9317%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1785/2000\n",
      "Loss is:0.0366, Train_accuracy is 98.9467%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1786/2000\n",
      "Loss is:0.0362, Train_accuracy is 98.9633%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1787/2000\n",
      "Loss is:0.0364, Train_accuracy is 98.9567%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1788/2000\n",
      "Loss is:0.0365, Train_accuracy is 98.9383%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1789/2000\n",
      "Loss is:0.0364, Train_accuracy is 98.9267%, Test_accuracy is 97.5900%\n",
      "================================================================================\n",
      "Epoch 1790/2000\n",
      "Loss is:0.0378, Train_accuracy is 98.8733%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1791/2000\n",
      "Loss is:0.0359, Train_accuracy is 98.9183%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1792/2000\n",
      "Loss is:0.0371, Train_accuracy is 98.9083%, Test_accuracy is 97.6200%\n",
      "================================================================================\n",
      "Epoch 1793/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9500%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1794/2000\n",
      "Loss is:0.0357, Train_accuracy is 98.9433%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1795/2000\n",
      "Loss is:0.0367, Train_accuracy is 98.8833%, Test_accuracy is 97.7000%\n",
      "================================================================================\n",
      "Epoch 1796/2000\n",
      "Loss is:0.0370, Train_accuracy is 98.8767%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1797/2000\n",
      "Loss is:0.0374, Train_accuracy is 98.8933%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1798/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9483%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1799/2000\n",
      "Loss is:0.0356, Train_accuracy is 98.9533%, Test_accuracy is 97.6400%\n",
      "================================================================================\n",
      "Epoch 1800/2000\n",
      "Loss is:0.0370, Train_accuracy is 98.9400%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1801/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0354, Train_accuracy is 98.9700%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1802/2000\n",
      "Loss is:0.0363, Train_accuracy is 98.9233%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1803/2000\n",
      "Loss is:0.0370, Train_accuracy is 98.9783%, Test_accuracy is 97.6400%\n",
      "================================================================================\n",
      "Epoch 1804/2000\n",
      "Loss is:0.0359, Train_accuracy is 98.9850%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1805/2000\n",
      "Loss is:0.0360, Train_accuracy is 98.9567%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1806/2000\n",
      "Loss is:0.0362, Train_accuracy is 98.9233%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1807/2000\n",
      "Loss is:0.0367, Train_accuracy is 98.9233%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1808/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9083%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1809/2000\n",
      "Loss is:0.0366, Train_accuracy is 98.9667%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1810/2000\n",
      "Loss is:0.0360, Train_accuracy is 98.9017%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1811/2000\n",
      "Loss is:0.0357, Train_accuracy is 98.9483%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1812/2000\n",
      "Loss is:0.0376, Train_accuracy is 98.8867%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1813/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9200%, Test_accuracy is 97.7000%\n",
      "================================================================================\n",
      "Epoch 1814/2000\n",
      "Loss is:0.0357, Train_accuracy is 98.9850%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1815/2000\n",
      "Loss is:0.0360, Train_accuracy is 98.9517%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1816/2000\n",
      "Loss is:0.0356, Train_accuracy is 98.9800%, Test_accuracy is 97.2800%\n",
      "================================================================================\n",
      "Epoch 1817/2000\n",
      "Loss is:0.0356, Train_accuracy is 98.9700%, Test_accuracy is 97.5900%\n",
      "================================================================================\n",
      "Epoch 1818/2000\n",
      "Loss is:0.0349, Train_accuracy is 98.9783%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1819/2000\n",
      "Loss is:0.0360, Train_accuracy is 98.9417%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1820/2000\n",
      "Loss is:0.0357, Train_accuracy is 98.9550%, Test_accuracy is 97.2600%\n",
      "================================================================================\n",
      "Epoch 1821/2000\n",
      "Loss is:0.0348, Train_accuracy is 99.0117%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1822/2000\n",
      "Loss is:0.0348, Train_accuracy is 98.9433%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1823/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9117%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1824/2000\n",
      "Loss is:0.0349, Train_accuracy is 99.0417%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1825/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9400%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1826/2000\n",
      "Loss is:0.0353, Train_accuracy is 98.9850%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1827/2000\n",
      "Loss is:0.0364, Train_accuracy is 98.9350%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1828/2000\n",
      "Loss is:0.0362, Train_accuracy is 98.9400%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1829/2000\n",
      "Loss is:0.0359, Train_accuracy is 98.8733%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1830/2000\n",
      "Loss is:0.0349, Train_accuracy is 98.9867%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1831/2000\n",
      "Loss is:0.0363, Train_accuracy is 98.9150%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1832/2000\n",
      "Loss is:0.0359, Train_accuracy is 98.9133%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1833/2000\n",
      "Loss is:0.0359, Train_accuracy is 98.9383%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1834/2000\n",
      "Loss is:0.0356, Train_accuracy is 98.9617%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1835/2000\n",
      "Loss is:0.0365, Train_accuracy is 98.9050%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1836/2000\n",
      "Loss is:0.0357, Train_accuracy is 98.9483%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1837/2000\n",
      "Loss is:0.0350, Train_accuracy is 98.9683%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1838/2000\n",
      "Loss is:0.0348, Train_accuracy is 98.9700%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1839/2000\n",
      "Loss is:0.0354, Train_accuracy is 99.0117%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1840/2000\n",
      "Loss is:0.0348, Train_accuracy is 98.9950%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1841/2000\n",
      "Loss is:0.0346, Train_accuracy is 98.9767%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1842/2000\n",
      "Loss is:0.0349, Train_accuracy is 98.9417%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1843/2000\n",
      "Loss is:0.0356, Train_accuracy is 98.9267%, Test_accuracy is 97.6700%\n",
      "================================================================================\n",
      "Epoch 1844/2000\n",
      "Loss is:0.0344, Train_accuracy is 98.9950%, Test_accuracy is 97.6900%\n",
      "================================================================================\n",
      "Epoch 1845/2000\n",
      "Loss is:0.0345, Train_accuracy is 98.9950%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1846/2000\n",
      "Loss is:0.0355, Train_accuracy is 98.9817%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1847/2000\n",
      "Loss is:0.0357, Train_accuracy is 98.9250%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1848/2000\n",
      "Loss is:0.0345, Train_accuracy is 99.0133%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1849/2000\n",
      "Loss is:0.0361, Train_accuracy is 98.9450%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1850/2000\n",
      "Loss is:0.0347, Train_accuracy is 98.9767%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1851/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0350, Train_accuracy is 98.9383%, Test_accuracy is 97.6200%\n",
      "================================================================================\n",
      "Epoch 1852/2000\n",
      "Loss is:0.0355, Train_accuracy is 98.9450%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1853/2000\n",
      "Loss is:0.0352, Train_accuracy is 99.0183%, Test_accuracy is 97.7300%\n",
      "================================================================================\n",
      "Epoch 1854/2000\n",
      "Loss is:0.0343, Train_accuracy is 99.0067%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1855/2000\n",
      "Loss is:0.0344, Train_accuracy is 99.0017%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1856/2000\n",
      "Loss is:0.0340, Train_accuracy is 99.0100%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1857/2000\n",
      "Loss is:0.0352, Train_accuracy is 98.9683%, Test_accuracy is 97.3300%\n",
      "================================================================================\n",
      "Epoch 1858/2000\n",
      "Loss is:0.0344, Train_accuracy is 98.9917%, Test_accuracy is 97.6900%\n",
      "================================================================================\n",
      "Epoch 1859/2000\n",
      "Loss is:0.0354, Train_accuracy is 98.9733%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1860/2000\n",
      "Loss is:0.0344, Train_accuracy is 98.9950%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1861/2000\n",
      "Loss is:0.0338, Train_accuracy is 99.0183%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1862/2000\n",
      "Loss is:0.0339, Train_accuracy is 99.0000%, Test_accuracy is 97.3500%\n",
      "================================================================================\n",
      "Epoch 1863/2000\n",
      "Loss is:0.0348, Train_accuracy is 98.9767%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1864/2000\n",
      "Loss is:0.0359, Train_accuracy is 98.9233%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1865/2000\n",
      "Loss is:0.0352, Train_accuracy is 98.9633%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1866/2000\n",
      "Loss is:0.0340, Train_accuracy is 99.0150%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1867/2000\n",
      "Loss is:0.0348, Train_accuracy is 98.9817%, Test_accuracy is 97.6400%\n",
      "================================================================================\n",
      "Epoch 1868/2000\n",
      "Loss is:0.0340, Train_accuracy is 99.0417%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1869/2000\n",
      "Loss is:0.0341, Train_accuracy is 99.0117%, Test_accuracy is 97.6500%\n",
      "================================================================================\n",
      "Epoch 1870/2000\n",
      "Loss is:0.0349, Train_accuracy is 98.9850%, Test_accuracy is 97.5900%\n",
      "================================================================================\n",
      "Epoch 1871/2000\n",
      "Loss is:0.0342, Train_accuracy is 99.0233%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1872/2000\n",
      "Loss is:0.0337, Train_accuracy is 99.0433%, Test_accuracy is 97.3600%\n",
      "================================================================================\n",
      "Epoch 1873/2000\n",
      "Loss is:0.0339, Train_accuracy is 99.0017%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1874/2000\n",
      "Loss is:0.0349, Train_accuracy is 98.9417%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1875/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0850%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1876/2000\n",
      "Loss is:0.0351, Train_accuracy is 98.9650%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1877/2000\n",
      "Loss is:0.0356, Train_accuracy is 98.9117%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1878/2000\n",
      "Loss is:0.0348, Train_accuracy is 98.9483%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1879/2000\n",
      "Loss is:0.0335, Train_accuracy is 99.0350%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1880/2000\n",
      "Loss is:0.0336, Train_accuracy is 98.9967%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1881/2000\n",
      "Loss is:0.0333, Train_accuracy is 99.0567%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1882/2000\n",
      "Loss is:0.0336, Train_accuracy is 98.9750%, Test_accuracy is 97.4400%\n",
      "================================================================================\n",
      "Epoch 1883/2000\n",
      "Loss is:0.0335, Train_accuracy is 98.9817%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1884/2000\n",
      "Loss is:0.0339, Train_accuracy is 98.9867%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1885/2000\n",
      "Loss is:0.0349, Train_accuracy is 98.9767%, Test_accuracy is 97.3900%\n",
      "================================================================================\n",
      "Epoch 1886/2000\n",
      "Loss is:0.0337, Train_accuracy is 98.9767%, Test_accuracy is 97.6200%\n",
      "================================================================================\n",
      "Epoch 1887/2000\n",
      "Loss is:0.0335, Train_accuracy is 99.0067%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1888/2000\n",
      "Loss is:0.0333, Train_accuracy is 99.0333%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1889/2000\n",
      "Loss is:0.0343, Train_accuracy is 98.9983%, Test_accuracy is 97.3700%\n",
      "================================================================================\n",
      "Epoch 1890/2000\n",
      "Loss is:0.0337, Train_accuracy is 99.0200%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1891/2000\n",
      "Loss is:0.0342, Train_accuracy is 98.9750%, Test_accuracy is 97.3200%\n",
      "================================================================================\n",
      "Epoch 1892/2000\n",
      "Loss is:0.0333, Train_accuracy is 99.0400%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1893/2000\n",
      "Loss is:0.0329, Train_accuracy is 99.0683%, Test_accuracy is 97.6200%\n",
      "================================================================================\n",
      "Epoch 1894/2000\n",
      "Loss is:0.0329, Train_accuracy is 99.0583%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1895/2000\n",
      "Loss is:0.0333, Train_accuracy is 99.0350%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1896/2000\n",
      "Loss is:0.0332, Train_accuracy is 99.0117%, Test_accuracy is 97.6700%\n",
      "================================================================================\n",
      "Epoch 1897/2000\n",
      "Loss is:0.0337, Train_accuracy is 99.0067%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1898/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0567%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1899/2000\n",
      "Loss is:0.0343, Train_accuracy is 98.9833%, Test_accuracy is 97.7100%\n",
      "================================================================================\n",
      "Epoch 1900/2000\n",
      "Loss is:0.0337, Train_accuracy is 99.0017%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1901/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0342, Train_accuracy is 99.0150%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1902/2000\n",
      "Loss is:0.0337, Train_accuracy is 99.0317%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1903/2000\n",
      "Loss is:0.0334, Train_accuracy is 99.0300%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1904/2000\n",
      "Loss is:0.0322, Train_accuracy is 99.0567%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1905/2000\n",
      "Loss is:0.0333, Train_accuracy is 98.9733%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1906/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0267%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1907/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0400%, Test_accuracy is 97.4700%\n",
      "================================================================================\n",
      "Epoch 1908/2000\n",
      "Loss is:0.0333, Train_accuracy is 99.0717%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1909/2000\n",
      "Loss is:0.0330, Train_accuracy is 99.0200%, Test_accuracy is 97.3400%\n",
      "================================================================================\n",
      "Epoch 1910/2000\n",
      "Loss is:0.0323, Train_accuracy is 99.0450%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1911/2000\n",
      "Loss is:0.0322, Train_accuracy is 99.0583%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1912/2000\n",
      "Loss is:0.0342, Train_accuracy is 98.9883%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1913/2000\n",
      "Loss is:0.0327, Train_accuracy is 99.0350%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1914/2000\n",
      "Loss is:0.0336, Train_accuracy is 99.0383%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1915/2000\n",
      "Loss is:0.0324, Train_accuracy is 99.0400%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1916/2000\n",
      "Loss is:0.0335, Train_accuracy is 98.9500%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1917/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0467%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1918/2000\n",
      "Loss is:0.0318, Train_accuracy is 99.0950%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1919/2000\n",
      "Loss is:0.0329, Train_accuracy is 99.0017%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1920/2000\n",
      "Loss is:0.0331, Train_accuracy is 99.0483%, Test_accuracy is 97.4200%\n",
      "================================================================================\n",
      "Epoch 1921/2000\n",
      "Loss is:0.0338, Train_accuracy is 99.0183%, Test_accuracy is 97.7000%\n",
      "================================================================================\n",
      "Epoch 1922/2000\n",
      "Loss is:0.0329, Train_accuracy is 99.0767%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1923/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0200%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1924/2000\n",
      "Loss is:0.0326, Train_accuracy is 99.0483%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1925/2000\n",
      "Loss is:0.0317, Train_accuracy is 99.1233%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1926/2000\n",
      "Loss is:0.0324, Train_accuracy is 99.0817%, Test_accuracy is 97.7600%\n",
      "================================================================================\n",
      "Epoch 1927/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0850%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1928/2000\n",
      "Loss is:0.0319, Train_accuracy is 99.0650%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1929/2000\n",
      "Loss is:0.0331, Train_accuracy is 99.0333%, Test_accuracy is 97.4800%\n",
      "================================================================================\n",
      "Epoch 1930/2000\n",
      "Loss is:0.0329, Train_accuracy is 99.0650%, Test_accuracy is 97.7700%\n",
      "================================================================================\n",
      "Epoch 1931/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0400%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1932/2000\n",
      "Loss is:0.0323, Train_accuracy is 99.0783%, Test_accuracy is 97.6800%\n",
      "================================================================================\n",
      "Epoch 1933/2000\n",
      "Loss is:0.0316, Train_accuracy is 99.0867%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1934/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0583%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1935/2000\n",
      "Loss is:0.0320, Train_accuracy is 99.0667%, Test_accuracy is 97.4100%\n",
      "================================================================================\n",
      "Epoch 1936/2000\n",
      "Loss is:0.0315, Train_accuracy is 99.0183%, Test_accuracy is 97.6000%\n",
      "================================================================================\n",
      "Epoch 1937/2000\n",
      "Loss is:0.0319, Train_accuracy is 99.0983%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1938/2000\n",
      "Loss is:0.0324, Train_accuracy is 99.0517%, Test_accuracy is 97.5900%\n",
      "================================================================================\n",
      "Epoch 1939/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0567%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1940/2000\n",
      "Loss is:0.0331, Train_accuracy is 99.0417%, Test_accuracy is 97.6500%\n",
      "================================================================================\n",
      "Epoch 1941/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0283%, Test_accuracy is 97.6300%\n",
      "================================================================================\n",
      "Epoch 1942/2000\n",
      "Loss is:0.0326, Train_accuracy is 99.0317%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1943/2000\n",
      "Loss is:0.0312, Train_accuracy is 99.0717%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1944/2000\n",
      "Loss is:0.0313, Train_accuracy is 99.0767%, Test_accuracy is 97.6800%\n",
      "================================================================================\n",
      "Epoch 1945/2000\n",
      "Loss is:0.0315, Train_accuracy is 99.0800%, Test_accuracy is 97.5300%\n",
      "================================================================================\n",
      "Epoch 1946/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0483%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1947/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0483%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1948/2000\n",
      "Loss is:0.0320, Train_accuracy is 99.0833%, Test_accuracy is 97.6600%\n",
      "================================================================================\n",
      "Epoch 1949/2000\n",
      "Loss is:0.0316, Train_accuracy is 99.0783%, Test_accuracy is 97.4000%\n",
      "================================================================================\n",
      "Epoch 1950/2000\n",
      "Loss is:0.0332, Train_accuracy is 99.0217%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1951/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0324, Train_accuracy is 99.0450%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1952/2000\n",
      "Loss is:0.0317, Train_accuracy is 99.0733%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1953/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0483%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1954/2000\n",
      "Loss is:0.0325, Train_accuracy is 99.0467%, Test_accuracy is 97.3800%\n",
      "================================================================================\n",
      "Epoch 1955/2000\n",
      "Loss is:0.0327, Train_accuracy is 99.0350%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1956/2000\n",
      "Loss is:0.0317, Train_accuracy is 99.0733%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1957/2000\n",
      "Loss is:0.0320, Train_accuracy is 99.1050%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1958/2000\n",
      "Loss is:0.0323, Train_accuracy is 99.0467%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1959/2000\n",
      "Loss is:0.0311, Train_accuracy is 99.0967%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1960/2000\n",
      "Loss is:0.0317, Train_accuracy is 99.0833%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1961/2000\n",
      "Loss is:0.0320, Train_accuracy is 99.0383%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1962/2000\n",
      "Loss is:0.0319, Train_accuracy is 99.0883%, Test_accuracy is 97.6800%\n",
      "================================================================================\n",
      "Epoch 1963/2000\n",
      "Loss is:0.0322, Train_accuracy is 99.0500%, Test_accuracy is 97.6900%\n",
      "================================================================================\n",
      "Epoch 1964/2000\n",
      "Loss is:0.0323, Train_accuracy is 99.0583%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1965/2000\n",
      "Loss is:0.0328, Train_accuracy is 99.0250%, Test_accuracy is 97.4300%\n",
      "================================================================================\n",
      "Epoch 1966/2000\n",
      "Loss is:0.0318, Train_accuracy is 99.0767%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1967/2000\n",
      "Loss is:0.0313, Train_accuracy is 99.0967%, Test_accuracy is 97.5200%\n",
      "================================================================================\n",
      "Epoch 1968/2000\n",
      "Loss is:0.0319, Train_accuracy is 99.0400%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1969/2000\n",
      "Loss is:0.0322, Train_accuracy is 99.0567%, Test_accuracy is 97.5800%\n",
      "================================================================================\n",
      "Epoch 1970/2000\n",
      "Loss is:0.0324, Train_accuracy is 99.0833%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1971/2000\n",
      "Loss is:0.0323, Train_accuracy is 99.0783%, Test_accuracy is 97.6200%\n",
      "================================================================================\n",
      "Epoch 1972/2000\n",
      "Loss is:0.0313, Train_accuracy is 99.0717%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1973/2000\n",
      "Loss is:0.0312, Train_accuracy is 99.0783%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1974/2000\n",
      "Loss is:0.0320, Train_accuracy is 99.0983%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1975/2000\n",
      "Loss is:0.0315, Train_accuracy is 99.0883%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1976/2000\n",
      "Loss is:0.0312, Train_accuracy is 99.1333%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1977/2000\n",
      "Loss is:0.0313, Train_accuracy is 99.0933%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1978/2000\n",
      "Loss is:0.0315, Train_accuracy is 99.0900%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1979/2000\n",
      "Loss is:0.0314, Train_accuracy is 99.0817%, Test_accuracy is 97.6400%\n",
      "================================================================================\n",
      "Epoch 1980/2000\n",
      "Loss is:0.0312, Train_accuracy is 99.0733%, Test_accuracy is 97.5700%\n",
      "================================================================================\n",
      "Epoch 1981/2000\n",
      "Loss is:0.0302, Train_accuracy is 99.0800%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 1982/2000\n",
      "Loss is:0.0308, Train_accuracy is 99.1317%, Test_accuracy is 97.7700%\n",
      "================================================================================\n",
      "Epoch 1983/2000\n",
      "Loss is:0.0313, Train_accuracy is 99.0733%, Test_accuracy is 97.6200%\n",
      "================================================================================\n",
      "Epoch 1984/2000\n",
      "Loss is:0.0320, Train_accuracy is 99.0300%, Test_accuracy is 97.5900%\n",
      "================================================================================\n",
      "Epoch 1985/2000\n",
      "Loss is:0.0314, Train_accuracy is 99.0183%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1986/2000\n",
      "Loss is:0.0303, Train_accuracy is 99.1517%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1987/2000\n",
      "Loss is:0.0317, Train_accuracy is 99.0017%, Test_accuracy is 97.3100%\n",
      "================================================================================\n",
      "Epoch 1988/2000\n",
      "Loss is:0.0315, Train_accuracy is 99.0800%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1989/2000\n",
      "Loss is:0.0314, Train_accuracy is 99.1200%, Test_accuracy is 97.5600%\n",
      "================================================================================\n",
      "Epoch 1990/2000\n",
      "Loss is:0.0317, Train_accuracy is 99.0017%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1991/2000\n",
      "Loss is:0.0303, Train_accuracy is 99.1100%, Test_accuracy is 97.4600%\n",
      "================================================================================\n",
      "Epoch 1992/2000\n",
      "Loss is:0.0312, Train_accuracy is 99.0700%, Test_accuracy is 97.5000%\n",
      "================================================================================\n",
      "Epoch 1993/2000\n",
      "Loss is:0.0310, Train_accuracy is 99.0833%, Test_accuracy is 97.6100%\n",
      "================================================================================\n",
      "Epoch 1994/2000\n",
      "Loss is:0.0319, Train_accuracy is 99.0950%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1995/2000\n",
      "Loss is:0.0313, Train_accuracy is 99.1050%, Test_accuracy is 97.4900%\n",
      "================================================================================\n",
      "Epoch 1996/2000\n",
      "Loss is:0.0316, Train_accuracy is 99.0650%, Test_accuracy is 97.5500%\n",
      "================================================================================\n",
      "Epoch 1997/2000\n",
      "Loss is:0.0307, Train_accuracy is 99.1233%, Test_accuracy is 97.4500%\n",
      "================================================================================\n",
      "Epoch 1998/2000\n",
      "Loss is:0.0306, Train_accuracy is 99.1250%, Test_accuracy is 97.5100%\n",
      "================================================================================\n",
      "Epoch 1999/2000\n",
      "Loss is:0.0310, Train_accuracy is 99.0967%, Test_accuracy is 97.5400%\n",
      "================================================================================\n",
      "Epoch 2000/2000\n",
      "Loss is:0.0305, Train_accuracy is 99.0950%, Test_accuracy is 97.6300%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 2000 ## 定义学习率及训练次数\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr = lr) ## 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss(reduction='mean') ## 定义损失函数，分类问题一般使用交叉熵损失\n",
    "\n",
    "train_loss_all = []\n",
    "train_acc_all = []\n",
    "test_acc_all = []\n",
    "test_loss_all = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {}/{}\".format(epoch+1,num_epochs))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    \n",
    "    for X, y in train_loader:\n",
    "        mlp.train() ## 表明模型在训练\n",
    "        output = mlp.forward(X) ## 模型在 X 上的输出: N * num_class\n",
    "        train_loss = loss_func(output, y ) ## 交叉熵误差\n",
    "        _, pred = torch.max(output.data, 1) ## 获得预测结果\n",
    "        optimizer.zero_grad() ## 每次迭代将梯度初始化为0\n",
    "        train_loss.backward() ## 损失的后向传播， 计算梯度\n",
    "        optimizer.step() ## 使用梯度进行优化\n",
    "        running_loss += train_loss.item() ## 统计模型预测损失\n",
    "        running_correct += torch.sum(pred == y.data) ## 统计模型预测准确个数\n",
    "        \n",
    "    test_correct = 0\n",
    "    val_loss = 0\n",
    "    for data in test_loader:\n",
    "        X_test, y_test = data        \n",
    "        output = mlp(X_test)\n",
    "        test_loss = loss_func(output, y_test )\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        test_correct += torch.sum(pred == y_test.data)\n",
    "        val_loss += test_loss.item()\n",
    "    print(\"Loss is:{:.4f}, Train_accuracy is {:.4f}%, Test_accuracy is {:.4f}%\"\n",
    "          .format(running_loss/len(train_loader),100*running_correct/len(data_train), 100*test_correct/len(data_test)))\n",
    "    print(\"=\"*80)\n",
    "    train_loss_all.append(running_loss/len(train_loader))\n",
    "    train_acc_all.append(running_correct/len(data_train))\n",
    "    test_loss_all.append(val_loss/len(test_loader))\n",
    "    test_acc_all.append(test_correct/len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "-lMXYhhRZ1xu",
    "outputId": "2f5b9ea7-adcb-45f5-c913-b9af5f13d8cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAFgCAYAAACmDI9oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAABhe0lEQVR4nO3dd5wd5Xn3/881p2zvu+oVEEU0AQJDMA4OxhTbYMcOLsFxSYyTx0nsJzYxjrufJD8neeI4jitOeNxxjW0ScAw4gO2YJkAIAQIVJLSqq11t31Pn+v0xs9KRUDkr9ujsSt/363VeO+eeds19Zs+55p57ZszdERERERGRSFDtAEREREREphIlyCIiIiIiJZQgi4iIiIiUUIIsIiIiIlJCCbKIiIiISAklyCIiIiIiJZQgi4hUgZl9zcz+usxpN5rZKyodk4iIRJQgi4iIiIiUUIIsIiJHzMyS1Y5BRGSyKUEWETmIuGvDjWa2ysxGzOzfzGymmf3MzIbM7G4zayuZ/hoze9LM+s3sXjM7rWTcOWb2aDzf94Da/db1ajNbGc/7GzM7q8wYX2Vmj5nZoJltNrNP7Df+pfHy+uPxb4/L68zsH81sk5kNmNmv47JLzaz7APXwinj4E2b2QzP7lpkNAm83swvM7P54HdvM7PNmli6Z/3Qzu8vM+sxsh5n9lZnNMrNRM+some5cM+sxs1Q52y4iUilKkEVEDu31wOXAycBrgJ8BfwV0EX2H/jmAmZ0M3Aq8Lx53B/AfZpaOk8WfAN8E2oEfxMslnvcc4Bbg3UAH8BXgNjOrKSO+EeAPgFbgVcCfmNlr4+UujOP9lzimZcDKeL7/C5wH/FYc018CYZl1ci3ww3id3waKwP8GOoGLgMuA/xXH0ATcDfwXMAc4CfiFu28H7gWuK1nuW4Hvunu+zDhERCpCCbKIyKH9i7vvcPctwK+AB939MXfPAD8GzomneyNwu7vfFSd4/xeoI0pALwRSwGfdPe/uPwQeLlnHDcBX3P1Bdy+6+9eBbDzfIbn7ve7+hLuH7r6KKEn/7Xj0W4C73f3WeL297r7SzALgncB73X1LvM7fuHu2zDq5391/Eq9zzN0fcfcH3L3g7huJEvzxGF4NbHf3f3T3jLsPufuD8bivA9cDmFkCeDPRQYSISFUpQRYRObQdJcNjB3jfGA/PATaNj3D3ENgMzI3HbXF3L5l3U8nwQuD9cReFfjPrB+bH8x2Smb3EzO6JuyYMAH9M1JJLvIz1B5itk6iLx4HGlWPzfjGcbGb/aWbb424Xf1tGDAA/BZaa2WKiVvoBd3/oCGMSEZk0SpBFRCbHVqJEFwAzM6LkcAuwDZgbl41bUDK8Gfgbd28tedW7+61lrPc7wG3AfHdvAb4MjK9nM3DiAebZBWQOMm4EqC/ZjgRR94xSvt/7LwFrgCXu3kzUBaU0hhMOFHjcCv99olbkt6LWYxGZIpQgi4hMju8DrzKzy+KLzN5P1E3iN8D9QAH4czNLmdnvAheUzPtV4I/j1mAzs4b44rumMtbbBPS5e8bMLiDqVjHu28ArzOw6M0uaWYeZLYtbt28BPmNmc8wsYWYXxX2enwVq4/WngI8Ah+sL3QQMAsNmdirwJyXj/hOYbWbvM7MaM2sys5eUjP8G8HbgGpQgi8gUoQRZRGQSuPszRC2h/0LUQvsa4DXunnP3HPC7RIlgH1F/5X8vmXcF8C7g88BuYF08bTn+F/ApMxsCPkaUqI8v93ngaqJkvY/oAr2z49EfAJ4g6gvdB/wdELj7QLzMfyVq/R4B9rmrxQF8gCgxHyJK9r9XEsMQUfeJ1wDbgbXAy0vG/w/RxYGPuntptxMRkaqxfbvEiYiIHF1m9t/Ad9z9X6sdi4gIKEEWEZEqMrPzgbuI+lAPVTseERFQFwsREakSM/s60T2S36fkWESmErUgi4iIiIiUUAuyiIiIiEiJZLUDmKjOzk5ftGhRtcMQERERkWnukUce2eXu+9/rvXIJspndQvSI0Z3ufsYBxhvwz0S3IBoF3u7ujx5uuYsWLWLFihWTHa6IiIiIHGfM7IC3l6xkF4uvAVceYvxVwJL4dQPRk5hERERERKqqYgmyu/+S6ObzB3Mt8A2PPAC0mtnsSsUjIiIiIlKOal6kNxfYXPK+Oy4TERERkSnmeLrz2bS4SM/MbiDqhsGCBQuqHI2IiBxL3J3ospi9CsUQgGTihe1II9kCdakEDmQLRRKBMTCWpzaVIBUEFN0pFEN6R3I01SQZyRUxIHSnNpWgGDqhO8PZAjXJgMCMfNGJVmVsGxijJpmgJhmQyRdJJgx3GMpE09elE4zmigRmpJNGthBSKDo1yWjdY7kiuUJIS10KgOFsgULopBMB2UJIfU2CkWyBYhglOw3pJP1jeZKB4TiFYlQfuUJIfTpBrhASBEZgMJIrUiyG1KYSJIIorrE4xkLRyRdDCvFyU4mAfDEkdMcdiqFTCJ36dILRbAEzI50MCEMnUyhSl0owlo9iL4ZQkwooFEOSiYCE2Z4YhjMFRvNFGtIJ0smA0VwRgHQiYCRX2LNewwg9qmszI5Mv0lSTZChTIFsIcaK4xnO+Pe/jzzmdDMBhKFugNhmQSgZ7PscwZM+yw3jbSrczVwypSyWoTQUkAmM0V2QoU8AMwtBJJwMKoZMwoxA6dakEyYQxOJbHzPbMU5MM4ro0RrJFggBGc0VqkwmCINrmsXw44cS1byRHQ02UAhbCkDCM/kbbAYFFdTf+F2AsVyT06PPLF8c/42jfHZ9mPIxEEH22xdAJQ6foTjF0UomAdDJgKJMnH++z4/N99W3L+e2TX3CtXNVUM0HeAswveT8vLnsBd78ZuBlg+fLlx8/hi4gcU0p/KML4bzII4gQmJF9w6msSFIrOaK7AWL5Ioegkgr3JW+mPOcDu0Ty5QkgqTqIcZywXYgY1yYDBTJ6t/RlmNteSDKIkIVsI4x/gAq31aUayUVLhRMnf+HL2rCv+4e8fy5MIjNpkwHC2SDEMSSWiH/rQneFMtJwgiOLM5Ivk4x/IxjgxKYROMjCCAHaP5EklA1KBkYoT0eFsAYiSk2whSpYSQZx8hU5tMsAdRvOFPesbTyaAPfUAUeIWJZJQn07SVJtkYCzPcKZAthjS0ZBm13CWfDH60U8lgjiJC8nkowS5NhXsSaIc35MYJALbk2BOX+PxR/tXmjyGkyU9oaXUkiVDzQvKkxQoEuAEGCGOAUaSAgYkKMbzeVyf0BKMUUjUk/Yss30Hm4N5JMIsg2Et49UdGLTVpcjm84SFLJZI0ZUYZWexgXQ6TaEY0pAIyZGkJhwlSKTIewISSXK5HF21zqzUMLusAzDCIEmdZyiSAIviK1iatsxmehIzqalJM1wYYzCsISRgvm+jNzGT0ALSViQM0jQxwmiiiSAICN0ZzRYhO0gWKBSLdCVHyaVnkQ6cfDGLWyM1yWgfaqpNks9lCbNjnJXqpSfoAi/SVp9hd7GWIU/TXtxNsbmLvAfkEgVIJRkrBrQGo1h9IwlCZha66UvOoLE4QNqzjAUNZKye0aCR5uJuHBhLNJL3BGfOSJALE9SRoZBsps7HaAv7IJFkt3WQTdRRH+TJe8Bgpsg8dlGXMhp8lJrMTnY0nkbWAxoKQ6QDh0SS4VQH+aCWBEWSmX5qcn301p9Ac7GPbLKVtBVoGd1ENl9gDYtoq0/SknIKiTQzxzYwr3lqtdlWM5rbgD81s+8CLwEG3H1bFeMRkUkQho5ZlFCMt0AMZQsUilGLVt9Ibk+ilY5bE0ZzRYqhk8kXGc4WGMsVCQKjGIY83zvKws4GhjNRwhjGLRxFd3xPssme4ULo9AxlaalLRa01DsStPDsHx8gVirgFDI7lo3gdzKIUYbyVidE+LN1AlhQeFiiGgBdIhHmCYg68SMGNXm+mGLeQpcMxMp7CwjwZT5L0POkwQ8qzjIUJGn2EBCED3sBJwRZ2eBtNjNHjLbTbENu8A4hSlhQFApzTg40MeBRHgSQdNkCBBINeTwNZsqRotSEGvYFmG+FE20qfN7PZu2iwLJ0MELWjOQ/ThAELbQcdNsjzPoMWRthFSLsN85TPJkHIbm+k2UZJEJImTwNZ6i0DwEJGKBKwxLrZRgcPhEt5Y+Je1tkinrGFzCJLU5Clk91stZmMWCMLfAtLi8/wUOIc8pamIQUNxUHOLjzB6tSZ5EhR42MsKa7jqcSpdNkgXWEPzySWMM+3MSPsYXNiAUVL0Jfsor4wyKxwB7tSs+kIhggdkrkMKc+zMz0PDwvkSFFMN9GV6KGxbozRRBNezFOb281Aw1zqmkPmDq3CvMiOjkW0+gCNuR46s5tZ1fFKcolGWrJbaQ4HyJEmFY4xmmoHjN7ULE4efIBMspmxmg5q8/3MGn6Kgbr5jNTMor9uHgEhc/seJOU5anN9bOm8mKaxrTSPPMeO5jMppJrwIEnSQupHt2I4HiRpHlzLQOOJFC1JreXJJxvBAvKWomFsG6NNi6gb2xm3iELDwFrCIEWmcQFhqp70yDYszFOsbY9SXw/JNczBciPRQVaQIDnWS83QJjIdp5Ea3IwHKfINs0lk+0mO9RCE0f9Fvmk+ZgEeFqCmkWBkJ2FNGwFFEgOb8CBFoWEWyaFujL0HCmHzfLyhk8S2xw74/eBti2F4B5YfjaZvXUTQvzEa1zwXGzxAO1kCSDVAuh7PDEJtC5Yfg3AoGjcuCXgCGlphtBeStRBmoDi+8gAshCzRa1y6EXLDB/9SGzn4qBeoawMPoaYFBraAFw8+baoeLAFhAQpjE1hJLJGGYg6CFMSf2wFZYt84Djc97FsnFkTbVGln3Aqzrq78espUsSfpmdmtwKVAJ7AD+DiQAnD3L8e3efs80Z0uRoF3uPth79+2fPly123e5HiXLRQJQ8gVQ9KJgF3DWbKFkHwxehWyo+SKRo5kVFYokCtCvhBSKBYYLcDOoSzJMEN9OEo23cbwWAbPjYIZ9SPdPOvzaE0V6RrbQL7opLK7edYWMiuzgZney66wgUXhZtb7PIbCFMniGDVhhiX+HEbIhnA2TkAIhAR0WT9NjJEhRQMZRqhlyOtpsAxd9DNGDUPU0cwoc6yX530GJ9lWNnsXeZKcaFs5J1jLVu9kkHouCJ7hkXAJNeSpIU+CIiEBw9TSSys5TzDfejgj2Mig19Fs0Q9QhjRrWExbMEqaPGNWT5I8DeEI24NZNIW7WRAfq+8O2qn3ERJeJEnhBZ/DSNBMQzi4531IEG+xVJ4BB/j9CpJRwgFRUhUkIZmGsd2QboB8Bool2VHLAhh4fu/7uvYoGUjVQyIJhSwM74B0ExQyexOLZN2+Sc34+/qOaJ3ZYcjHmVW6CTpPgt2boKETapqgmIewCGN90TrzI1DIQaY/Gt+xJFq/O4zsgsEtkEhB16kQJGBwW7RNqdooAcoMQG1ztC6LkmFqW6Lpkulofe7RssNC9DdZG62vvjNK7AY2w0A37H4O2k+AoR3QPDtaZyEb1XddO2QHYetjcYKWh9YFUULatx5OfXWUWIXRgSazzozq7/kHYM4yaJ4Dqbpom4q5KKYtj0J2ABZcFK2npina1nV3w4zToWlWVK/peti1FravhrnnQNNsaF0I638B3Q/Dmb8HO56CtoXQ/zwsfhn0rIHtT8TLjFvGT3oFDO+EkZ69+9Css2D7KujbADPPiKbtfhhmnh59Fmbw2Ldgzjmw4R446XKYfVa0r1gAj34TZpwKNc1Q2xrtCx5G+0W6Aerbo/1nYEu0/7UsiJZZyMLwdmicCWP9kBuJPse69qhegyT0roXND8HQNug8GeZfEM3nYRSvOzTNhBlLITMYlT9zBzTOiBLdmqZoO0b7ov03LERJcjEHuzdGy5h1VvQ5Nc+JXsM7o+U0zoymH+2Nlte7Dvo3R9sz51xoWwS7no0+z2RNtE3JWmiZH9XtSE/0OWX6o32lviOKsXdt9LlaEMXXNBtOuRrqWo/4G+FImdkj7r78BeXTrcO1EmSZSjL5qE9WLl9kKFukfzjD2HA/NrSFdbkOEjUN5Ef76ex9mBQhNtbLk00vJcwMYGN9FMaGaaivJzW6k51jzkzrZ052A7toozEc4OTCWvpp4qRwPZ0M8LQvYjvttPoQ6302HQxQQ55NPpOlwSZSFMmRZFmwnqwn+WV4NpcnHnlB3E+HCzgteP4AW1Q9Hp/mtQMlPftPm6zDCmOEta2AYdkBzEO8pgnvOg3b9Wz0Aw1YbmjfmTtP2fuDZdEpVXZvin6Q042QH41+KBdcFP1IhoUo2ajviJOmFKy4BU6+Kvoy37U2Gj+wBU5/bbSMYi5KEuraox+7wa3RD3khTs7aFkfrSTdGyUjfc9C5JFo+RPOHhegHrWVe9D4zCNmhKPaOE6MfldG+aDg3CrmhKDnqXRclRul6SNREy8mNQMvcqE76n49iSjVE255uiOJq6IqWM7wjWmeQ2Pvjte1xaJ4b/QhClCDVt0fLT6ShfXH0g1rXFq03LEaJlgVR4tY8O17+SPSqa4t+OFsXQM8zgMNwDyy+JPpMsoNRXfRvitZf3xElnMl09MOeG4HGriiBM4uWHRaiZMLDKGEYj3F/+bFofJCM1puMuwZkh6O62K8v8j5GeqNpxhOBMIxPPxxiHojWd7hpRKQqlCDL8Sn+YQpDZ+Pm5xmjhsbhTQw1LGT3ugdJDz1PYrSHWh/j+aZzGMg4C0YeZ0fYSsPup2m1EfCQ4bCGlsIuluejfW8nbRTd2OodLLZt1JJns3ex0HZQa3tPXY14DQ2WPVh0L0rBUrglSIUZcslGcjXtNI48j8en1AGKqUYS+WEy7adAsp50/zqC3BCFztMIahpgaDu85N2EI7tIJmuiZCYbJ2L1HVGCs/hlURIz2A1Y1DLQdUo0TaouSkh2rY0So5b5UeIXJKPWhWR6b7JS2xq1GDz3y6j1o3V+1NqS6Y8SxfqOKHHKDEQJVl1rtA6zvUlR08y9FZAfi9YvIiJyhA6WIE+tHtEipXIjUaJU20wmV2B0ZJDB7RsYHs1QGNxGJpMlyPbTuusx+vJJtiXmsmj3/zAzu4kdqfm05ray2LuB6H6GJxxmdS943ON+8lEPITJBPc2Wp7Y4zGzbe6vvExO7yKXa2NW0kKahqJtBOO+3GGmdT7LvWYrzLiSdTJAMiFrqitno9Nbc86B53t7Twqe+am+rZX4sSiLNorpIpKKksaGT5PjBbVggnUhFl9XkM1iqNpqmpinqnheG1O7XyrX/P/5Rvd/jyVccenxpq1/pcE3jvtMpORYRkQpRgixHjzv0rieXamZHLs3gWI5g/X+T6d/GWDFgrH8HLX2rKJCgI7eVJYVnAeinibwHdNkABzhhekANuRFqye1TtrLjVbQm88zb9Su2zruappFN7GxfTksyT31jC6nGNpL1rSS6TsEyfVhmEBo6YPYyqGsjFSRgeCe1jTOiBWYGo9OtQXSVSDJ+1Zesc2LXgh9AbcsLy8ZPCY8nvInU3nGp2uhvTdPesqCatzsXERGZfpQgy5HLjUR9EHF8tJeBTU8QPPo1dradQ9eab9Ey8hwAA6kuhr2OuYWoz2uafe/vV2qbt9PCCPUl3RJaGeK5jkvobj2dxnCIulRA2LEEmmeTaJpFqqaWtsY6Uo0dcbeABC2JeNcuFvZc6LKspAV1/G7abRPd5vHkGKJ+nCIiInLMUYIsBxYWo4toMoMM7djAjuE8hb5NtK/9EemRrYxRw+zcpj2TG9AaDzfzn/ssqiXfwxPJi7CUMSe/iaH0DHbM/h2svo06y5M5+TU0p422mQuY3b5o78U24xfBeMjixBHuquPz6QIZERERKZMS5OPV2O7otjHpBgoPf42+tjMZ3L6Rhh0PM3voiX0mbYpfpfpsPv3WzEjQxK7ahaSTCfrbz2a4YSGJxk7OWDyH2tmnUj+2Axpn8NKGtkMubx+lXQaCgOo+EV1ERESON0qQj3XFPGx+iNHRYUbX/pLguftoGFxPTTi6Z5IkMIMfMGO/WZ/gJLa1LWd2TZZwxhk0tc+gqWM2Laf+Diekon63rcDcQ62/uXVSN0dERESk0pQgH0v6nsO3r2L4yTtJbryXXNEhN0JL2E89+148BrDNO9hUfwY75lzGjNoiDUsuYdaiU5nRGrXvnhm/RERERI4nSpCnq5Fd0VN97v74PsXG3u4LSU9wX3A+W7teiqUb6GqpZ1ZXF7PPvZraVILZ9WlmH/XARURERKY2JcjTRViEXWspPvtz/FefIZntP+Bk/9jyIU5vLZA88VKWn3c+r2ioObpxioiIiExzSpCnOnfCVT8g+PG7AKIHP8RuqX8nfbMu4eKzlnD2aadSn07yft2tQURERORFUYI8VW15hJHbP0zD1vv33MNhu7dzf/1v03LedZzxkt/hnU21VQ1RRERE5FikBHkq2bkGH97O8E//kqaBZ0h6KupUDNx3wVf4rctfz+tSqUMvQ0REREReFCXIU0EYwto74dY3YkDWm/nP4sv55YL38M7Lz2X5onZ+W10nRERERI4KJcjVFhYpfvs6EuvvBmBleCI/PuMLvOfKc3hzs7pQiIiIiBxtSpCraXAbfObUPRfe/bL51Zz6R//GJ5UYi4iIiFRNRZ/ha2ZXmtkzZrbOzG46wPgFZnaPmT1mZqvM7OpKxjOldK+Az5wKwL1+Lj+7dhUv+4tvM0PJsYiIiEhVVSxBNrME8AXgKmAp8GYzW7rfZB8Bvu/u5wBvAr5YqXimlF3r4F8vA+Dv82+k64Yfc9U5C6sclIiIiIhAZVuQLwDWufsGd88B3wWu3W8aB5rj4RZgawXjmRoyg4x+6y0A/H3y3fz+jf/M6XNbqxuTiIiIiOxRyT7Ic4HNJe+7gZfsN80ngDvN7M+ABuAVB1qQmd0A3ACwYMGCSQ/0qNm9ieLXXk39wPN8Nf1Wrv9fn2ROa121oxIRERGREhXtg1yGNwNfc/d5wNXAN83sBTG5+83uvtzdl3d1dR31ICeFO/6960kMPM8/5V/PJe/8WyXHIiIiIlNQJRPkLcD8kvfz4rJSfwh8H8Dd7wdqgc4KxlQ9T/8Htn0VPy8uh0tv4tRZzYefR0RERESOukomyA8DS8xssZmliS7Cu22/aZ4HLgMws9OIEuSeCsZUHe7w/bcCcEfnO/jzy5ZUOSAREREROZiKJcjuXgD+FPg58DTR3SqeNLNPmdk18WTvB95lZo8DtwJvd3evVExVs/VRAH4Y/jbvedO1JAI9FU9ERERkqqrog0Lc/Q7gjv3KPlYy/BRwcSVjmAoG7/sCSa9h24Uf5w0zm6odjoiIiIgcQrUv0jv27XiS5md/xH/4xfz+b59Z7WhERERE5DCUIFfY0EPfInRj53n/m/aGdLXDEREREZHDUIJcSWERW/U97gyX87qXLa92NCIiIiJSBiXIFeRrbqcx38u6WVcxr62+2uGIiIiISBnKSpDN7N/N7FUHeoiHHFzf6rsZ9Rpmnf+6aociIiIiImUqN+H9IvAWYK2ZfdrMTqlgTMcGd2rW3s7/+Blcdvq8akcjIiIiImUqK0F297vd/feBc4GNwN1m9hsze4eZpSoZ4LTVu47G/C42tb+UNl2cJyIiIjJtlN1lwsw6gLcDfwQ8BvwzUcJ8V0Uim+Z2P/MrAFpPuaTKkYiIiIjIRJT1oBAz+zFwCvBN4DXuvi0e9T0zW1Gp4Kaz/mf/h8DrOe0s3b1CREREZDop90l6n3P3ew40wt2VAR5A3fZHecJO5qLZrdUORUREREQmoNwuFkvNrHX8jZm1mdn/qkxI05+P9TMj+xy7Ws8mEVi1wxERERGRCSg3QX6Xu/ePv3H33cC7KhLRMaDnsdsJcOpOvrTaoYiIiIjIBJWbICfMbE9TqJklAN2a4SBGNq4g4ylmnXFptUMRERERkQkqtw/yfxFdkPeV+P274zI5gJptK9joszhhRlO1QxERERGRCSo3Qf4gUVL8J/H7u4B/rUhE093gNuYMreLBhtdxaq1uES0iIiIy3ZSVILt7CHwpfskhjG1fQx2QX3xZtUMRERERkSNQVh9kM1tiZj80s6fMbMP4q4z5rjSzZ8xsnZnddJBprouX+6SZfWeiGzDV7HjuSQDmnHhmlSMRERERkSNRbheL/wd8HPgn4OXAOzhMch1fyPcF4HKgG3jYzG5z96dKplkCfAi42N13m9mMiW/C1DK8ZQ1jnuakE0+udigiIiIicgTKvYtFnbv/AjB33+TunwBedZh5LgDWufsGd88B3wWu3W+adwFfiG8bh7vvLD/0qalu1xNstHnMbKmrdigiIiIicgTKTZCzZhYAa83sT83sdUDjYeaZC2wued8dl5U6GTjZzP7HzB4wsysPtCAzu8HMVpjZip6enjJDroIwZP7oajY3n0PJXfFEREREZBopN0F+L1AP/DlwHnA98LZJWH8SWAJcCrwZ+GrpE/vGufvN7r7c3Zd3dXVNwmorY9f2TaQpUDf7lGqHIiIiIiJH6LB9kOO+xG909w8Aw0T9j8uxBZhf8n5eXFaqG3jQ3fPAc2b2LFHC/HCZ65hSnl3zJJ3AnIXqfywiIiIyXR22Bdndi8BLj2DZDwNLzGyxmaWBNwG37TfNT4hajzGzTqIuF4e9O8ZUNbbulwAsOP3CKkciIiIiIkeq3LtYPGZmtwE/AEbGC9393w82g7sXzOxPgZ8DCeAWd3/SzD4FrHD32+JxrzSzp4AicKO79x7htlTdjJ3/w8bUiSxqmV3tUERERETkCJWbINcCvcDvlJQ5cNAEGcDd7wDu2K/sYyXDDvxF/JrWBnb3cmr+aR6ffz2Lqh2MiIiIiByxcp+kV26/4+PW9jv+llOsSPrs11c7FBERERF5EcpKkM3s/xG1GO/D3d856RFNQ71P/4pT1v4r/2GXcvmyI+muLSIiIiJTRbldLP6zZLgWeB2wdfLDmX7Wfvv9LFn7rwDM/72/ozaVqHJEIiIiIvJilNvF4kel783sVuDXFYloGunbtnFPcvzQaR/igqWnVjkiEREREXmxym1B3t8SYMZkBjLtuJP+f5cDsOHV3+eC5VdUOSARERERmQzl9kEeYt8+yNuBD1Ykouliw7005nbyP3Uv52IlxyIiIiLHjHK7WDRVOpDpZuS5B2kAnrngr7m42sGIiIiIyKQ57JP0AMzsdWbWUvK+1cxeW7GopoHB7jVs9XZOX6iHgoiIiIgcS8pKkIGPu/vA+Bt37wc+XpGIpove9Wz0WZw+t+Xw04qIiIjItFFugnyg6Y70Ar/pz52mkeforZlPY83xWw0iIiIix6JyE+QVZvYZMzsxfn0GeKSSgU1pQ9tpDIfIt51c7UhEREREZJKVmyD/GZADvgd8F8gA76lUUFNdZvNKAGzO2dUNREREREQmXbl3sRgBbqpwLNPG0KZHqQVq551V7VBEREREZJKVexeLu8ysteR9m5n9vGJRTXG5nevY7m3Mnjmz2qGIiIiIyCQrt4tFZ3znCgDcfTfH8ZP0wqEd9HgL89vqqh2KiIiIiEyychPk0MwWjL8xs0Xs+2S9AzKzK83sGTNbZ2YH7aJhZq83Mzez5WXGU1WJsV30WRvtDelqhyIiIiIik6zce5R9GPi1md0HGHAJcMOhZjCzBPAF4HKgG3jYzG5z96f2m64JeC/w4ARjr5rabC+Z9HzMrNqhiIiIiMgkK6sF2d3/C1gOPAPcCrwfGDvMbBcA69x9g7vniO5+ce0Bpvs/wN8R3Rlj6gtDmou7KdR3VTsSEREREamAslqQzeyPiFp55wErgQuB+4HfOcRsc4HNJe+7gZfst9xzgfnufruZ3Vh+2FWU6SdJERqP2y7YIiIiIse0crtYvBc4H3jA3V9uZqcCf/tiVmxmAfAZ4O1lTHsDcZeOBQsWHGbqyioMbCMJBEqQRUREZBrL5/N0d3eTyUyPk/gvRm1tLfPmzSOVSpU1fbkJcsbdM2aGmdW4+xozO+Uw82wB5pe8nxeXjWsCzgDujfvyzgJuM7Nr3H1F6YLc/WbgZoDly5cf9uLAShresZ5WgLaF1QxDRERE5EXp7u6mqamJRYsWHdPXVbk7vb29dHd3s3jx4rLmKfcuFt3xfZB/AtxlZj8FNh1mnoeBJWa22MzSwJuA20qCHXD3Tndf5O6LgAeAFyTHU01mxzoA0l0nVjkSERERkSOXyWTo6Og4ppNjADOjo6NjQi3l5T5J73Xx4CfM7B6gBfivw8xTMLM/BX4OJIBb3P1JM/sUsMLdbzvU/FNVfmAbWU/R3K6HhIiIiMj0dqwnx+Mmup3ldrHYw93vm8C0dwB37Ff2sYNMe+lEY6mG4vAudtNIZ1NttUMRERERkQoot4uFxGy0l93eREejHhIiIiIicqT6+/v54he/OOH5rr76avr7+yc/oBJKkCcokemjnyaaaibc+C4iIiIisYMlyIVC4ZDz3XHHHbS2tlYoqoiyvAlqzGxnd/L046bPjoiIiEgl3HTTTaxfv55ly5aRSqWora2lra2NNWvW8Oyzz/La176WzZs3k8lkeO9738sNN0QPcV60aBErVqxgeHiYq666ipe+9KX85je/Ye7cufz0pz+lrq7uRcemBHkiClmaC7vor5tT7UhEREREJs0n/+NJnto6OKnLXDqnmY+/5vSDjv/0pz/N6tWrWblyJffeey+vetWrWL169Z5bsd1yyy20t7czNjbG+eefz+tf/3o6Ojr2WcbatWu59dZb+epXv8p1113Hj370I66//voXHbsS5IkY3kGAk6nTHSxEREREJtMFF1ywz32KP/e5z/HjH/8YgM2bN7N27doXJMiLFy9m2bJlAJx33nls3LhxUmJRgjwRo73R34bO6sYhIiIiMokO1dJ7tDQ0NOwZvvfee7n77ru5//77qa+v59JLLz3gfYxramr2DCcSCcbGxiYlFl2kNwE+EiXIySYlyCIiIiIvRlNTE0NDQwccNzAwQFtbG/X19axZs4YHHnjgqMamFuQJyAzupA6obZpR7VBEREREprWOjg4uvvhizjjjDOrq6pg5c28X1iuvvJIvf/nLnHbaaZxyyilceOGFRzU2JcgTMNrfQx1Q36YEWUREROTF+s53vnPA8pqaGn72s58dcNx4P+POzk5Wr169p/wDH/jApMWlLhYTkB3soehGU6u6WIiIiIgcq5QgT0BheBf9NNLZ/OLvryciIiIiU5MS5AkIh6PHTHc11hx+YhERERGZlpQgT8RYL/000akEWUREROSYpQR5AlKZ3YylWgkCPWZaRERE5FilBHkC6gr9FGrbqx2GiIiIiFSQEuRyhUWawkG8ruPw04qIiIjIIfX39/PFL37xiOb97Gc/y+jo6CRHtFdFE2Qzu9LMnjGzdWZ20wHG/4WZPWVmq8zsF2a2sJLxvBjZnvWkKFBsO6HaoYiIiIhMe1M5Qa7Yg0LMLAF8Abgc6AYeNrPb3P2pkskeA5a7+6iZ/Qnw98AbKxXTi7F74ypmAclZp1U7FBEREZFp76abbmL9+vUsW7aMyy+/nBkzZvD973+fbDbL6173Oj75yU8yMjLCddddR3d3N8VikY9+9KPs2LGDrVu38vKXv5zOzk7uueeeSY+tkk/SuwBY5+4bAMzsu8C1wJ4E2d1Lt+gB4PoKxvOijG15EoDGeWdUORIRERGRSfazm2D7E5O7zFlnwlWfPujoT3/606xevZqVK1dy55138sMf/pCHHnoId+eaa67hl7/8JT09PcyZM4fbb78dgIGBAVpaWvjMZz7DPffcQ2dnZR7eVskuFnOBzSXvu+Oyg/lD4IDPFDSzG8xshZmt6OnpmcQQy+e9a9niHcyd2VWV9YuIiIgcq+68807uvPNOzjnnHM4991zWrFnD2rVrOfPMM7nrrrv44Ac/yK9+9StaWlqOSjyVbEEum5ldDywHfvtA4939ZuBmgOXLl/tRDG2P1OBmtngX5zXXVmP1IiIiIpVziJbeo8Hd+dCHPsS73/3uF4x79NFHueOOO/jIRz7CZZddxsc+9rGKx1PJFuQtwPyS9/Pisn2Y2SuADwPXuHu2gvG8KA1jW9mdnk1C90AWERERedGampoYGhoC4IorruCWW25heHgYgC1btrBz5062bt1KfX09119/PTfeeCOPPvroC+athEq2ID8MLDGzxUSJ8ZuAt5ROYGbnAF8BrnT3nRWM5cUp5Ggt9DDSfKgeIiIiIiJSro6ODi6++GLOOOMMrrrqKt7ylrdw0UUXAdDY2Mi3vvUt1q1bx4033kgQBKRSKb70pS8BcMMNN3DllVcyZ86c6XWRnrsXzOxPgZ8DCeAWd3/SzD4FrHD324B/ABqBH5gZwPPufk2lYjpig90EOGHLgmpHIiIiInLM+M53vrPP+/e+9737vD/xxBO54oorXjDfn/3Zn/Fnf/ZnFYuron2Q3f0O4I79yj5WMvyKSq5/sozu3EA9kOpYXO1QRERERKTC9CS9MvRvXQ9A0yw9JERERETkWKcEuQyjO5+j4AFdc9SCLCIiIscO96rcHOyom+h2KkEuw71z3sUF2S8yv7Op2qGIiIiITIra2lp6e3uP+STZ3ent7aW2tvxb9U6J+yBPdfPaG3jp2afSUpeqdigiIiIik2LevHl0d3dTrYewHU21tbXMmzev7OmVIJfhyjNmceUZs6odhoiIiMikSaVSLF6s7qMHoi4WIiIiIiIllCCLiIiIiJRQgiwiIiIiUsKm25WLZtYDbKrCqjuBXVVY73SkupoY1Vf5VFflU12VT3VVPtXVxKi+yletulro7l37F067BLlazGyFuy+vdhzTgepqYlRf5VNdlU91VT7VVflUVxOj+irfVKsrdbEQERERESmhBFlEREREpIQS5PLdXO0AphHV1cSovsqnuiqf6qp8qqvyqa4mRvVVvilVV+qDLCIiIiJSQi3IIiIiIiIllCCLiIiIiJRQglwGM7vSzJ4xs3VmdlO146k2M5tvZveY2VNm9qSZvTcu/4SZbTGzlfHr6pJ5PhTX3zNmdkX1oj/6zGyjmT0R18mKuKzdzO4ys7Xx37a43Mzsc3FdrTKzc6sb/dFjZqeU7DsrzWzQzN6n/WovM7vFzHaa2eqSsgnvS2b2tnj6tWb2tmpsS6UdpK7+wczWxPXxYzNrjcsXmdlYyT725ZJ5zov/f9fF9WlV2JyKOkhdTfj/7nj4rTxIXX2vpJ42mtnKuPx4368OlitMj+8sd9frEC8gAawHTgDSwOPA0mrHVeU6mQ2cGw83Ac8CS4FPAB84wPRL43qrARbH9Zmo9nYcxfraCHTuV/b3wE3x8E3A38XDVwM/Awy4EHiw2vFXqc4SwHZgofarfbb5ZcC5wOoj3ZeAdmBD/LctHm6r9rYdpbp6JZCMh/+upK4WlU6333IeiuvP4vq8qtrbdpTqakL/d8fLb+WB6mq/8f8IfEz71SFzhWnxnaUW5MO7AFjn7hvcPQd8F7i2yjFVlbtvc/dH4+Eh4Glg7iFmuRb4rrtn3f05YB1RvR7PrgW+Hg9/HXhtSfk3PPIA0Gpms6sQX7VdBqx390M9NfO426/c/ZdA337FE92XrgDucvc+d98N3AVcWfHgj7ID1ZW73+nuhfjtA8C8Qy0jrq9md3/Ao1/qb7C3fo8ZB9mvDuZg/3fHxW/loeoqbgW+Drj1UMs4jvarg+UK0+I7Swny4c0FNpe87+bQyeBxxcwWAecAD8ZFfxqfGrll/LQJqkMH7jSzR8zshrhsprtvi4e3AzPj4eO9rsa9iX1/ZLRfHdxE9yXVW+SdRK1V4xab2WNmdp+ZXRKXzSWqn3HHW11N5P9O+xVcAuxw97UlZdqveEGuMC2+s5QgyxEzs0bgR8D73H0Q+BJwIrAM2EZ0qkngpe5+LnAV8B4ze1npyLgFQfdbjJlZGrgG+EFcpP2qTNqXymNmHwYKwLfjom3AAnc/B/gL4Dtm1lyt+KYI/d9N3JvZ98Be+xUHzBX2mMrfWUqQD28LML/k/by47LhmZimiHf7b7v7vAO6+w92L7h4CX2Xv6e7jug7dfUv8dyfwY6J62THedSL+uzOe/Liuq9hVwKPuvgO0X5VhovvScV1vZvZ24NXA78c/zsTdBXrj4UeI+tKeTFQvpd0wjpu6OoL/u+N9v0oCvwt8b7xM+9WBcwWmyXeWEuTDexhYYmaL45atNwG3VTmmqor7Wf0b8LS7f6akvLSv7OuA8at8bwPeZGY1ZrYYWEJ0gcIxz8wazKxpfJjoIqHVRHUyfiXu24CfxsO3AX8QX817ITBQcirqeLFPK4z2q8Oa6L70c+CVZtYWnzZ/ZVx2zDOzK4G/BK5x99GS8i4zS8TDJxDtSxvi+ho0swvj770/YG/9HtOO4P/ueP+tfAWwxt33dJ043verg+UKTJfvrEpfBXgsvIiurHyW6Ojvw9WOp9ov4KVEp0RWASvj19XAN4En4vLbgNkl83w4rr9nOAav1j1EXZ1AdDX348CT4/sP0AH8AlgL3A20x+UGfCGuqyeA5dXehqNcXw1AL9BSUqb9au/23kp02jZP1A/vD49kXyLqf7sufr2j2tt1FOtqHVFfxvHvrS/H074+/v9cCTwKvKZkOcuJksP1wOeJn0B7LL0OUlcT/r87Hn4rD1RXcfnXgD/eb9rjfb86WK4wLb6z9KhpEREREZES6mIhIiIiIlJCCbKIiIiISAklyCIiIiIiJZQgi4iIiIiUUIIsIiIiIlJCCbKIyHHIzC41s/+sdhwiIlOREmQRERERkRJKkEVEpjAzu97MHjKzlWb2FTNLmNmwmf2TmT1pZr8ws6542mVm9oCZrTKzH8dPncLMTjKzu83scTN71MxOjBffaGY/NLM1Zvbt+MlXIiLHPSXIIiJTlJmdBrwRuNjdlwFF4PeJnji4wt1PB+4DPh7P8g3gg+5+FtGTqMbLvw18wd3PBn6L6ElgAOcA7wOWEj318eIKb5KIyLSQrHYAIiJyUJcB5wEPx427dcBOIAS+F0/zLeDfzawFaHX3++LyrwM/MLMmYK67/xjA3TMA8fIecvfu+P1KYBHw64pvlYjIFKcEWURk6jLg6+7+oX0KzT6633R+hMvPlgwX0W+CiAigLhYiIlPZL4A3mNkMADNrN7OFRN/db4ineQvwa3cfAHab2SVx+VuB+9x9COg2s9fGy6gxs/qjuREiItONWgtERKYod3/KzD4C3GlmAZAH3gOMABfE43YS9VMGeBvw5TgB3gC8Iy5/K/AVM/tUvIzfO4qbISIy7Zj7kZ6ZExGRajCzYXdvrHYcIiLHKnWxEBEREREpoRZkEREREZESakEWERERESmhBFlEREREpIQSZBERERGREkqQRURERERKKEEWERERESmhBFlEREREpIQSZBERERGREkqQRURERERKKEEWERERESmhBFlEREREpIQSZBGRacjMvmZmf13mtBvN7BUvdjkiIscLJcgiIiIiIiWUIIuIiIiIlFCCLCJSIXHXhhvNbJWZjZjZv5nZTDP7mZkNmdndZtZWMv01ZvakmfWb2b1mdlrJuHPM7NF4vu8Btfut69VmtjKe9zdmdtYRxvwuM1tnZn1mdpuZzYnLzcz+ycx2mtmgmT1hZmfE4642s6fi2LaY2QeOqMJERKYIJcgiIpX1euBy4GTgNcDPgL8Cuoi+g/8cwMxOBm4F3hePuwP4DzNLm1ka+AnwTaAd+EG8XOJ5zwFuAd4NdABfAW4zs5qJBGpmvwP8f8B1wGxgE/DdePQrgZfF29EST9Mbj/s34N3u3gScAfz3RNYrIjLVKEEWEamsf3H3He6+BfgV8KC7P+buGeDHwDnxdG8Ebnf3u9w9D/xfoA74LeBCIAV81t3z7v5D4OGSddwAfMXdH3T3ort/HcjG803E7wO3uPuj7p4FPgRcZGaLgDzQBJwKmLs/7e7b4vnywFIza3b33e7+6ATXKyIypShBFhGprB0lw2MHeN8YD88harEFwN1DYDMwNx63xd29ZN5NJcMLgffH3Sv6zawfmB/PNxH7xzBM1Eo8193/G/g88AVgp5ndbGbN8aSvB64GNpnZfWZ20QTXKyIypShBFhGZGrYSJbpA1OeXKMndAmwD5sZl4xaUDG8G/sbdW0te9e5+64uMoYGoy8YWAHf/nLufBywl6mpxY1z+sLtfC8wg6gry/QmuV0RkSlGCLCIyNXwfeJWZXWZmKeD9RN0kfgPcDxSAPzezlJn9LnBBybxfBf7YzF4SX0zXYGavMrOmCcZwK/AOM1sW91/+W6IuIRvN7Px4+SlgBMgAYdxH+vfNrCXuGjIIhC+iHkREqk4JsojIFODuzwDXA/8C7CK6oO817p5z9xzwu8DbgT6i/sr/XjLvCuBdRF0gdgPr4mknGsPdwEeBHxG1Wp8IvCke3UyUiO8m6obRC/xDPO6twEYzGwT+mKgvs4jItGX7dmkTERERETm+qQVZRERERKSEEmQRERERkRJKkEVERERESihBFhEREREpkax2ABPV2dnpixYtqnYYIiIiIjLNPfLII7vcvWv/8mmXIC9atIgVK1ZUOwwRERERmebMbNOBytXFQkRERESkhBJkEREREZESSpDL8OzKX/PADz7Dzu3d1Q5FRERERCps2vVBroa+h3/AhVu+RnH1p1iZPpu+s97Fb13xJmrTqj4RERGZnvL5PN3d3WQymWqHUnG1tbXMmzePVCpV1vTT7lHTy5cv96N9kZ6HIZufeoCdD/2QBd23MSPs4VkW0XfZ/+XCSy4/qrGIiIiITIbnnnuOpqYmOjo6MLNqh1Mx7k5vby9DQ0MsXrx4n3Fm9oi7L99/HnWxKIMFAQvO+C2Wv/MzdP3VU6y7+B9otWHOvvst3PHT71Q7PBEREZEJy2Qyx3xyDGBmdHR0TKilXAnyBFkyzUmX30Dr+35DX808Lnn0L3hgxcPVDktERERkwo715HjcRLdTCfIRSrfMpOOGnxCYEd5+I2O5YrVDEhEREZFJoAT5RajtXEjveX/Ob/lj3HXXHdUOR0RERGTa6O/v54tf/OKE57v66qvp7++f/IBKKEF+kRZc/h5GrY7Gx25mul3wKCIiIlItB0uQC4XCIee74447aG1trVBUESXIL1ZtM93zr+HC/IOs6d5V7WhEREREpoWbbrqJ9evXs2zZMs4//3wuueQSrrnmGpYuXQrAa1/7Ws477zxOP/10br755j3zLVq0iF27drFx40ZOO+003vWud3H66afzyle+krGxsUmJTTfynQQzzn019c9/j2dX3MVp899S7XBEREREJuST//EkT20dnNRlLp3TzMdfc/pBx3/6059m9erVrFy5knvvvZdXvepVrF69es+t2G655Rba29sZGxvj/PPP5/Wvfz0dHR37LGPt2rXceuutfPWrX+W6667jRz/6Eddff/2Ljl0tyJOg9bTfoUgA6++tdigiIiIi09IFF1ywz32KP/e5z3H22Wdz4YUXsnnzZtauXfuCeRYvXsyyZcsAOO+889i4ceOkxKIW5MlQ08i2upOZPbSaMHSC4Pi4ZYqIiIgcGw7V0nu0NDQ07Bm+9957ufvuu7n//vupr6/n0ksvPeB9jGtqavYMJxKJSetiUbEWZDObb2b3mNlTZvakmb33ANOYmX3OzNaZ2SozO7dS8VTa2KzlnME6Nuzsr3YoIiIiIlNeU1MTQ0NDBxw3MDBAW1sb9fX1rFmzhgceeOCoxlbJLhYF4P3uvhS4EHiPmS3db5qrgCXx6wbgSxWMp6IaT7iAesuy8ZmV1Q5FREREZMrr6Ojg4osv5owzzuDGG2/cZ9yVV15JoVDgtNNO46abbuLCCy88qrFVrIuFu28DtsXDQ2b2NDAXeKpksmuBb3h0f7QHzKzVzGbH804rnScth19AZvMq4OXVDkdERERkyvvOd75zwPKamhp+9rOfHXDceD/jzs5OVq9evaf8Ax/4wKTFdVQu0jOzRcA5wIP7jZoLbC553x2X7T//DWa2wsxW9PT0VCzOFyPVeQIAhb6N1Q1ERERERF6UiifIZtYI/Ah4n7sf0f1D3P1md1/u7su7uromN8DJkqpjINFGeuj5akciIiIiIi9CRRNkM0sRJcffdvd/P8AkW4D5Je/nxWXT0nDdXFqz2whDPVFPREREZLqq5F0sDPg34Gl3/8xBJrsN+IP4bhYXAgPTsf/xuFzjfObSw67hbLVDEREREZEjVMn7IF8MvBV4wsxWxmV/BSwAcPcvA3cAVwPrgFHgHRWMp/LaFjJn252s7htmRnNttaMRERERkSNQybtY/Bo45BMz4rtXvKdSMRxttV0nkLIiu7dvhEWd1Q5HRERERI6AHjU9iZpmnwjA6I4NVY5EREREZGrr7+/ni1/84hHN+9nPfpbR0dFJjmgvJciTqGGGbvUmIiIiUo6pnCBXsg/yccda51MkIDGgW72JiIiIHMpNN93E+vXrWbZsGZdffjkzZszg+9//Ptlslte97nV88pOfZGRkhOuuu47u7m6KxSIf/ehH2bFjB1u3buXlL385nZ2d3HPPPZMemxLkyZRIMZRoJT22o9qRiIiIiJTvZzfB9icmd5mzzoSrPn3Q0Z/+9KdZvXo1K1eu5M477+SHP/whDz30EO7ONddcwy9/+Ut6enqYM2cOt99+OwADAwO0tLTwmc98hnvuuYfOzspc86UuFpNsNNVOXa6v2mGIiIiITBt33nknd955J+eccw7nnnsua9asYe3atZx55pncddddfPCDH+RXv/oVLS0tRyUetSBPsmxNB82juwhDJwgOeRMPERERkanhEC29R4O786EPfYh3v/vdLxj36KOPcscdd/CRj3yEyy67jI997GMVj0ctyJOsWN9Fpw2wezRX7VBEREREpqympiaGhoYAuOKKK7jlllsYHh4GYMuWLezcuZOtW7dSX1/P9ddfz4033sijjz76gnkrQS3Ik61xBl0MsHEoS0djTbWjEREREZmSOjo6uPjiiznjjDO46qqreMtb3sJFF10EQGNjI9/61rdYt24dN954I0EQkEql+NKXvgTADTfcwJVXXsmcOXMqcpGeRc/qmD6WL1/uK1asqHYYB7XxP/6ORY/8LQ9ct5ILly6udjgiIiIiB/T0009z2mmnVTuMo+ZA22tmj7j78v2nVReLSVbbOhOA4b6tVY5ERERERI6EEuRJ1tgxB4CMEmQRERGRaUkJ8iRraJ8NQH5wZ5UjERERETm06dbV9khNdDuVIE8ya4y6WDCsh4WIiIjI1FVbW0tvb+8xnyS7O729vdTW1pY9j+5iMdnqOwgxbHRXtSMREREROah58+bR3d1NT09PtUOpuNraWubNm1f29EqQJ1uQYCRoIp3V0/RERERk6kqlUixerDtuHUjFuliY2S1mttPMVh9k/KVmNmBmK+NX5R+LcpSMJlupze+udhgiIiIicgQq2YL8NeDzwDcOMc2v3P3VFYyhKrI17TRmBnB3zPS4aREREZHppGItyO7+S+C47GdQrG2njUEGM4VqhyIiIiIiE1Ttu1hcZGaPm9nPzOz0g01kZjeY2QozWzEtOpI3dNJug/QOZ6sdiYiIiIhMUDUT5EeBhe5+NvAvwE8ONqG73+zuy919eVdX19GK74glGrtoY5hdg2PVDkVEREREJqhqCbK7D7r7cDx8B5Ays85qxTOZ0s0zCMwZ2q2HhYiIiIhMN1VLkM1slsVXsJnZBXEsvdWKZzLVtc4AYKRfDwsRERERmW4qdhcLM7sVuBToNLNu4ONACsDdvwy8AfgTMysAY8Cb/Bh5lEtj2ywAMkqQRURERKadiiXI7v7mw4z/PNFt4I45iaaon3RxeBpcUCgiIiIi+6j2XSyOTfVRV2of1uOmRURERKYbJciVUN8BQCJzTHSpFhERETmuKEGuhGSa0aCBdFaPmxYRERGZbspKkM3svWbWbJF/M7NHzeyVlQ5uOhtLtVOfVwuyiIiIyHRTbgvyO919EHgl0Aa8Ffh0xaI6BozWzqIr3EW2UKx2KCIiIiIyAeUmyBb/vRr4prs/WVImB5Bvmstc20XvcK7aoYiIiIjIBJSbID9iZncSJcg/N7MmIKxcWMeApll0MkDvUKbakYiIiIjIBJR7H+Q/BJYBG9x91MzagXdULKpjQLp5Jglzendth/lt1Q5HRERERMpUbgvyRcAz7t5vZtcDHwEGKhfW9NfUET1Nr79nW5UjEREREZGJKDdB/hIwamZnA+8H1gPfqFhUx4Cm9jkADPcpQRYRERGZTspNkAvu7sC1wOfd/QtAU+XCmv6C1nkAFPufr3IkIiIiIjIR5fZBHjKzDxHd3u0SMwuAVOXCOga0zgcgPdRd5UBEREREZCLKbUF+I5Aluh/ydmAe8A8Vi+pYkKxhINlJw+jWakciIiIiIhNQVoIcJ8XfBlrM7NVAxt3VB/kwhuvn0lXYroeFiIiIiEwj5T5q+jrgIeD3gOuAB83sDYeZ5xYz22lmqw8y3szsc2a2zsxWmdm5Ew1+qis0zWOe9bC1X/dCFhEREZkuyu1i8WHgfHd/m7v/AXAB8NHDzPM14MpDjL8KWBK/biC6U8YxJd2+gJnWx/odg9UORURERETKVG6CHLj7zpL3vYeb191/CfQdYpJrgW945AGg1cxmlxnPtNA6azFpK7Kle1O1QxERERGRMpWbIP+Xmf3czN5uZm8HbgfueJHrngtsLnnfHZe9gJndYGYrzGxFT0/Pi1zt0VM3+xQAxrY8UeVIRERERKRcZd3mzd1vNLPXAxfHRTe7+48rF9YL1n8zcDPA8uXL/Wit90WbvQyA+l1KkEVERESmi3Lvg4y7/wj40SSuewswv+T9vLjs2FHXSm/NfGaPPEUYOkFg1Y5IRERERA7jkF0szGzIzAYP8Boysxd75dltwB/Ed7O4EBhw92PuuczDHWdxOutZ3zNc7VBEREREpAyHbEF29yN+nLSZ3QpcCnSaWTfwceKn77n7l4n6MF8NrANGgXcc6bqmsqYTzqd96+38YM2zLJl5XrXDEREREZHDKLuLxUS5+5sPM96B91Rq/VNF25KXwK+h79kH4LeVIIuIiIhMdeXexUKOkM05l5yladn2P0THBCIiIiIylSlBrrRULbs6lnNeYSWbekerHY2IiIiIHIYS5KOg9pTLWRJs4f7HHq92KCIiIiJyGEqQj4L2s6Inbvc+/l9VjkREREREDkcJ8tEw4zSG010sGniQjbtGqh2NiIiIiByCEuSjwYzEKVfwO8FjfPc+dbMQERERmcqUIB8ldRe9i3rLMvz4T9g9kqt2OCIiIiJyEEqQj5bZZ5NrWcQr/Td884FN1Y5GRERERA5CCfLRYkb6rDfwssQTcN/fs3MoU+2IREREROQAlCAfTS/932RmnsOfB9/niz9fVe1oREREROQAlCAfTTWN1L7iwwBcterPuP3xrVUOSERERET2pwT5aDvxMgrn38BLgjWM/Og9rNzcX+2IRERERKSEEuSjLQhIvvL/EDbM4Lrgv/nCLbewdsdQtaMSERERkZgS5GpI1RK893HyLYv5qn+S227+GE90D1Q7KhERERGhwgmymV1pZs+Y2Tozu+kA499uZj1mtjJ+/VEl45lS0vWk3vIdAN5fvIUHv/InfOv+jbh7lQMTEREROb5VLEE2swTwBeAqYCnwZjNbeoBJv+fuy+LXv1Yqnilp5lJ432oKM87kjxK3037Hu3jHF3/O4+qXLCIiIlI1lWxBvgBY5+4b3D0HfBe4toLrm55a55N8y614TTNXJx7i8z1v586v/CWf/+mvGMsVqx2diIiIyHGnkgnyXGBzyfvuuGx/rzezVWb2QzObX8F4pq7W+diHNsMf3k1t21xuTH6PP33s1fz1pz/FF37xNAMjY9WOUEREROS4Ue2L9P4DWOTuZwF3AV8/0ERmdoOZrTCzFT09PUc1wKNq/vkkb/gFzF4GwN+En+U9v7qQhn+Yw+23/DVbtzxf3fhEREREjgNWqYvCzOwi4BPufkX8/kMA7v7/HWT6BNDn7i2HWu7y5ct9xYoVkx3u1PPsz+Gpn9I/NEzr+p/uKf553dV0zVnEvGs/yozm+ioGKCIiIjK9mdkj7r78BeUVTJCTwLPAZcAW4GHgLe7+ZMk0s919Wzz8OuCD7n7hoZZ73CTIpe77B7jnr/cp2uKdbK5ZwpMXf45li7o4d0ErZlalAEVERESmn6OeIMcrvRr4LJAAbnH3vzGzTwEr3P02M/v/gGuAAtAH/Im7rznUMo/LBBkgDKF/Ezz0VQqPf4/k2K59Rn8veQ2rT3sfp89u5hVnLaCzsaZKgYqIiIhMD1VJkCvhuE2QS7nDUz/Bf3YTxVQ9yd0b9oza5c2sCk/g543XMnfWbGbOW8zSU07j1NlNpBLV7nIuIiIiMnUoQT6WbX8C/vtvyDXOJbnyGwRhbp/RO72VFEW21SziyXlvZGzJazhtVhPLF7WrW4aIiIgct5QgHy/GdsPmh+Cpn8LKbx9wkufCmSwOdvBQeCr317yU7jlXctLsdk5aMJeFnQ0s7mwkEShxFhERkWObEuTjWWYAetfBHTfita0Uux8lmd198Mk9xabUCdy24IM0zjmFs5LddJywjBnNdbS1NKvVWURERI4JSpDlhUZ6Ye2dsPFXFLc+TmLnagpBDckwe8DJCx5wt11IX/0J7Oq6kDmtdbS1ttCx4DRmNNcym15s9yZoWwhdpxzljRERERGZGCXIUr7cCDz8b9C7jnxNK/7EDxlKz2TEGpjX+2sCyttnNs26gr45v01h6e/S0dzIos5GAnXdEBERkSlCCbJMjuww7H4Otj1OYc3PyORDfNc6Etnd1GcP/5TDlXYaZ/izrG84F2oa6Om4gE3zruGsVDez+x6m9cq/IplMHoUNERERkeOdEmSpvDCMLhIs5gh3rWV01U9JbryXsVQbieFtNI91H3YRvd5EAqfVhveU3bfgPeTaTiZfP4M56VEaEwXmb7uTmss+BK0LIZmGnU9D58kQJCq5hSIiInIMUYIsU4M7hEXofphiPsPY0G4Gu58m6wkanr8HG+2hdWwzKc8dflnAiNfQYFGf6V3JWTzY8TpeteNLAAy0nEameTEjsy9kZMlrmDljBm07HyY17xxIN0AiVbHNFBERkalPCbJMP8UCDDxPmB1hdOtTFHY8Q1/QTti7noXrv0MuqAOchkJ/WYsL3Qhs7/7+a5aRTqWwZA1tNkyNFWku7GL93GuZP7yKGh+jb/4VpGvqGJtzER02SMPo8wRLryXxzH9C+4lgBrPOihZY2xz9HdoBda2QjJ9mOLgVGmeqdVtERGSKUYIsx65iHjAoZiEs4slahnq30r9pFYXsGIXsCMneteR2dzNj4Anax54DYGdyDg3Ffmo8S5Liiw5jMGilOezf874QpBmpn0/L8Hr6Zr+M3Y1LqE0CHSfRUuyj8f5/IGw/EV/6WmzhSwnaF0Lfc7D1MTjneqjviLqP5DOQH4VV34Pl79ybeLtDWCi/Jdw9SuhFREQEUIIscmi71kFdK2FdB4N9O+nr66Gw6SHAyY8Nks8XSPQ8SaKYoWNkLVtqlpAJ6jhx8EF6aWM3TcwOt9FW7CNNjgYyQHRP6VrLv6D1ulwj1kiDD+9TNpzqYDTdQWtmC+niCDvbzsETNViQJF0Yom5sO4kwSzHdRL71RKhrh+Y5NKz6OuGMpdiJLycY6YH+56GmEZZdH7V454ajBL3jxOi+2QtfGiXUWx6B066BZ38GqfroLifzXwKt8/cGNdANTXNgtBd+9Ifwyr+G2WdF/dKD+BHn7lGin24o2Zie6EAg0GPQRUTk6FOCLHIUhaEznCswMJpnMJNnsG8Xtdke6kaeZ1cwA7atIjW2ky2NZ5BNNNG86xGy+QLp4ijzR59ilDq6w3Y6wl7q830kCDk/fJxfcD714Sin2iae8fnUkCdPglaGabIxZlsfAOvD2ZwYbKvoNg7ULyRM1tE0solkcYzQUgSe37cegjT5thOhro1kZjeJXU8TzjkPaluwrY9gmQEAfMkV2JZHogS6cwm0LYqeBgkw60w46RXw63+CuedFCfqcc6DnGWiaDcVclHTPOhMauqB1AfSth5oW2LIiSto7T4nGb/wVLLwYGmdE6+p+GMb64eQronUVMtF6X/q/IZGGQjbqGrNrLcw8A5pmRReiWhCVewi7N0GQjJbXugBSdYBFf0d6ou41ZtGZDkvAziehtgXSjVDfvl+lxheytswrqcT4IMM9ii8/9sL5JkvpAY1MXCEL2SFo6Kx2JCJSJiXIIseQMHRyxZBsPiRTKJLNh2QLRTK5ItlCkWzRyeSLZPPR++LYAPlcFjKDFHJZtqfnQXaYWf2PQSFDLoT6bA81hSGGwloI8wyEdXQUdtJU3E1roYc8Keaxg13eQpsNs8lnUEeOUWpoYYRnfD5NjHJy0E2eJKNeQ5Y0c2wXWVLMt5102SBPhQvJkSTEODdYd8DtG6WW+rgVfqpyDDvUPcEtiBJogIYZMLITapohO7h3mnkXQPdDL5y3vjM6ECiMRcN1rVGr/rgZS6PEvm0RbH4QvAjNc6MLYEd64MSXw44nYckrof0EWHN7lNAXslFf+XwGhndECXmyFnJD0dmB/CgsflkUZ99zMOuMqHzrY9HyG2dEZxp2b4SOJdH7dEN0AJAdipbfOAMKOUgko9tCjvREsS54CexcEx20nHIVbLgPLvpTyPRD94povid/Ej35c9lboGVuVId9z8HQtuigaMZpUb0kUtE1CvVt0YHSWD+c+DvRthUy0fK6H4YnfgBti2Hm6fCSP44eYLTjyejgZWx3dNDRvjj6mx2C534JnSdFBzWNM6OzJ7s3RtcZdJwE21fBilugeQ5c8oGoTmuaonmb58Ctb4YN98BfrInGrfo+nPaaqI6StVH9/Poz0Wdy5hsAg/W/gJOvjD4LC6JtXXhxFGfbQkjWRXUZFvee4Slk4Pn7YbQP5p4bLXfzg9Fy578E1t0dHUw2zYLcaPS51rVHf4NEtP2FXNSFKzcSfcZmUT2M7Yah7dHndNabomnC4t59GqKuXfmx6LNtPyGKJ1UX/2McoitXGMLA5mi7CrkolmIuWpYFUfexoe1RXdR3RJ9n6cEiQN8G6H4Ell4THZgSn+WqaYSuUw/fjayYj/bh2tZo2oFueOhmePlHolhSdVFc+bG929S3IdpOiPa7ILF3PWEx+j8f7+qWz0TbEhZgdFf0+TV27RuDO2z6H1hw0eGvTSnmYcuj0f8PRPsaFm1vIQd4tM/84v/Aa/45Kt+/zg920NvzTLRfti08dAylcY9v93j9uEf7KkTfF0cqO/zC2I8SJcgi8qJlC0UCM0azRXLFkEy+SL4YJYG5YkiuEJItRIl7vhhSDJ3hbIGRXIFcIXpfCD36W3RwJzHWw2CijeFckYQZI9k8hRAK+Ty1uV6GigmKuSyj+ZBEMkWQH6bOMwwW09QWhwnDkESYJR/CKeEGhsJaNodtDHo97TbEDPoZI80i284JwXaaGOW+8GxaGAGg3QZZ53O5JFjFDm+nz5toslG2ezsJijSQpd0GSZPnZYknuKe4jEHqSRAyy/o429azm2YW23bWM48WG6bP2hiyRl4R/oYhGngkdS5nFJ6iaElmhjv21Oe6xIksLG5iQ+okTsmvAaAnOYsRa2RRPkqIc0EtQ8kOOnJb9sw3kmghk2wCoCPbTdESJHxvP/qRmhnU5foAJ4jLs6kWEmGOIMztKZNponkeDB7+NpkvZPGBWsnnbYm970uH69phrO+Fi2hdGJ2FKeaj6zyStVFSOH5gtX+MtS3R2ZdiPhoOktEZnfEDBDw62Brc8sJ1lR5UjmuZH50pGtsdLW/LikNP33VqlGSbRevp3wzZgehgNFUbHQSNGz9wBUg37d2eVAPkR6Jbhw7vjA7i9jd3eZS8b7gHHAjz0QFIoiZKjkvrvHkeDG+P1lfXFnVvK627+s7oIKp/0351vyCaFmDRJdE0z/5X9P6kV8Cm+6M4xyVqokR626qoznqe3htr28IorkJ0rQ5m0ZN0AVoWRAeGO56CRRdHB4XJupILz7dHiXnv2ugAund99Pk1zY6WOdKzdzk1TdFB3PhnkxmI1r17U3TWrGdNdKCbHYymSdTA2p9H8//BT+GES19Y1xV2sARZT2QQkbLVJKPWjpb6yTwNf/IkLivi7mQLUQKfLYTs36Z0ejGkfzRPGE+3DDCgNR9SCEMKRWdBfACQSgSYQaHo3F8MSYZOTbbAaK7IlsDYWIymz4ch+YJTCEPyRadQDLk9dPLx+D3lYUgmH9Jal8KBYjxN/2g+Oqhwpz6dYHCsAMBItoAXwQMnERhmRjZfxIsQmFF0J5cPyRcLOBZtSQaiNm6nmVGGqCfMxOOAufSwkzZqyFFDngEaqCVHniQBIV02wG5vIkWBAGeYWjKkaWaUThuglWGabZTV4WLyJEiTxwmYbzvZ7u3sppGFtoMt3snJ1k2BBPWWpc+bSJMnGUBnYoxOG6TbZlIgwRCNzLUeutjNbmshJEE6naLLdzMcNNJoY6QMOuhnLQtpZpj2xBgAGxMLqA+H6WCIrsJ20uR4vP4iEqkazsqswIoZRmpmkMr2szT3BM80voTZ2fWMBY1kEo2cNLaK9Q3nUOejDKZnkk000lbYSdIL1PgYnZnn2dRyPrlEAzXhKE35XRSDGppz2xlLNjNv8HH6mpbQ23AySQoEYY6Ffb9hZv9jbGtbzu7mU6kpDOGpepKjO6kpDBEGKUZbT6Eus4OCB5gXqAnHSBXHyNV20rr7CbJ1Mymkmyimmkg0L6W5bxX5mjYKNe2MtJ9Ow+6nwALyjXNJje2geetvGFhwGY3bHwIL8CDNyJyLsMBIZPohWUuxtpWavmcp1ndiQRJPN2DFPFbMkBzcTJAbptg8H1K1hM3zSAx2Ewxvw3IjgONNc6IzJ8kawLChrVhuKDqjsOSV2PD2KJlN1kTJz+DWKHFqXxS19O94MuqCMrglStBrmqIzFvkROPmq6EzJjif3JpBdp0YPp8qPRQlb0+yoxbr9hCjZ2/n03mR01llRN6tUfbTe4R3RPLnhKGnPDERnIrY+Fk3fOCNK3Ie3Q0PH3nUmkpAnSuiaggMnyMVc1GofdxOjtjVq9TaLEt6tj+6dNjccJ6djsHNrFGNpgjy6a98zS3vKd0cHKP2boiR0tOQAZmjHvskxRAcwm+6PkvXx5LZjSbTsDfdGiXF9R1Tnpcl4IQPr/zsafvbnUbzj8xaz0bqK0e1U2b1x78FNIh21Xo/L9EfzjvRAOv4Mijl4Ll4WHh0s9a2PP8fs3oOytsXRZz2FVLQF2cyuBP4ZSAD/6u6f3m98DfAN4DygF3iju2881DLVgiwi8kLuvqcVP190Ugnb02pf9LjFnqilf3AsTyoRkAiMYhiVF8Ioqc8Xo4Q9XwypSSYYzET9yhOBYfF0tamA4WzUhSedDPYk+eMHBoXQCd2pSSYYzhb2xDeWL5JOJMgVi4zlQhxn/CfI3XGiM7aOUwxhMJMnMMPj+McPMhKBEZgxli9g2J6zvtlCSDIw3KPtHMsVyRSKpIKAfBjSVJOMznCMHzTFvQqK8VmN8boK47/FMBoO45hCj+IMHULfG7vsKzAws33/Ev0NLPq8xsvTySD+zCNGlGOOl6cSAamEUSg6o7kiyYSRDIxEYCSDgNAdi5cblUUHjYkgIBUPj++3ZkYqMIJg7yFzMXTSieiAPxGPC4i6EiSDAIjOdAHUpJIkAosOnJMBRrTe8e00i5ZnQDIR7NmW0m0uLQu8CEGShOchkaZQDEkmou1OJsan3RtrIoB0IkEhjPZhd4+WQ5EEIR4kCSwgMCeZSFKbSuz5vw4CoyYZUJMM6B/Nk04G1KUCAkIskSQA0uEYxWTDnviK7uQKIQ7UFEawdB3pdDo6QKd0e6K/QcA+/48GJPJDFC1NurZuzyecCDNYso5C6CQpEiQCEkGCM+a20NFYM/k75GEc9RZkM0sAXwAuB7qBh83sNnd/qmSyPwR2u/tJZvYm4O+AN1YqJhGRY5WZUZNM7Gnll8pzd/LxgUcxdBwnX3CSiSiJipInYyRXIJkwsvmQhpok7lECPpQp4A41yWBP4pWLuyZ5nISXJuXjBxF7kvbx9yVJOweZb/8kv3T5+88X7jlYiQ4QonWML2d83ni+knj2mW/Pug8833hMuUIYJ4/jdRq9RvPFKNkNoyQtmbA9iWzRfW/iZ0Y+/hvGn0cisBeMb65L7DkIGo/bPUqKs4Vi/NcpxkdpocdJNXu7Z2cLo+SLTl0qQT4Mo9w5/uzH8kVSQXRVQjJhhOHeg6i99V56ILjvZzG+nPFkuxCG+xw4jO9j4we0talgzzaXLqc4jQ/c/t87zuflp8yodhh7VLKLxQXAOnffAGBm3wWuBUoT5GuBT8TDPwQ+b2bm061jtIiIHHfMjHRyvw486ehPQ83en9eW+gPfq3xGU6Uik2PVeAt1aSv4gUTXgxRJBkGUsI93O8sVaapNEcZndPYewIwfIPmeg5TQo4O9dDIgDCFfDMkVQ9KJgCCwvcl9fBAwPs/4mSDwPa3LY/lifFlzNF0hjM5yhSF7ztac1FWdi/QOppIJ8lxgc8n7buAlB5vG3QtmNgB0ALtKJzKzG4AbABYsWFCpeEVERESmrMRhEuNx6WRAOrnvtSI1yQTNtXsP1koP4uSFpsUNL939Zndf7u7Lu7q6Dj+DiIiIiMgRqmSCvAUoedQW8+KyA05jZkmghehiPRERERGRqqhkgvwwsMTMFptZGngTcNt+09wGvC0efgPw3+p/LCIiIiLVVOnbvF0NfJboNm+3uPvfmNmngBXufpuZ1QLfBM4B+oA3jV/Ud4hl9gCbDjVNhXSyX99oOSjV1cSovsqnuiqf6qp8qqvyqa4mRvVVvmrV1UJ3f0H/3Wn3JL1qMbMVB7pPnryQ6mpiVF/lU12VT3VVPtVV+VRXE6P6Kt9Uq6tpcZGeiIiIiMjRogRZRERERKSEEuTy3VztAKYR1dXEqL7Kp7oqn+qqfKqr8qmuJkb1Vb4pVVfqgywiIiIiUkItyCIiIiIiJZQgi4iIiIiUUIJcBjO70syeMbN1ZnZTteOpNjObb2b3mNlTZvakmb03Lv+EmW0xs5Xx6+qSeT4U198zZnZF9aI/+sxso5k9EdfJiris3czuMrO18d+2uNzM7HNxXa0ys3OrG/3RY2anlOw7K81s0Mzep/1qLzO7xcx2mtnqkrIJ70tm9rZ4+rVm9rYDrWu6O0hd/YOZrYnr48dm1hqXLzKzsZJ97Msl85wX//+ui+vTqrA5FXWQuprw/93x8Ft5kLr6Xkk9bTSzlXH58b5fHSxXmB7fWe6u1yFeRA85WQ+cAKSBx4Gl1Y6rynUyGzg3Hm4CngWWAp8APnCA6ZfG9VYDLI7rM1Ht7TiK9bUR6Nyv7O+Bm+Lhm4C/i4evBn4GGHAh8GC1469SnSWA7cBC7Vf7bPPLgHOB1Ue6LwHtwIb4b1s83FbtbTtKdfVKIBkP/11JXS0qnW6/5TwU15/F9XlVtbftKNXVhP7vjpffygPV1X7j/xH4mParQ+YK0+I7Sy3Ih3cBsM7dN7h7DvgucG2VY6oqd9/m7o/Gw0PA08DcQ8xyLfBdd8+6+3PAOqJ6PZ5dC3w9Hv468NqS8m945AGg1cxmVyG+arsMWO/uh3pq5nG3X7n7L4meOlpqovvSFcBd7t7n7ruBu4ArKx78UXagunL3O929EL99AJh3qGXE9dXs7g949Ev9DfbW7zHjIPvVwRzs/+64+K08VF3FrcDXAbceahnH0X51sFxhWnxnKUE+vLnA5pL33Rw6GTyumNkiokeFPxgX/Wl8auSW8dMmqA4duNPMHjGzG+Kyme6+LR7eDsyMh4/3uhr3Jvb9kdF+dXAT3ZdUb5F3ErVWjVtsZo+Z2X1mdklcNpeofsYdb3U1kf877VdwCbDD3deWlGm/4gW5wrT4zlKCLEfMzBqBHwHvc/dB4EvAicAyYBvRqSaBl7r7ucBVwHvM7GWlI+MWBN1vMWZmaeAa4AdxkfarMmlfKo+ZfRgoAN+Oi7YBC9z9HOAvgO+YWXO14psi9H83cW9m3wN77VccMFfYYyp/ZylBPrwtwPyS9/PisuOamaWIdvhvu/u/A7j7DncvunsIfJW9p7uP6zp09y3x353Aj4nqZcd414n478548uO6rmJXAY+6+w7QflWGie5Lx3W9mdnbgVcDvx//OBN3F+iNhx8h6kt7MlG9lHbDOG7q6gj+7473/SoJ/C7wvfEy7VcHzhWYJt9ZSpAP72FgiZktjlu23gTcVuWYqiruZ/VvwNPu/pmS8tK+sq8Dxq/yvQ14k5nVmNliYAnRBQrHPDNrMLOm8WGii4RWE9XJ+JW4bwN+Gg/fBvxBfDXvhcBAyamo48U+rTDarw5rovvSz4FXmllbfNr8lXHZMc/MrgT+ErjG3UdLyrvMLBEPn0C0L22I62vQzC6Mv/f+gL31e0w7gv+74/238hXAGnff03XieN+vDpYrMF2+syp9FeCx8CK6svJZoqO/D1c7nmq/gJcSnRJZBayMX1cD3wSeiMtvA2aXzPPhuP6e4Ri8WvcQdXUC0dXcjwNPju8/QAfwC2AtcDfQHpcb8IW4rp4Alld7G45yfTUAvUBLSZn2q73beyvRads8UT+8PzySfYmo/+26+PWOam/XUayrdUR9Gce/t74cT/v6+P9zJfAo8JqS5SwnSg7XA58nfgLtsfQ6SF1N+P/uePitPFBdxeVfA/54v2mP9/3qYLnCtPjO0qOmRURERERKqIuFiIiIiEgJJcgiIiIiIiWUIIuIiIiIlFCCLCIiIiJSQgmyiIiIiEgJJcgiIschM7vUzP6z2nGIiExFSpBFREREREooQRYRmcLM7Hoze8jMVprZV8wsYWbDZvZPZvakmf3CzLriaZeZ2QNmtsrMfhw/dQozO8nM7jazx83sUTM7MV58o5n90MzWmNm34ydfiYgc95Qgi4hMUWZ2GvBG4GJ3XwYUgd8neuLgCnc/HbgP+Hg8yzeAD7r7WURPohov/zbwBXc/G/gtoieBAZwDvA9YSvTUx4srvEkiItNCstoBiIjIQV0GnAc8HDfu1gE7gRD4XjzNt4B/N7MWoNXd74vLvw78wMyagLnu/mMAd88AxMt7yN274/crgUXAryu+VSIiU5wSZBGRqcuAr7v7h/YpNPvoftP5ES4/WzJcRL8JIiKAuliIiExlvwDeYGYzAMys3cwWEn13vyGe5i3Ar919ANhtZpfE5W8F7nP3IaDbzF4bL6PGzOqP5kaIiEw3ai0QEZmi3P0pM/sIcKeZBUAeeA8wAlwQj9tJ1E8Z4G3Al+MEeAPwjrj8rcBXzOxT8TJ+7yhuhojItGPuR3pmTkREqsHMht29sdpxiIgcq9TFQkRERESkhFqQRURERERKqAVZRERERKSEEmQRERERkRJKkEVERERESihBFhEREREpoQRZRERERKTE/w+WNkpBwNXYhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(train_acc_all)\n",
    "plt.plot(test_acc_all)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(train_loss_all)\n",
    "plt.plot(test_loss_all)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train'], loc='upper right')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxJd53qfacf1",
    "outputId": "a5847be6-2677-4870-e126-16e4c3e8b29f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.2, inplace=False)\n",
       "  (7): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Dropout(p=0.2, inplace=False)\n",
       "  (10): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(mlp, \"mlp.pkl\")\n",
    "net_load = torch.load(\"mlp.pkl\")\n",
    "net_load.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dimTswRtaj7K"
   },
   "outputs": [],
   "source": [
    "for X,y in test_loader:\n",
    "    break\n",
    "y_hat = net_load(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvJwEfbDarRc",
    "outputId": "61236820-2e87-4e91-d798-f8c17cbba187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0].reshape(-1,10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvSWq0viausN",
    "outputId": "e2d9961e-6104-4f1e-8163-378f64f4f85b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9989, 1.0000, 1.0000, 0.9661, 0.9999, 0.9966, 0.9999, 0.6256, 1.0000,\n",
       "         0.9995], grad_fn=<MaxBackward0>),\n",
       " tensor([6, 9, 6, 7, 2, 1, 8, 5, 9, 9]),\n",
       " tensor([6, 9, 6, 7, 2, 1, 8, 3, 9, 9]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score,pred = torch.max(torch.softmax(y_hat[:10],dim = 1), 1)\n",
    "score,pred,y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "V7ZFnxn8ax7c",
    "outputId": "c1a9e70a-5e91-4fdc-ae70-96e4a9d8fae9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAGbCAYAAACGfpQKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAA100lEQVR4nO3dedxW094/8M9X85wG0UCSEOeQ01OUoUNKIkl0MnYcEcl5HEOmn6JBTo78Dh6c6CRTA1FKesTJ0CCiE44ozaWUSvP8ff7Y+972Wu5rHtY1fN6vV6/W9157WNd1r/v6XnuvvfcSVQUREZErh7huABERFTcmIiIicoqJiIiInGIiIiIip5iIiIjIKSYiIiJyymkiEpHRIjLYL58pIt9mab8qIk2zsa90EZGBIvKS63bkEvaf+LH/mNh34peNvhMzEYnIchHZJSLbRWS9/wusmu6GqOpHqnpcHO3pJSIfp3v/1j7ai8jnIrJDRFaLyOVxrPOM/x5tF5G9IrIvFE9LcP/tRGR18q8g2M6fRWSZ/zq+EZFmqW4ziTYUVf8RkQYiMklENvl9p0+c6+VU/xGRNiIyT0S2ichCETkjle0l2Yai6jv+PorysyfeI6KLVLUqgFMBtARwfyk7Lpt4c3OPiDQH8AqA+wDUAHAygPmx1lPVPqpa1X+fhgIYVxKraqfQ9rPyPonI9QD+BKAzgKoALgSwMRv7LkXR9B8ALwFYBqAevPd+qIj8PtZKudR/RKQWgLcADAdQE8BfAbwlIodmet+lKJq+U8yfPQmdmlPVNQCmATjJ36GKSF8RWQxgsf+zC0VkgYhsEZHZIvLbUANb+Nl+m4iMA1AxVGdkYhFpJCITRWSDiPwkIk+KyAkAngFwup/tt/jLVhCRR0Vkpf/N6RkRqRTa1p0i8oOIrBWR62K8zPsBPKuq01R1v6r+pKrfJ/I+2fxvdv1FZCGAHSJSVqxDdP/b3mARqQLvPa4f+lZT31+svIiM8d+/r0WkZYT9HQJgAIDbVPU/6vleVTel8jpSVej9x/+23g7AEFXdp6r/BvAagFh9Lqps9x8AbQCsU9UJqnpAVV8CsAFAt1ReRyoKve/4ivazJ6FEJCKNAFwA4IvQj7sCaA2guYi0ADAKwI0AagN4FsBk/5dVHsCbAF4EUAvABACXRthPGQBTAKwA0BhAAwBjVfUbAH0AzPGzfU1/lWEAmgE4BUBTf/kH/G2dD+AOAOcBOBZA+xgv8zR/vS/9DvSSeN8QU9UT3jeEmqq6P9JCqroDQCcAa0Pfatb61V0AjIX3LXUygCcjbKah/+8kEVkl3iHyg34ncaYI+o9Y/5eUT4qyTryy2X9K2m3H6XgdSSmCvgMU82ePqkb9B2A5gO0AtsD75fwPgEp+nQI4J7Ts0wAGWet/C+BsAGcBWAtAQnWzAQz2y+0ArPbLp8P7Bla2lPb0AvBxKBYAOwAcE/rZ6QCW+eVRAIaF6pr57W4a4fXu9V9zM3iHla8DeDnW+2RtYyCAl6z38DprGaMNAEaX9l5Y25wRipsD2BVh/2387U+F13EaA/gOQO9EXkc6/hVh//kYwBPwvnGfCmATgG/zrP/U9n9fPQGUA3AtgIPwvq2z72Su7xTtZ0+85wy7quqMCHWrQuWjAFwrIv1CPysPoL7fuDXqt9a3IsI2GwFYoVGyd0hdAJUBzBcJvsQJgDJ+uT7M86yR9lliF4B/qup3ACAiQwFEeu2JWBV7kZjWhco7AVQUkbKlvE+7/P//qqpbAGwRkWfhfaMcmYZ2JKqY+s+VAJ6C97qWwhszOjGOdsSStf6jqj+JyMUAHoX3WqbD+xtIeRA7CcXUd4r2sycdp2rCv9xV8M6P1wz9q6yqrwL4AUADCf3GABwZYZurABwppQ+u2Y8L3wjvxZ8Y2mcN9Qbu4O+3URz7LLHQ2ke6Hk9ub2cnvE5c4vA07vNbeN+uMvE60q2g+o+qrlDVC1W1rqq2BlAHwLxo68Qpm/0HqvqBqv6XqtYCcDWA45Ge15FOBdV3UMSfPekeMxgJoI+ItBZPFRHpLCLVAMwBsB/ArSJSTkS6AWgVYTvz4P0Sh/nbqCgibf269QAa+ud9oaoH/f2OEJHDgOAS2o7+8uMB9BKR5iJSGd5AWjT/BPBHEWniL383vHPG8Le9XER6JfKmRLAAwBUiUsY/l3x2qG49gNoiUiOZDavqTgDjANwlItVEpCGAGxB6HTkq7/uPiJzgv+flReQqAB0APBaqz/n+AwSD++VEpDq8I6NVqjo9pRZnVt73HRTxZ09aE5GqfgagN7yBrM0AlsA7rwpV3Qvvqpte8M6b9wAwMcJ2DgC4CN7g30p4pwR6+NXvA/gawDoRKbkksL+/r7kishXe4exx/ramAXjcX2+J/3+01zAKwBgAn8A7lN4D4FYA8DtgbQBz43g7Yvmz/xq3wDud82aoDYsAvApgqXhXANUvbQMx3ALv/PpaeH+Ir8A7Z52zCqH/AOgI75TcZniD2+er6gYg7/rPXfC+8a8CcASAS1Jsb0YVQt8p5s8eMU+bUjTi3dTXV1V7um4L5R/2H0pWofcdJiIiInKKDz0lIiKnmIiIiMgpJiIiInKKiYiIiJxK6mmsIsIrHPLDRlWt67oRNvaf/KCq9vPmnGPfyQ+J9h0eERW2WI8UISJyjomIiIicYiIiIiKnmIiIiMgpJiIiInKKiYiIiJxK6vJtIiKKT9265h0U3333nRGPHTvWiG+66aaMtynX8IiIiIicYiIiIiKn8urU3OOPP27Et956qxEPHz7ciPv375/pJhERRdWrVy8jrlHDnPx03rxcm4E9+3hERERETjERERGRU0xERETkVE6PEfXsaU7P3rdvXyO2pzl/5513Mt4mIqJEHHnkka6bkPN4RERERE4xERERkVNMRERE5FROjxG1atXKiA85xMybH3/8sRHPnj07420iIoqlQoUKQfniiy826nbt2mXE9iN/ihGPiIiIyCkmIiIicoqJiIiInMrpMaLu3btHrf/888+NeM+ePZlsDhW4ypUrG/Gzzz4blK+88sqo6w4bNsyIp0+fbsQffPBBiq2jfNKtW7eg3LBhQ6PuvvvuM+JZs2ZlpU25jEdERETkFBMRERE5ldOn5mJ5+eWXXTeB8ljz5s2N+F//+pcR16lTJyjbj5Oy3X333Ubcr18/I+7atWtQfu+99xJpJuWhNm3aRKxbuXJlFluSH3hERERETjERERGRU0xERETkVM6NEYXPpYfP0ROlqlKlSkb8l7/8xYjt/rZ169ag/Pbbbxt17777rhGPGjXKiO1LwUeOHBmU27VrZ9RxzCD/1atXz4jDU9jMnz/fqBs3blxW2pRPeEREREROMREREZFTTERERORUzo0RhR+HUb58eaNu27ZtRrx79+6stCmWatWqGfGQIUOM2H7ER9imTZuM+Prrr09fw8hg/17++Mc/Rl3+6quvDspTpkyJuuyOHTuMuFOnTkZ87bXXBuUvvvjCqLvhhhuM2H480Pbt26Pum9w7/vjjjbhWrVpBecSIEUbd/v37s9KmfMIjIiIicoqJiIiInGIiIiIip3JujCga+xldX331lZN22PeIPPfcc0Yca/qKsHXr1hlx1apVjZjjA+ljn8e3ffTRR0b8/vvvx73tCRMmGPHkyZON+MCBA0H5uuuuM+rGjx9vxE899ZQR33rrrXG3g9w488wzI9blylh2LuMREREROcVERERETjERERGRU3k1RpQrxowZY8SXXHKJEYfHAwBg586dQdl+3tnhhx9uxOH7TYBfjxdQ/Jo1a2bErVq1irr8o48+asTh31uqRCTuZWfPnp22/VJ2XHzxxRHrPv300yy2JD/xiIiIiJxiIiIiIqd4ai5Op512WlA+77zzoi47c+ZMI+7QoUNQnjhxolEX7ZCeUrN69Woj/uabb4zYns45/HsCYj/WJ5o777zTiGM9TijMbjflnpYtWxpx06ZNjXjz5s1B2e536WSf8q1YsWLEZffs2WPEBw8ezEibksEjIiIicoqJiIiInGIiIiIip3JujGjo0KFB2T7/mcglsOl2++23B2V72ofvvvvOiO1HuITZr+GQQ/hdIFPsy6/taURs9qXzf/vb34LyihUroq57xx13GLE9DTkVFnu69xo1ahhxeCx4w4YNKe2revXqQfnKK6806i699FIjPueccyJu58MPPzTi/v37G/Enn3ySbBNTxk9BIiJyiomIiIicYiIiIiKncm6MKPx4E/t+HVXNWjvs+wQ6d+4csR2XX365EUe7D2TOnDlG3KVLl2SbSAmyH7XSsWNHI7an4AhP7/HWW29F3faAAQOi1r/44otBOTwFORUmezr4RJx44olGHJ6OpG7duklv96yzzjJi+zOOY0RERFS0mIiIiMgpJiIiInIq58aIwo/ib9u2rVF3/vnnG/Epp5xixAsWLEhbO+zxqQoVKkRc1n6GUzTNmzdPuk2UmoceesiI7Sk5wveKAeY9GdHuzwB+fY+GPWa0du3aoMwxIgqzxypHjx5txOFxoVWrVhl1/fr1M+L27dsb8S233BJxv1OnTk2kmRnFIyIiInKKiYiIiJxiIiIiIqdyboxoxowZQXnLli1GXf369Y3YnvPFfg5TpkyaNMmIly1bFnX5WrVqBeXjjjvOqFu/fr0Rv/LKKym2jiKxp3C/6667jHjUqFFGbE8BHxZ+Dh0A7N27N+q+w9u2ny+4fPlyI471XDvKfe+9917EuipVqhixPZ5Yr149I541a1ZQDt/PCPz6eYr//d//HXG/b775phH/8MMPEZfNNh4RERGRU0xERETkVM6dmgs/LifW4yxSedxFLDfffHPEumHDhhmxfVqmZ8+eRnzvvfcG5caNGxt19uWX4SmGKbsWLVpkxA8//HDath1+LJQ9RfPKlSuN2L5El/JPq1atgvLcuXONuvvvv9+ITzvtNCN+/PHHjXjgwIFBeevWrUad/VlkT08RnqLGnpokkdtOMo1HRERE5BQTEREROcVERERETuXcGFF4Ggj7XOqDDz5oxKeeeqoRv/vuu0b88ssvB+UpU6YYdRs3bozajgYNGhhx+Bx/7dq1jbrw+WDAHBMCzMf62G20H+dBhaFsWfNPKzzdMxW+8CPC/vGPfxh19nQjNvt2kO3btwfle+65x6izx5h3795txH/4wx+Csn2bQC7hERERETnFRERERE4xERERkVOSzPTbIpK9ObtD7Oma7UfzV6xYMeK6n3/+uRHHulfDfryLfe9HNPZjN8KP6PjjH/9o1GX4MRvzVbVl7MWyy1X/yaYjjjjCiKNNH29PP2HfR+KKqorrNthype/Y9wOGH00GAE2aNAnK9u/z+++/N+InnnjCiD/66CMjDo8ptWjRwqiz+5XdlyZMmAAXEu07PCIiIiKnmIiIiMgpJiIiInIqr8aIbLfeeqsR33HHHUYcvt8n2vhRaexH9UcbI7Kv7f/iiy+M2L53KIs4RuRIImNE9qP933nnnYy0KVEcI4rf9ddfb8T2vUNhO3bsMGJ7WgibyC+/Bvu5hJdeeqkRf/bZZ1G3lS0cIyIiorzCRERERE7l3CN+EvH3v/89atypU6egHL6cMhnDhw8PyhUqVIi6rMNTcUTkgD27b506dYJyly5doq5rP05szZo1Rhy+BPvJJ5806vbt25dQO3MVj4iIiMgpJiIiInKKiYiIiJzK6zGiWKZNm5a2bZUvXz4oDxgwwKhr3bp12vZDRPnHvr0jPIW3PZ03/RqPiIiIyCkmIiIicoqJiIiInMrrR/xQTHzEjyOJPOLHnlr+kUceyUibEsVH/FCy+IgfIiLKK0xERETkFBMRERE5VdD3ERHlgwsuuMCIc2WMiChbeEREREROMREREZFTTEREROQUx4iIMmD79u1GPHTo0KDctm1bo65fv35ZaRNRruIREREROcVERERETvERP4WNj/ihpPERP5QsPuKHiIjyChMRERE5xUREREROMREREZFTTEREROQUExERETnFRERERE4l9Yif3/3ud/jss8/S3RZKM5Gcuw0EAPtPPhCR+a7bUBr2ndyXTN9J9obWDQBWJLwiZdtRqlrXdSNs7D95gX2HkpVw30kqEREREaULx4iIiMgpJiIiInKKiYiIiJxiIiIiIqeYiIiIyCkmIiIicoqJiIiInGIiIiIip5iIiIjIKSYiIiJyiomIiIicYiIiIiKnnCYiERktIoP98pki8m2W9qsi0jQb+0oXERkoIi+5bkcuYf+JH/uPiX0nftnoOzETkYgsF5FdIrJdRNb7v8Cq6W6Iqn6kqsfF0Z5eIvJxuvcf2v7X/mst+bdfRN6KY71nQuvsFZF9oXhagm1oJyKrU3gNR1qvYbv/B3B7sttMoS3F1n8eFZHFIrJNRBaJyDVxrpdL/ecwEXlVRNaKyM8iMktEWie7vRTaUWx953IRmS0iO0VkZgLr5Uzf8bcxSES+9D87B8azTrxHRBepalUApwJoCeD+Unae1CR7uUZVT1TVqv7rrQZgFYAJcazXJ7TeUADjSmJV7VSyXDbeJ1VdGdp3VQC/AXAQwOuZ3ncERdN/AOwAcBGAGgCuBfD/RaRNrJVyqf8AqArgUwC/A1ALwAsApmYiCcShmPrOJgCPAxiWyEo51ncAYAmAuwBMjXeFhE7NqeoaANMAnAQEh5l9RWQxgMX+zy4UkQUissXP7r8tWV9EWojI5/63xXEAKobqjEwsIo1EZKKIbBCRn0TkSRE5AcAzAE73s/0Wf9kK/jfRlf43p2dEpFJoW3eKyA/+N7zrEnjJZwGogxQ/wP1vdv1FZCGAHSJSVqxDdP/b3mARqQLvPa4f+lZT31+svIiM8d+/r0WkZZxNuAbAh6q6PJXXkapi6D+qOkBVF6nqQVX9BMBHAE5P5X3Ldv9R1aWq+piq/qCqB1T1HwDKA4h51JApRdJ3ZqjqeABrU3/Hgv1n/bNHVV9Q1WkAtsXbzoQSkYg0AnABgC9CP+4KoDWA5iLSAsAoADcCqA3gWQCT/V9WeQBvAngR3resCQAujbCfMgCmwJuJsTGABgDGquo3APoAmONn+5r+KsMANANwCoCm/vIP+Ns6H8AdAM4DcCyA9gm85GsBvK6qOxJYJ5KeADoDqKmq+yMt5O+rE4C1oW81JR2zC4CxAGoCmAzgyVg7FRGBl4heSK35qSu2/uN/IP0XgK/jXScKJ/0HAETkFHiJaEnSrU9RsfWdNHPWd+IVbyJ60/8G8DGAD+Ad/pV4WFU3qeouADcAeFZVP/G/Sb0AYA+A0/x/5QA8rqr7VPU1eIf/pWkFoD6AO1V1h6ruVtVSz836H7Q3ALjNb8c2v31/8Be5HMA/VfUr/40eGM8LFpHKALoDGB3P8nH4u6qu8t+nZH2sqm+r6gF4f1Qnx7HOGQDqAXgthf2mquj6j+8ZAP8GMD2BdSJx0n9EpLq/7IOq+nMK+05WsfaddHL12RO3eM8ZdlXVGRHqVoXKRwG4VkT6hX5WHt4vVgGsUTXmJo8093wjACuiZe+QugAqA5jv9QsAgAAo45frA5gfxz5t3eCds/0gzuVjWRV7kZjWhco7AVQUkbIx3qeSo7rtadh/soqu/4jIcHinkX5vtTlZWe8//hHdWwDmqurDadh/Moqu72SAq8+euKXj8u3wL3cVgCGqWjP0r7KqvgrgBwANJPQbA3BkhG2uAnCklD64Zv9RbwSwC8CJoX3WUG/gDv5+G8WxT9u1AMak6UME+HW7d8LrxCUOj7JsUvwPksuQA6floii4/iMiD8I7xdFBVbfGWj5OWe0/IlIB3ums1fBOd+Wigus7GZL1z55Epfs+opEA+ohIa/FUEZHOIlINwBwA+wHcKiLlRKQbvMPg0syD90sc5m+jooi09evWA2jon/eFqh709ztCRA4DABFpICId/eXHA+glIs39020DYr0IEWkI4Pco5QPcH/zrFc+bEcMCAFeISBn/XPLZobr1AGqLSI0U93EJgM0A/pXidrIl7/uPiNwD4AoA7VX1p1Lqc77/iEg5eKdydwG41n+Pcl0h9J0yIlIR3pmqQ/x9lwvV53zfAbz+47+OQwCU9V9HmWjrpDURqepnAHrDG8jaDG9ws5dftxfe6a5e8E559QAwMcJ2DsC7BLYpgJXwvpX18Kvfhzf4u05ENvo/6+/va66IbAUwA/4VPupdvfG4v94S//9YroY3KPl9+Id+B6wNYG4c24jlz/Be4xYAV8L79gm/zYsAvApgqXhXANUvbQNxuBbAi2k8qsuoAuk/Q+F9810iv1x5dC+QV/2nDYALAXQAsCX0Os5MQ7szokD6ztXwkv/TAM70yyOBvOo7gNfmXfAukrjPL18dbQXJk8+onCAiZwDoq6o9XbeF8g/7DyWr0PsOExERETnFh54SEZFTTEREROQUExERETnFRERERE4l9TRWEeEVDvlho6rWdd0IG/tPflBVib1UdrHv5IdE+w6PiAqbq0eKEBHFjYmIiIicYiIiIiKnmIiIiMgpJiIiInKKiYiIiJxiIiIiIqeYiIiIyCkmIiIiciqpJysQFbumTZsa8W233WbEN910U8R1p0yZYsS9e/c24vXr16fYOipUHTt2NOJ33nnHiJ999lkj7tOnT8bblA48IiIiIqeYiIiIyCkmIiIicopjREQRlC37y5/HgAEDjLpbbrnFiKtXr27EqpEfEt25c2cjts/z2/Vr166N3VgqWPXr1w/Kb7zxhlFn97NPPvkkK21KNx4RERGRU0xERETkFBMRERE5xTEioghuvPHGoHzvvfcadSLmBJSxztW3aNEiKJcvX96oO/nkk424X79+RnzPPffE2WIqRIcc8svxQsWKFY26xYsXG/HYsWOz0qZ04xERERE5xUREREROMREREZFTHCMiiqBRo0ZxLztmzBgjDo8vAUDXrl2D8vPPP2/UValSJfHGUdGI9tzCcePGGfGuXbsy3ZyM4BERERE5xURERERO5fWpucaNGxvxYYcdZsS9evWKuG67du2M+IQTTjBi+3LcJUuWBOUZM2YYdfYlkx9++GHE/VL+sB+1E03Pnj2NeMWKFUY8bNiwoLxgwQKjrm3btok3jgpWhQoVjPg3v/lNUN63b59Rl6+Xa9t4RERERE4xERERkVNMRERE5FRejRHZ59InTZpkxIceemjS2z548GDU+mOOOabUMgBcfvnlRnz88ccb8caNG5NuF7kzevTooDx8+HCjzn7Ej/3Ynr59+xrxiBEjIu7H3pYdU3EJPw4KAC688MKgvGfPHqPuP//5T1balGk8IiIiIqeYiIiIyCkmIiIiciqvxog6duxoxImMCa1cudKI//d//9eIFy1aFHXbPXr0CMpNmjSJuuzNN99sxA899FDc7aTc8cQTTwRlewyxW7duRmyfu7///vuNODzteIMGDYw6+561aNOMU+EbNGiQ6yZkHY+IiIjIKSYiIiJyiomIiIicyqsxokQNHTo0KIef9QUAO3bsSGhbDzzwQFDevHmzUVe9enUjLlOmTELbpty0d+/eoGzfBxTtvqDSdOjQISgfddRRqTWMCkr79u2N+Jxzzom4bKFOG88jIiIicoqJiIiInGIiIiIipwpqjGjr1q1GPHjw4KBs3+dBlE329OBh9njlnDlzMt0cyiGxnjUY7h/ffPNNVtqUbTwiIiIip5iIiIjIqYI6NWc/GoWn4yhX2NM/h40fP96IJ0+enOnmUB6ZN29eUJ4+fbrDlmQOj4iIiMgpJiIiInKKiYiIiJwqqDEi+zz83XffHZTHjBlj1K1duzahbXfp0iUoV6tWLeqyCxYsSGjbVHhuuOEGI65Tp07EZd94441MN4dymN1XbM8991yWWuIOj4iIiMgpJiIiInKKiYiIiJwqqDGiihUrGvGQIUMiLmtPCxFLlSpVgrL9CA7b3LlzE9o25b8jjjjCiIcPH27E4XvcPv30U6NuypQpmWsY5ZxOnToZ8bnnnmvE+/btM+KdO3dmvE2u8YiIiIicYiIiIiKnmIiIiMipvBojOnjwoBHbz5azx25WrVoVlEePHp3Svk866aSIdf/617+MeMOGDSnti3Jf7dq1jTg8LT0AVK1aNeK6f/nLXzLSJspNZ599thHbzxYMjz8DwGeffWbEkyZNykzDcgiPiIiIyCkmIiIicoqJiIiInMqrMaKBAwca8axZs4y4YcOGRvzBBx8E5XXr1iW0r0qVKhnx+eefH3FZ+z6Q/fv3J7Qvyg01a9aMWLdlyxYjvuWWW4z4mmuuibrtxYsXB+UVK1Yk3DbKX7fffrsR22NCS5cuNeKePXtmvE25hkdERETkFBMRERE5lVen5mzvvvtuxrZ99NFHG/Epp5wScdlFixZlrB2UvGbNmhnx888/H3X5ww47LGLdjz/+aMRt27Y1YvtWAlvXrl2D8po1a6IuS/mvVatWQdl+pI/t+++/jxoXAx4RERGRU0xERETkFBMRERE5lddjRES2++67LygPGjTIqLMfARVrXCfs2GOPjbqtRNo1ceJEo2727NlGvH79+oS2TbnnoosuCsplypQx6sKPHgOAe+65JyttymU8IiIiIqeYiIiIyCkmIiIickoSOU8erCSS+Ep5xj5vO3jw4KBsn8O3p4jYtGlT5hqWmPmq2tJ1I2yZ7D/h+33sqRrscZ2RI0cacbt27Yy4adOmEfeTyniTze5Pjz32mBE/+uijSW87Faqa2EBYFuTqZ4/92J7wvYUNGjQw6tq0aWPEc+fONeImTZoYsf0IoHyQaN/hERERETnFRERERE4xERERkVO8jyiC8LPBbE8//bQR59CYUNFbuXJlULbHiGz2dB3Rpve2TZ8+3YhHjRplxPaj/MPPGytfvrxRd/jhhxtxjx49jNjVGBHFr3fv3kZsjwuF2fe37d6924grVKhgxB06dEixdbmPR0REROQUExERETnFU3MRRJv2Ye/evdlrCCVk2LBhQXncuHFRl+3Tp0/c250xY4YRX3LJJUZsn16ZMGGCETdu3Dgo//Of/zTqWrY0r7D/6quv4m4XuWFPGZJIXzr33HONeN68eUY8dOjQ5BuWp3hERERETjERERGRU0xERETkFMeIqKBMnTo1KL/++utGXffu3aOuu2LFCiN+5JFHgvKrr75q1NljQrEsX748KP/+97836uxHRHGMKPfZ48SbN2+Oe90hQ4YY8RNPPGHE9rT0xYBHRERE5BQTEREROcVERERETnEaiAj27NljxGXL/jKcNnPmTKPOvi8ghxTdNBCUPpwGgpLFaSCIiCivMBEREZFTTEREROQU7yOKwL5v5Oqrrw7KRx99dLabQ0RUsHhERERETjERERGRU0xERETkFMeIIvj5558j1tWpU8eIf/vb3xrxwoULM9ImIqJCxCMiIiJyiomIiIic4qm5CEaOHGnE3bp1C8qvvfaaUbds2bKstImIqBDxiIiIiJxiIiIiIqeYiIiIyClOA1HYOA0EJY3TQFCyOA0EERHlFSYiIiJyiomIiIicSvY+oo0AVqSzIZQRR7luQATsP7mPfYeSlXDfSepiBSIionThqTkiInKKiYiIiJxiIiIiIqeYiIiIyCkmIiIicoqJiIiInGIiIiIip5iIiIjIKSYiIiJyiomIiIicYiIiIiKnmIiIiMgpJiIiInLKaSISkdEiMtgvnyki32ZpvyoiTbOxr3QRkV4i8rHrduQS9p/4hd8rYt9JhIgMFJGXMrmPmIlIRJaLyC4R2S4i6/1fYNV0N0RVP1LV4+JoT0Y/kEWkloiME5GfRGSjiLwsItXjWO9e/z3aLiK7ReRAKP46wTY09jtssvNFlWzjbRHZLCLrROTJVLaXQjuKrf+MFpG9od/9dhEpE8d600LL77O28UyCbUjpNYpIHRGZ5f8NbBGROSLSNtntpdCOYus7DURkkohsEpHVItInzvWeCfWVvX7/KYmnJdiGdiKyOrlXEGyjjYjME5FtIrJQRM6ItU68R0QXqWpVAKcCaAng/lJ2nvUPuQwZDOBQAEcDOAZAPQADY62kqkNVtar/PvUBMKckVtUTS5YTTzaORP8HwI8AjgBwCoCzAdychf2Wppj6DwD8NfS7r6qqB2KtoKqdQv3nZWsbwQdSlt6n7QCuA1AX3t/CIwDecvQ7Kqa+8xKAZfA+czoDGCoiv4+1kqr2CfWdoQDGhfpOp5LlsvE+iUgtAG8BGA6gJoC/wus7h0ZbL6EPRFVdA2AagJP8naqI9BWRxQAW+z+7UEQW+N+kZovIb0ONbCEin/uZchyAiqE6IxOLSCMRmSgiG/xvZk+KyAkAngFwup/tt/jLVhCRR0Vkpf/N6RkRqRTa1p0i8oOIrBWR62K8zKMBvKmqW1X1ZwBvADgxxjpRichMERkiIrMA7ATQxP+21z60TPjw90P//y3+6zw9tNyj/lHOMhHphMiOBjBeVXer6joA76T6OlJVJP0n7ez3SUo5Yvb72PWRXqPvUBGZ6r9/n4jIMaXtz+8z36rqQQAC4AC8hFQrYy8yhkLvO+Id6bUDMERV96nqvwG8Bu8LQdL8z5n+IrIQwA4RKSvW6UHxT1OKSBV473F9+eWIqr6/WHkRGeO/f1+LSMsIu2wDYJ2qTlDVA6r6EoANALpFa2dCiUhEGgG4AMAXoR93BdAaQHMRaQFgFIAbAdQG8CyAyf4vqzyANwG8CK9DTwBwaYT9lAEwBd6UwI0BNAAwVlW/gXm0UdNfZRiAZvC++Tf1l3/A39b5AO4AcB6AYwEEH/4RPAXgQhE5VLwsfim8X06qrgZwA4BqiD3V8Vn+/zX91znHj1sD+BZAHXjfNJ4XEYmwjccB/EFEKotIAwCd4CUjZ4qk/wDAzeKdXpkvIqW2MQld4b9P0RaK8hoB4A8AHoSXVJYAGBJtW/6H124AkwE8p6o/Jtv4VBVB3xHr/5LySVHWiVdPeEdYNVV1f6SFVHUHvM+JtaEjqrV+dRcAY+Ed5UwG8GSU/dmfSbFfh6pG/QdgObxD9S3wfjn/A6CSX6cAzgkt+zSAQdb638I7LXQWgLXwpyf362YDGOyX2wFY7ZdPh5dFy5bSnl4APg7FAmAHgGNCPzsdwDK/PArAsFBdM7/dTSO83voAZgA46P97F0D5WO9TjDbOBPBQKe9r+1A8EMBLfrmx38ay1jaXhOLK/jKHR2jDCQDmA9jvLzc6/N5n618R9p9T4X0QloX3wbkNQNsE37PRJa8rwvtUWv+YCeD60l5jaJvPheILACyKoy0V4X2QXcu+k/G+8zGAJ/z3/FQAmwB8m+B7NhD+50joPbzOWsZoQ7i/hd8La5szQnFzALsi7L+2//vqCaAcgGvhfY4+G63d8Z4z7KqqMyLUrQqVjwJwrYj0C/2sPLwPdwWwRv3W+iIdGTQCsEKjZO+QuvA+lOeHDg4EQMkAcX14H8ix9lliPICFAC72t/MovHO3l8fRlmhWxV4kpnUlBVXd6b/eXw3eijcG9Q6Af8A7VK4K74/iEQB3paEdiSqa/qOqn4fCt0XkZXinJWbF0ZZo0tp/4J0ijjnwr6q7AbwqIt+IyAL1ThllU9H0HQBXwjsjswrAUnifO+k4nZ6JvlNRRMra75Oq/iQiF8P73HwKwHR4X+yjXgCRjkHz8C93FbxznDVD/yqr6qsAfgDQwDqVdGSEba4CcKSUPrimVrwRwC4AJ4b2WUO9gTv4+20Uxz5LnAIve+9Q1e3wzgtfEGOdeNjt3gGvE5c4PMqyiaoF73U+qap7VPUnAP9Eel5HuhVa/yltf5FOnya6nRI7/P8z1X9KUw5AkwxsNxUF1XdUdYWqXqiqdVW1NbxT8POirRMnu907kcG+o6ofqOp/qWoteEMSxyPG60j31VsjAfQRkdbiqSIinUWkGoA58E4T3Soi5USkG4BWEbYzD94vcZi/jYryy+Wj6wE09M/7Qr0B1ZEARojIYUBwGWRHf/nxAHqJSHMRqQxgQIzX8CmA60Wkkj/oeAO8IyT4254pIgMTeVMiWABvDKecP/DXPVS3Ad7hbFJ/+Kq6Ed7VNzf5g5M14R0iL4y6ont5339EpLuIVBWRQ0SkA4Cr4J1TL6lXEWmX4PtiUNUNANYAuEpEyviD4OELD4zXmCgROU1EzhCR8v7fQX94V3J9kkq7M6wQ+s4JIlLNf9+vAtABwGOh+uUi0ivRN6YUCwBc4fed8+GdviyxHkBtEamR7MbFuzCknHi3vTwKYJWqTo+2TloTkap+BqA3vIGszfAGRHv5dXvhnaLoBe/cZw8AEyNs5wCAi+AN/q2Ed1jXw69+H8DXANaJyEb/Z/39fc0Vka3wDgWP87c1Dd7A/fv+Mu/HeBnXwTsHvxreH3sTeB/iJRoh9dMsAPD/4H14bIY3gPxKSYWq7oQ3kDxLvCuATkti+90AnA8vqS0BsA/Abak2OpMKpP/8GV6/2QLvEtbeqjoTCAbctwH4MsY24tEbwJ0AfoJ3+mZ2qK6015iICvBOq/wE77VcAKCz/jJwnXMKpO90hHdKbjO8CyPO9790wE9+tQHMjflmxPZneK9xC7zTgW+WVKjqIgCvAljqf/bUL20DMdwF72hxFbzbRy6JtYKYp00pGhFpCO+S6Dau20L5x/+We6Kq3uO6LZRfxLsptK+q9nTdlkxgIiIiIqf40FMiInKKiYiIiJxiIiIiIqeYiIiIyKmknsYqIrzCIT9sVNW6rhthY//JD6qajhtx04p9Jz8k2nd4RFTYYj1ShIjIOSYiIiJyiomIiIicYiIiIiKnmIiIiMgpJiIiInKKiYiIiJxiIiIiIqeYiIiIyCkmIiIicoqJiIiInGIiIiIip5iIiIjIqaSevp2PqlWrZsQNGjQw4t69e0dd/9RTTw3K7dq1M+reeustIx43blzE7bz88stR90NEVGx4RERERE4xERERkVNMRERE5JSoJj7hYa7OktisWTMjvvnmm4PyWWedZdSdfPLJRpzI+yBiTj6YyLply2Z1WG6+qrbM5g7jkUr/ueeee6LWf/XVV0HZHrujxHCGVkoWZ2glIqK8wkREREROMREREZFTeT1GVK9ePSP+8ssvjbhWrVoR1401zrN69Wojnjt3blC+7LLLElr3p59+Csq/+93vIrYpAwpujOjgwYNGbL/3+/fvD8q7d+9OdjcJs/vTgAEDjHjfvn0R1+3QoYMRv/jii0Y8YcKEFFuXHI4RRVauXDkj7t69uxGfe+65Edc988wzjXjXrl1G3L9/fyOePn16Mk10imNERESUV5iIiIjIqbw+NdeoUSMjXrZsWdzrfvjhh0Y8aNAgI164cKERh0+vNWzYMOq27UPtvXv3BuVt27bF3cY0KLpTc66kckm/bd68eUZ8+umnJ72tVPDU3C/sU3EdO3Y04kmTJsW9rVh9Zfv27Ub8n//8JyjbpwDXrFkT936ziafmiIgorzARERGRU0xERETkVEFNA2Gfe43mnHPOSXo/9uXZlD3hxzYBwHnnnRf3unXr1jXitm3bpqVNVPhatWplxImMCSWqatWqEff9yiuvGHXXXHONEa9YsSJj7cokHhEREZFTTEREROQUExERETmV1/cRVa5c2YjtR2FEu//ipptuMuKRI0emr2G5o+DuI0pF+/btjTidj05ZuXKlES9evDjisl9//bURh+9RA4CJEycacfg+kmwq5vuIWrY0/2w6d+5sxA888EDU9X/88ceIy4brgF/fG3TFFVfE3c6lS5cacZs2bYx4w4YNcW8rnXgfERER5RUmIiIicoqJiIiInMrrMSKbPVV4+PH5J554olFnP5Z/zJgxRnzjjTemuXVOcIwopFevXkb8/PPPx73ugQMHjHjo0KFGbE/d8P333yfWuBxUzGNEr7/+uhFfcsklRmx/btr374THI+1xHFudOnWMeP369XG307538vbbbzfiESNGxL2tdOIYERER5RUmIiIicoqJiIiInCqoZ8199913Rhyec8geIypfvrwR2/eYHHHEEUb8ww8/BOVq1aoZdW+88YYRH3vssRHbeNRRR0Wso/Syf0+33XZbQutv2rQpKNvjS1OnTk26XZSbrr/++qBsjwnZYzEbN2404iZNmiS93/D09gCwefNmI65Vq1bEde121atXL+l2uMQjIiIicoqJiIiInCqoU3O2fv36BeWaNWsadVdeeaURN27c2IijTfVgHw7b0/UOGzbMiJcvXx6jpZQJZ5xxhhEfd9xxCa1fsWLFoHz55ZcbdXY8c+ZMI37hhReM2J7inHJPt27dgrJ9ebb9eXDXXXelbb/250l4GAAADj300Li3ZX+uPffcc0F5yZIlSbQuO3hERERETjERERGRU0xERETkVEGPEYXZ513tc8DJPOqohH3Z+NixY43Yfsw/Zce0adOMePDgwUb84IMPRl0/PM3IVVddFXXZq6++2ohbt25txOFHSj3++ONGnf2o/p07dxqxfXkvpYd9i4Y9hUKY/Qgf+288FQ899JARN2/ePOlt1a9fP+K2OEZEREQUARMRERE5xUREREROFfQY0bnnnhuUb7nllrRt157q176nhGNCuemll14yYnvsxb4HI5Vz9b17945Yd/PNN0dd1x5/GDJkSFB2NW14IWrVqpUR24+ESkWFChWCsn0f0MMPP2zEdr8rRjwiIiIip5iIiIjIKSYiIiJyqqCmCrfPy4fPrduPUref75TI+2A/Wy6Hp3bgVOFpcvHFFxuxfZ+QfQ/KWWedlbZ9h/vq+PHjjbp58+YZ8d/+9re07bfQpwq3PxPC99nUqFHDqLOnfj/zzDON+IILLjDi8JQSRx99tFF3+OGHG3Eq9zDG+hwLT2cxefLkpPeTKE4VTkREeYWJiIiInGIiIiIip/L6PqKyZc3md+nSxYhr164dcd2tW7ca8auvvmrEixcvNuLwNNP2fQEnn3yyEf/73/+OuF/KT5MmTYoa21PPh+8jAcz5a0455RSjzh5fsIXP+3fv3t2ou/DCC414z549Rvzkk09G3XYxC08FDwAjR44MynfeeadRd+yxxxqx/ezKRNjjOjb7PsQ+ffoE5eeff96os8ey8hWPiIiIyCkmIiIiciqvL9+2p/+eM2eOEduH02H2ofeIESOi7uvss88Oyu+//75RN3v2bCP+05/+ZMT2NBFZxMu3c1ClSpWM2D7V27BhQyMOX7LdqFGjhPZVpkyZBFv3i0K/fNvWtGnToPzII48YdeHLoIHULrleunSpEQ8cONCI7Wnnd+/eHZQ//fRTo65x48ZR28XLt4mIiOLARERERE4xERERkVN5ffm2/UifaGNCsabztoWnkADMSzttb7/9thGncmknFb5du3ZFjZs0aWLE4f6U6BgRxS/8iJ9LL73UqLP//q+77rqo2/r666+Dsj1l/VNPPWXEK1eujLqt448/Pijn8OPEUsIjIiIicoqJiIiInGIiIiIip/J6jOj++++Pe9mpU6cacaxxHPsR8UceeWTEZe3HAW3bti3udlHmhB/FD/x6TDF8Hh+Ifd4/FWeccUZQrlixolF30003GbE9PpnIFNb2dAWUHvb07nfffXfU5Xfu3BmU7THATNqxY4cR58vU8jwiIiIip5iIiIjIKSYiIiJyKq/HiOxz59Ge/9SuXTsjvuqqq4zYfhR/jx49Im7LnkJi4cKF0ZpJWVSnTp2gfO+99xp19j0YzZo1M+IPP/zQiKOdX+/YsaMRh59FCPy6L4bHiOwpI1IRHosAgPPOOy9t26Zf7Nu3z4jtqRoyKdr9kTZ7PCp8b1Qu4xERERE5xURERERO5fWpOfv0R7RTcy1atDDiF154IeltPfbYY0bscJoHsoRPgR1xxBFRl61evboR27NfJuKQQ8zvdAcPHkx6W+HH/gPA8uXLg7J9Wnjw4MFGvGLFiqT3S7kp3Kft2V1jxfmCR0REROQUExERETnFRERERE7l9RiRPX3vxIkT07Zte9xn3LhxQXnQoEFp2w+l15tvvhmUP/nkE6PuhBNOMOLwpd6ZFr7MevPmzUbd008/bcQLFiwwYnsaASou4fHqWFOUv/baa5luTkbwiIiIiJxiIiIiIqeYiIiIyKm8HiOyp+ju27evEYcf29O5c+eo27If8x4eEwKA7du3J9NEcsh+rJM9zXZ4PAkAjjnmmIjbmjx5shHb40+xLFq0KCi/9957Ca1Lxc1+FFU0P//8cwZbkjk8IiIiIqeYiIiIyCkmIiIickpiXZde6koiia9ELsxX1ZauG2Fj/8kPqppzDy4rxr7z5ZdfBuXmzZsbdfaz5S677DIjfv311zPXsCgS7Ts8IiIiIqeYiIiIyCkmIiIiciqv7yMiIip0Dz74YFC2p6i37zGaNWtWVtqUbjwiIiIip5iIiIjIKV6+Xdh4+TYljZdvU7J4+TYREeUVJiIiInKKiYiIiJxiIiIiIqeYiIiIyCkmIiIicoqJiIiInEr2ET8bAaxIZ0MoI45y3YAI2H9yH/sOJSvhvpPUDa1ERETpwlNzRETkFBMRERE5xUREREROMREREZFTTEREROQUExERETnFRERERE4xERERkVNMRERE5NT/AV5K5m2BN0waAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(X[i].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Truth {}\".format(pred[i],y[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "c6hi9GTua0q_",
    "outputId": "79ec5dd7-c225-491b-d78c-94ca65a9ac8f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(X[i].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, score {:.2f}\".format(pred[i],score[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NC-ST1539-HW2-2.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02f72b93b4bb4431914c34df47cb1ed8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d4a15640ef5422299989e834da73626",
      "placeholder": "​",
      "style": "IPY_MODEL_9e896960a2894d7a9c18116881a54ef6",
      "value": " 5120/? [00:00&lt;00:00, 101184.71it/s]"
     }
    },
    "06c878ac72ce4b98b8743bdcc679643e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "094de1b4857b4668b72a3160e0af4ae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d330ee2e8bc640e694abaf2371f0994c",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9580c5922b848dbbeed254a69a302e0",
      "value": 1648877
     }
    },
    "148d268885544c53999e71cceccf6c96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fc76c33a13e44728bf6d974d5036cc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_57fdcfcdc4e240ffa2189a29e2517633",
       "IPY_MODEL_55f40a11927b42e6af8c4eaa37df344b",
       "IPY_MODEL_d5801e57bec3448dae87a53fc1b907a2"
      ],
      "layout": "IPY_MODEL_85a978c798ba44c4ba4fa2ace2bd4983"
     }
    },
    "28442885523141fb8688f1a1f9365c82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d11f46392804f2aa0206790ce5e8ce1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_341c0e8cd3e542778cdc006479db4701",
      "placeholder": "​",
      "style": "IPY_MODEL_4344f89c1ec14095a45de9ba880d9343",
      "value": " 1649664/? [00:00&lt;00:00, 13686585.71it/s]"
     }
    },
    "2d86297399034b389663116e71567f52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341c0e8cd3e542778cdc006479db4701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "353d957da38b4917ba8067fc71daaa19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a26773d69f34cabb07deb3d63733938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_676c07ac3b804786bb65b88e07673633",
       "IPY_MODEL_d90ab9d6017a411fa3efa24de9895501",
       "IPY_MODEL_02f72b93b4bb4431914c34df47cb1ed8"
      ],
      "layout": "IPY_MODEL_6ae38e8964c84b0b8a539a3ea62e7583"
     }
    },
    "3d4a15640ef5422299989e834da73626": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42066f9eebbc471cad42292234606c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c4a404f55b34b229a984f93ddea1f29",
       "IPY_MODEL_cea0ea0ed6544874b6f4d1f8505071fc",
       "IPY_MODEL_dfc3b4f1fd7142d497b4797425b65292"
      ],
      "layout": "IPY_MODEL_2d86297399034b389663116e71567f52"
     }
    },
    "4344f89c1ec14095a45de9ba880d9343": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48d6c74d5c304882bb8be8a3674de859": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c4a404f55b34b229a984f93ddea1f29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d36de7b8a3164379a1e814bbd3ad097d",
      "placeholder": "​",
      "style": "IPY_MODEL_ffd1f3a4f7bc49ff8d0ab31c9c8bf000",
      "value": ""
     }
    },
    "55f40a11927b42e6af8c4eaa37df344b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_353d957da38b4917ba8067fc71daaa19",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff64e56c0d1c461da44351c69addac7f",
      "value": 9912422
     }
    },
    "57fdcfcdc4e240ffa2189a29e2517633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c73bf30e8ca400e9b1df74221b3c26c",
      "placeholder": "​",
      "style": "IPY_MODEL_06c878ac72ce4b98b8743bdcc679643e",
      "value": ""
     }
    },
    "5e0f3233166148ec89445f05c0256668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64e7e002e0274fbd906ac56c49271019": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67247d9d5c454310816815207df8feea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c980d794034a4315ae931fd0f5dc2dcd",
       "IPY_MODEL_094de1b4857b4668b72a3160e0af4ae3",
       "IPY_MODEL_2d11f46392804f2aa0206790ce5e8ce1"
      ],
      "layout": "IPY_MODEL_925214df03974081b0507f44b461e463"
     }
    },
    "676c07ac3b804786bb65b88e07673633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecbe5e6cad78453183cb57a66a382f96",
      "placeholder": "​",
      "style": "IPY_MODEL_64e7e002e0274fbd906ac56c49271019",
      "value": ""
     }
    },
    "6ae38e8964c84b0b8a539a3ea62e7583": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c73bf30e8ca400e9b1df74221b3c26c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85a978c798ba44c4ba4fa2ace2bd4983": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "925214df03974081b0507f44b461e463": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e896960a2894d7a9c18116881a54ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a55a0760c4ce449ca604f931e3c76ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bff4a9aec0d1460aa1a5b01a4ca9dccb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9580c5922b848dbbeed254a69a302e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c980d794034a4315ae931fd0f5dc2dcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a55a0760c4ce449ca604f931e3c76ea8",
      "placeholder": "​",
      "style": "IPY_MODEL_f40fcf31f4c845f4928b6d7c9f738322",
      "value": ""
     }
    },
    "cea0ea0ed6544874b6f4d1f8505071fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_148d268885544c53999e71cceccf6c96",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48d6c74d5c304882bb8be8a3674de859",
      "value": 28881
     }
    },
    "d330ee2e8bc640e694abaf2371f0994c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36de7b8a3164379a1e814bbd3ad097d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5801e57bec3448dae87a53fc1b907a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd069f3fa7634cfa878523058aedafd1",
      "placeholder": "​",
      "style": "IPY_MODEL_e31cdb7f86cb4c5d8af8dca59b5726d6",
      "value": " 9913344/? [00:00&lt;00:00, 9320994.59it/s]"
     }
    },
    "d90ab9d6017a411fa3efa24de9895501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28442885523141fb8688f1a1f9365c82",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ddf26eedd06c45679b1a17b8ce37fa6f",
      "value": 4542
     }
    },
    "dd069f3fa7634cfa878523058aedafd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddf26eedd06c45679b1a17b8ce37fa6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dfc3b4f1fd7142d497b4797425b65292": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bff4a9aec0d1460aa1a5b01a4ca9dccb",
      "placeholder": "​",
      "style": "IPY_MODEL_5e0f3233166148ec89445f05c0256668",
      "value": " 29696/? [00:00&lt;00:00, 630375.74it/s]"
     }
    },
    "e31cdb7f86cb4c5d8af8dca59b5726d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecbe5e6cad78453183cb57a66a382f96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f40fcf31f4c845f4928b6d7c9f738322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff64e56c0d1c461da44351c69addac7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ffd1f3a4f7bc49ff8d0ab31c9c8bf000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
